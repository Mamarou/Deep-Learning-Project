{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN for regression, example 1, house energy bill estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports / modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv-file to pandas DataFrame\n",
    "df = pd.read_csv(\"Cars Datasets 2025.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After that i need to check the datasets to see if some modification are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1218 entries, 0 to 1217\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   Company Names              1218 non-null   object\n",
      " 1   Cars Names                 1218 non-null   object\n",
      " 2   Engines                    1218 non-null   object\n",
      " 3   CC/Battery Capacity        1215 non-null   object\n",
      " 4   HorsePower                 1218 non-null   object\n",
      " 5   Total Speed                1218 non-null   object\n",
      " 6   Performance(0 - 100 )KM/H  1212 non-null   object\n",
      " 7   Cars Prices                1218 non-null   object\n",
      " 8   Fuel Types                 1218 non-null   object\n",
      " 9   Seats                      1218 non-null   object\n",
      " 10  Torque                     1217 non-null   object\n",
      "dtypes: object(11)\n",
      "memory usage: 104.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company Names                0\n",
       "Cars Names                   0\n",
       "Engines                      0\n",
       "CC/Battery Capacity          3\n",
       "HorsePower                   0\n",
       "Total Speed                  0\n",
       "Performance(0 - 100 )KM/H    6\n",
       "Cars Prices                  0\n",
       "Fuel Types                   0\n",
       "Seats                        0\n",
       "Torque                       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company Names                0\n",
       "Cars Names                   0\n",
       "Engines                      0\n",
       "CC/Battery Capacity          3\n",
       "HorsePower                   0\n",
       "Total Speed                  0\n",
       "Performance(0 - 100 )KM/H    6\n",
       "Cars Prices                  0\n",
       "Fuel Types                   0\n",
       "Seats                        0\n",
       "Torque                       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Names</th>\n",
       "      <th>Cars Names</th>\n",
       "      <th>Engines</th>\n",
       "      <th>CC/Battery Capacity</th>\n",
       "      <th>HorsePower</th>\n",
       "      <th>Total Speed</th>\n",
       "      <th>Performance(0 - 100 )KM/H</th>\n",
       "      <th>Cars Prices</th>\n",
       "      <th>Fuel Types</th>\n",
       "      <th>Seats</th>\n",
       "      <th>Torque</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1210</td>\n",
       "      <td>1210</td>\n",
       "      <td>1210</td>\n",
       "      <td>1210</td>\n",
       "      <td>1210</td>\n",
       "      <td>1210</td>\n",
       "      <td>1210</td>\n",
       "      <td>1210</td>\n",
       "      <td>1210</td>\n",
       "      <td>1210</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>37</td>\n",
       "      <td>1193</td>\n",
       "      <td>350</td>\n",
       "      <td>309</td>\n",
       "      <td>453</td>\n",
       "      <td>113</td>\n",
       "      <td>180</td>\n",
       "      <td>533</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Jetta Hybrid</td>\n",
       "      <td>I4</td>\n",
       "      <td>2,000 cc</td>\n",
       "      <td>355 hp</td>\n",
       "      <td>250 km/h</td>\n",
       "      <td>6.5 sec</td>\n",
       "      <td>$35,000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>5</td>\n",
       "      <td>400 Nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>144</td>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "      <td>871</td>\n",
       "      <td>691</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Company Names    Cars Names Engines CC/Battery Capacity HorsePower  \\\n",
       "count           1210          1210    1210                1210       1210   \n",
       "unique            37          1193     350                 309        453   \n",
       "top           Nissan  Jetta Hybrid      I4            2,000 cc     355 hp   \n",
       "freq             148             2      64                  31         23   \n",
       "\n",
       "       Total Speed Performance(0 - 100 )KM/H Cars Prices Fuel Types Seats  \\\n",
       "count         1210                      1210        1210       1210  1210   \n",
       "unique         113                       180         533         21    17   \n",
       "top       250 km/h                   6.5 sec    $35,000      Petrol     5   \n",
       "freq           144                        45          36        871   691   \n",
       "\n",
       "        Torque  \n",
       "count     1210  \n",
       "unique     262  \n",
       "top     400 Nm  \n",
       "freq        72  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Performance(0 - 100 )KM/H\n",
       "6.5 sec               45\n",
       "7.5 sec               43\n",
       "8.5 sec               40\n",
       "10.5 sec              38\n",
       "8.0 sec               34\n",
       "6.0 sec               31\n",
       "9.5 sec               31\n",
       "7.0 sec               26\n",
       "6.8 sec               20\n",
       "2.9 sec               20\n",
       "4.5 sec               20\n",
       "10.0 sec              19\n",
       "9.0 sec               18\n",
       "11.0 sec              18\n",
       "12.0 sec              17\n",
       "5.1 sec               17\n",
       "5.7 sec               16\n",
       "6.6 sec               16\n",
       "7.8 sec               15\n",
       "5.5 sec               14\n",
       "4.8 sec               14\n",
       "10.2 sec              14\n",
       "5.6 sec               13\n",
       "12.5 sec              13\n",
       "7.4 sec               13\n",
       "3.0 sec               13\n",
       "6.7 sec               13\n",
       "6.9 sec               13\n",
       "8.2 sec               12\n",
       "5.0 sec               12\n",
       "7.6 sec               12\n",
       "5.9 sec               12\n",
       "5.2 sec               12\n",
       "7.3 sec               12\n",
       "5.4 sec               11\n",
       "15.0 sec              11\n",
       "6.2 sec               11\n",
       "3.9 sec               11\n",
       "2.8 sec               11\n",
       "3.6 sec               11\n",
       "11.5 sec              11\n",
       "4.9 sec               10\n",
       "4.4 sec               10\n",
       "8.4 sec                9\n",
       "3.4 sec                9\n",
       "9.2 sec                9\n",
       "6.3 sec                9\n",
       "3.5 sec                9\n",
       "13.0 sec               9\n",
       "7.1 sec                8\n",
       "3.3 sec                8\n",
       "5.3 sec                8\n",
       "7.2 sec                8\n",
       "8.6 sec                8\n",
       "7.9 sec                8\n",
       "5.8 sec                8\n",
       "4.1 sec                7\n",
       "2.5 sec                7\n",
       "3.2 sec                7\n",
       "9.4 sec                7\n",
       "9.6 sec                7\n",
       "8.9 sec                7\n",
       "4.3 sec                7\n",
       "6.1 sec                7\n",
       "4.2 sec                7\n",
       "6.4 sec                7\n",
       "4.0 sec                7\n",
       "4.7 sec                7\n",
       "8.8 sec                7\n",
       "9.8 sec                7\n",
       "14.0 sec               7\n",
       "3.1 sec                6\n",
       "13.5 sec               6\n",
       "9.3 sec                6\n",
       "11.2 sec               6\n",
       "12.2 sec               6\n",
       "7.7 sec                6\n",
       "2.4 sec                5\n",
       "8.1 sec                5\n",
       "8.3 sec                5\n",
       "10.3 sec               5\n",
       "3.7 sec                4\n",
       "10.8 sec               4\n",
       "10.9 sec               4\n",
       "15.5 sec               4\n",
       "16.0 sec               4\n",
       "3.2                    4\n",
       "10.7 sec               4\n",
       "13 sec                 3\n",
       "4.1                    3\n",
       "3.8 sec                3\n",
       "10.6 sec               3\n",
       "18.0 sec               3\n",
       "14.5 sec               3\n",
       "4.4                    3\n",
       "12 sec                 3\n",
       "8.7 sec                3\n",
       "3.4                    3\n",
       "10.4 sec               3\n",
       "11 sec                 3\n",
       "15 sec                 3\n",
       "16 sec                 3\n",
       "17 sec                 2\n",
       "9.7 sec                2\n",
       "3.8                    2\n",
       "4.9                    2\n",
       "4.7                    2\n",
       "5.6                    2\n",
       "4.8                    2\n",
       "4.3                    2\n",
       "12.9 sec               2\n",
       "3.5                    2\n",
       "11.9 sec               2\n",
       "4.6 sec                2\n",
       "14.8 sec               2\n",
       "4.2                    2\n",
       "3.6                    2\n",
       "5.4                    2\n",
       "16.5 sec               2\n",
       "10 sec                 2\n",
       "7.1  sec               1\n",
       " 6.1 sec               1\n",
       "23.0 sec               1\n",
       "9.9 sec                1\n",
       "12.4 sec               1\n",
       "11.7 sec               1\n",
       "17.5 sec               1\n",
       "5. 0 sec               1\n",
       "8 sec                  1\n",
       "10. 5 sec              1\n",
       "6 sec                  1\n",
       "14.3 sec               1\n",
       "13.8 sec               1\n",
       "12.3 sec               1\n",
       "12.8 sec               1\n",
       "18.5 sec               1\n",
       "13.7 sec               1\n",
       "10.1 sec               1\n",
       "6.2                    1\n",
       "6.4                    1\n",
       "3.9                    1\n",
       "3.7                    1\n",
       "5.5                    1\n",
       "2.8                    1\n",
       "2.6                    1\n",
       "4.6                    1\n",
       "2.7                    1\n",
       "4                      1\n",
       "29 sec                 1\n",
       "7.3                    1\n",
       "6.5                    1\n",
       "2.7 sec                1\n",
       "4.5                    1\n",
       "5.9                    1\n",
       "3.3                    1\n",
       "5.8                    1\n",
       "2.1 sec                1\n",
       "17.6 sec               1\n",
       "2.6 sec                1\n",
       "1.9 sec                1\n",
       "2.3 sec                1\n",
       "9.1 sec                1\n",
       "14 sec                 1\n",
       "9 sec                  1\n",
       "17.0 sec               1\n",
       "2.2 sec                1\n",
       "22.0 sec               1\n",
       "20.0 sec               1\n",
       "5.0 - 6.5 sec          1\n",
       "6.5 - 7.0 sec          1\n",
       "7.0 - 8.0 sec          1\n",
       "7.2 sec / 5.4 sec      1\n",
       "6.5 - 8.0 sec          1\n",
       "6.0 - 7.0 sec          1\n",
       "3.5 sec (GT Model)     1\n",
       "9.0 - 12.0 sec         1\n",
       "35.0 sec               1\n",
       "8.0  9.2 sec          1\n",
       "7.9  10.5 sec         1\n",
       "6.0  8.1 sec          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Performance(0 - 100 )KM/H\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is a few messy values(eg. 5.0 - 6.5 sec, 6.5 - 7.0 sec ect) in the dataset and with very low cardinality(1) so i decided to manage the column and ignore these values keeping only the typical ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance(0 - 100 )KM/H\n",
      "6.5     45\n",
      "7.5     43\n",
      "8.5     40\n",
      "10.5    38\n",
      "8.0     35\n",
      "6.0     32\n",
      "9.5     31\n",
      "7.0     26\n",
      "11.0    21\n",
      "10.0    21\n",
      "4.5     20\n",
      "2.9     20\n",
      "12.0    20\n",
      "6.8     20\n",
      "9.0     19\n",
      "5.1     17\n",
      "6.6     16\n",
      "5.7     16\n",
      "7.8     15\n",
      "4.8     14\n",
      "10.2    14\n",
      "5.5     14\n",
      "15.0    14\n",
      "6.9     13\n",
      "6.7     13\n",
      "5.6     13\n",
      "12.5    13\n",
      "3.0     13\n",
      "7.4     13\n",
      "5.9     12\n",
      "7.6     12\n",
      "5.0     12\n",
      "13.0    12\n",
      "7.3     12\n",
      "8.2     12\n",
      "5.2     12\n",
      "6.2     11\n",
      "11.5    11\n",
      "2.8     11\n",
      "3.9     11\n",
      "5.4     11\n",
      "3.6     11\n",
      "4.4     10\n",
      "4.9     10\n",
      "7.1      9\n",
      "6.3      9\n",
      "3.5      9\n",
      "3.4      9\n",
      "8.4      9\n",
      "9.2      9\n",
      "7.9      8\n",
      "7.2      8\n",
      "5.8      8\n",
      "3.3      8\n",
      "5.3      8\n",
      "8.6      8\n",
      "14.0     8\n",
      "4.0      7\n",
      "3.2      7\n",
      "2.5      7\n",
      "4.1      7\n",
      "6.4      7\n",
      "16.0     7\n",
      "8.8      7\n",
      "9.6      7\n",
      "9.8      7\n",
      "4.2      7\n",
      "4.3      7\n",
      "8.9      7\n",
      "4.7      7\n",
      "9.4      7\n",
      "6.1      7\n",
      "12.2     6\n",
      "3.1      6\n",
      "11.2     6\n",
      "7.7      6\n",
      "9.3      6\n",
      "13.5     6\n",
      "2.4      5\n",
      "10.3     5\n",
      "8.1      5\n",
      "8.3      5\n",
      "3.7      4\n",
      "10.9     4\n",
      "10.8     4\n",
      "10.7     4\n",
      "15.5     4\n",
      "3.8      3\n",
      "10.4     3\n",
      "14.5     3\n",
      "17.0     3\n",
      "8.7      3\n",
      "18.0     3\n",
      "10.6     3\n",
      "14.8     2\n",
      "4.6      2\n",
      "9.7      2\n",
      "16.5     2\n",
      "11.9     2\n",
      "12.9     2\n",
      "12.4     1\n",
      "9.9      1\n",
      "17.5     1\n",
      "11.7     1\n",
      "14.3     1\n",
      "23.0     1\n",
      "13.7     1\n",
      "10.1     1\n",
      "29.0     1\n",
      "2.7      1\n",
      "13.8     1\n",
      "18.5     1\n",
      "12.8     1\n",
      "12.3     1\n",
      "2.1      1\n",
      "17.6     1\n",
      "9.1      1\n",
      "1.9      1\n",
      "2.6      1\n",
      "2.3      1\n",
      "20.0     1\n",
      "2.2      1\n",
      "22.0     1\n",
      "35.0     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col = \"Performance(0 - 100 )KM/H\"\n",
    "df = df[df[col].astype(str).str.match(r\"^\\d+(\\.\\d+)?\\s*sec$\")]\n",
    "\n",
    "df[col] = df[col].str.replace(\" sec\", \"\").astype(float)\n",
    "\n",
    "print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Torque\n",
       "400 Nm               69\n",
       "250 Nm               56\n",
       "350 Nm               39\n",
       "500 Nm               31\n",
       "450 Nm               25\n",
       "519 Nm               22\n",
       "600 Nm               20\n",
       "560 Nm               19\n",
       "300 Nm               19\n",
       "200 Nm               18\n",
       "624 Nm               17\n",
       "850 Nm               16\n",
       "360 Nm               16\n",
       "320 Nm               15\n",
       "366 Nm               14\n",
       "900 Nm               13\n",
       "260 Nm               13\n",
       "310 Nm               12\n",
       "275 Nm               12\n",
       "355 Nm               12\n",
       "140 Nm               11\n",
       "180 Nm               11\n",
       "230 Nm               11\n",
       "160 Nm               11\n",
       "270 Nm               11\n",
       "430 Nm               11\n",
       "700 Nm               10\n",
       "179 Nm               10\n",
       "1600 Nm              10\n",
       "750 Nm               10\n",
       "264 Nm               10\n",
       "280 Nm               10\n",
       "800 Nm                9\n",
       "240 Nm                9\n",
       "362 Nm                9\n",
       "650 Nm                9\n",
       "420 Nm                9\n",
       "170 Nm                9\n",
       "265 Nm                9\n",
       "520 Nm                9\n",
       "629 Nm                8\n",
       "583 Nm                8\n",
       "113 Nm                8\n",
       "245 Nm                8\n",
       "637 Nm                8\n",
       "210 Nm                8\n",
       "870 Nm                8\n",
       "330 Nm                7\n",
       "205 Nm                7\n",
       "570 Nm                7\n",
       "150 Nm                7\n",
       "220 Nm                7\n",
       "720 Nm                7\n",
       "475 Nm                7\n",
       "353 Nm                6\n",
       "620 Nm                6\n",
       "380 Nm                6\n",
       "550 Nm                6\n",
       "145 Nm                6\n",
       "135 Nm                6\n",
       "480 Nm                6\n",
       "100 Nm                6\n",
       "197 Nm                6\n",
       "352 Nm                6\n",
       "130 Nm                6\n",
       "340 Nm                6\n",
       "15,590 Nm             5\n",
       "696 Nm                5\n",
       "151 Nm                5\n",
       "365 Nm                5\n",
       "630 Nm                5\n",
       "770 Nm                5\n",
       "1234 Nm               5\n",
       "441 Nm                4\n",
       "335 Nm                4\n",
       "760 Nm                4\n",
       "690 Nm                4\n",
       "580 Nm                4\n",
       "154 Nm                4\n",
       "290 Nm                4\n",
       "680 Nm                4\n",
       "252 Nm                4\n",
       "190 Nm                3\n",
       "652 Nm                3\n",
       "840 Nm                3\n",
       "142 Nm                3\n",
       "305 Nm                3\n",
       "120 Nm                3\n",
       "385 Nm                3\n",
       "451 Nm                3\n",
       "110 Nm                3\n",
       "95 Nm                 3\n",
       "413 Nm                3\n",
       "666 Nm                3\n",
       "370 Nm                3\n",
       "373 Nm                3\n",
       "60 Nm                 3\n",
       "127 Nm                3\n",
       "470 Nm                3\n",
       "114 Nm                3\n",
       "351 Nm                3\n",
       "617 Nm                2\n",
       "440 Nm                2\n",
       "1000+ Nm              2\n",
       "199 Nm                2\n",
       "460 Nm                2\n",
       "106 Nm                2\n",
       "325 Nm                2\n",
       "175 Nm                2\n",
       "93 Nm                 2\n",
       "217 Nm                2\n",
       "381 Nm                2\n",
       "1000 Nm               2\n",
       "685 Nm                2\n",
       "100 - 140 Nm          2\n",
       "225 Nm                2\n",
       "384 Nm                2\n",
       "664 Nm                2\n",
       "565 Nm                2\n",
       "390 Nm                2\n",
       "1,424 Nm              2\n",
       "215 Nm                2\n",
       "2500 Nm               2\n",
       "691 Nm                2\n",
       "141 Nm                2\n",
       "94 Nm                 2\n",
       "405 Nm                2\n",
       "206 Nm                2\n",
       "967 Nm                2\n",
       "198 Nm                2\n",
       "115 Nm                2\n",
       "1,400 Nm              2\n",
       "90 Nm                 2\n",
       "85 Nm                 2\n",
       "678 Nm                2\n",
       "563 Nm                2\n",
       "259 Nm                2\n",
       "422 Nm                2\n",
       "530 Nm                2\n",
       "569 Nm                2\n",
       "156 Nm                1\n",
       "171 Nm                1\n",
       "410 Nm                1\n",
       "295 Nm                1\n",
       "354 Nm                1\n",
       "651 Nm                1\n",
       "719 Nm                1\n",
       "718 Nm                1\n",
       "395 Nm                1\n",
       "153 Nm                1\n",
       "132 Nm                1\n",
       "821 Nm                1\n",
       "103 Nm                1\n",
       "278 Nm                1\n",
       "184 Nm                1\n",
       "186 Nm                1\n",
       "161 Nm                1\n",
       "168 Nm                1\n",
       "392 Nm                1\n",
       "356 Nm                1\n",
       "248 Nm                1\n",
       "174 Nm                1\n",
       "191 Nm                1\n",
       "139 Nm                1\n",
       "207 Nm                1\n",
       "780 Nm                1\n",
       "374 Nm                1\n",
       "329 Nm                1\n",
       "285 Nm                1\n",
       "10,000 Nm             1\n",
       "1,355 Nm              1\n",
       "559 Nm                1\n",
       "660 Nm                1\n",
       "498 Nm                1\n",
       "200 Nm / 115 Nm       1\n",
       "170-260 Nm            1\n",
       "190 Nm / 140 Nm       1\n",
       "135 Nm / 115 Nm       1\n",
       "344 Nm                1\n",
       "195 Nm                1\n",
       "820 Nm                1\n",
       "525 Nm                1\n",
       "188 Nm                1\n",
       "62 Nm                 1\n",
       "3500 Nm               1\n",
       "2600 Nm               1\n",
       "740 Nm                1\n",
       "510 Nm                1\n",
       "246 Nm                1\n",
       "255 Nm                1\n",
       "1,064 Nm              1\n",
       "421 Nm                1\n",
       "603 Nm                1\n",
       "893 Nm                1\n",
       "885 Nm                1\n",
       "324 Nm                1\n",
       "548 Nm                1\n",
       "529 Nm                1\n",
       "236 Nm                1\n",
       "881 Nm                1\n",
       "51 Nm                 1\n",
       "113-200 Nm            1\n",
       "1050 Nm               1\n",
       "465 Nm                1\n",
       "400 - 475 Nm          1\n",
       "150 - 400 Nm          1\n",
       "247 Nm                1\n",
       "130 - 290 Nm          1\n",
       "300 - 500 Nm          1\n",
       "200 - 400 Nm          1\n",
       "1200 Nm               1\n",
       "625 Nm                1\n",
       "640 Nm                1\n",
       "2200 Nm               1\n",
       "2400 Nm               1\n",
       "1800 Nm               1\n",
       "345 Nm                1\n",
       "1051 Nm               1\n",
       "210 Nm (Electric)     1\n",
       "746 Nm                1\n",
       "250 - 375 Nm          1\n",
       "420 - 500 Nm          1\n",
       "650 - 800 Nm          1\n",
       "400 - 600 Nm          1\n",
       "230 - 200 Nm          1\n",
       "170 - 200 Nm          1\n",
       "825 Nm                1\n",
       "407 Nm                1\n",
       "154 - 197 Nm          1\n",
       "542 Nm                1\n",
       "582 Nm                1\n",
       "847 Nm                1\n",
       "214 Nm                1\n",
       "181 Nm                1\n",
       "196 Nm                1\n",
       "343 Nm                1\n",
       "434 Nm                1\n",
       "271 Nm                1\n",
       "173 Nm                1\n",
       "213 Nm                1\n",
       "314 Nm                1\n",
       "202 Nm                1\n",
       "165 Nm                1\n",
       "80 Nm                 1\n",
       "155 Nm                1\n",
       "105 Nm                1\n",
       "45 Nm                 1\n",
       "239 Nm                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Torque\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's the same we can see that some data are not in a way we want so same process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torque\n",
      "400     69\n",
      "250     56\n",
      "350     39\n",
      "500     31\n",
      "450     25\n",
      "519     22\n",
      "600     20\n",
      "300     19\n",
      "560     19\n",
      "200     18\n",
      "624     17\n",
      "360     16\n",
      "850     16\n",
      "320     15\n",
      "366     14\n",
      "900     13\n",
      "260     13\n",
      "310     12\n",
      "355     12\n",
      "275     12\n",
      "230     11\n",
      "270     11\n",
      "430     11\n",
      "160     11\n",
      "140     11\n",
      "180     11\n",
      "750     10\n",
      "280     10\n",
      "700     10\n",
      "264     10\n",
      "1600    10\n",
      "179     10\n",
      "420      9\n",
      "650      9\n",
      "800      9\n",
      "520      9\n",
      "170      9\n",
      "240      9\n",
      "265      9\n",
      "362      9\n",
      "637      8\n",
      "870      8\n",
      "113      8\n",
      "245      8\n",
      "210      8\n",
      "629      8\n",
      "583      8\n",
      "150      7\n",
      "720      7\n",
      "220      7\n",
      "330      7\n",
      "475      7\n",
      "570      7\n",
      "205      7\n",
      "145      6\n",
      "550      6\n",
      "353      6\n",
      "620      6\n",
      "340      6\n",
      "135      6\n",
      "380      6\n",
      "130      6\n",
      "197      6\n",
      "100      6\n",
      "352      6\n",
      "480      6\n",
      "1234     5\n",
      "770      5\n",
      "630      5\n",
      "151      5\n",
      "365      5\n",
      "696      5\n",
      "580      4\n",
      "290      4\n",
      "441      4\n",
      "680      4\n",
      "760      4\n",
      "252      4\n",
      "154      4\n",
      "335      4\n",
      "690      4\n",
      "305      3\n",
      "370      3\n",
      "652      3\n",
      "385      3\n",
      "470      3\n",
      "373      3\n",
      "666      3\n",
      "413      3\n",
      "142      3\n",
      "840      3\n",
      "120      3\n",
      "95       3\n",
      "351      3\n",
      "110      3\n",
      "127      3\n",
      "451      3\n",
      "60       3\n",
      "114      3\n",
      "190      3\n",
      "215      2\n",
      "569      2\n",
      "90       2\n",
      "691      2\n",
      "422      2\n",
      "967      2\n",
      "617      2\n",
      "115      2\n",
      "259      2\n",
      "106      2\n",
      "565      2\n",
      "1000     2\n",
      "381      2\n",
      "460      2\n",
      "325      2\n",
      "664      2\n",
      "93       2\n",
      "685      2\n",
      "390      2\n",
      "85       2\n",
      "678      2\n",
      "2500     2\n",
      "141      2\n",
      "94       2\n",
      "175      2\n",
      "530      2\n",
      "217      2\n",
      "198      2\n",
      "206      2\n",
      "384      2\n",
      "225      2\n",
      "199      2\n",
      "440      2\n",
      "405      2\n",
      "563      2\n",
      "719      1\n",
      "295      1\n",
      "718      1\n",
      "651      1\n",
      "821      1\n",
      "354      1\n",
      "153      1\n",
      "248      1\n",
      "171      1\n",
      "174      1\n",
      "156      1\n",
      "395      1\n",
      "410      1\n",
      "132      1\n",
      "62       1\n",
      "525      1\n",
      "344      1\n",
      "195      1\n",
      "188      1\n",
      "103      1\n",
      "374      1\n",
      "191      1\n",
      "139      1\n",
      "881      1\n",
      "236      1\n",
      "603      1\n",
      "285      1\n",
      "529      1\n",
      "324      1\n",
      "885      1\n",
      "893      1\n",
      "548      1\n",
      "465      1\n",
      "1050     1\n",
      "820      1\n",
      "51       1\n",
      "660      1\n",
      "498      1\n",
      "559      1\n",
      "392      1\n",
      "186      1\n",
      "168      1\n",
      "161      1\n",
      "329      1\n",
      "207      1\n",
      "780      1\n",
      "356      1\n",
      "278      1\n",
      "184      1\n",
      "2200     1\n",
      "740      1\n",
      "246      1\n",
      "3500     1\n",
      "2600     1\n",
      "421      1\n",
      "345      1\n",
      "746      1\n",
      "1051     1\n",
      "247      1\n",
      "640      1\n",
      "1800     1\n",
      "2400     1\n",
      "625      1\n",
      "1200     1\n",
      "255      1\n",
      "510      1\n",
      "542      1\n",
      "196      1\n",
      "825      1\n",
      "847      1\n",
      "582      1\n",
      "214      1\n",
      "181      1\n",
      "407      1\n",
      "343      1\n",
      "434      1\n",
      "271      1\n",
      "173      1\n",
      "213      1\n",
      "314      1\n",
      "202      1\n",
      "165      1\n",
      "80       1\n",
      "155      1\n",
      "105      1\n",
      "45       1\n",
      "239      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col = \"Torque\"\n",
    "df = df[df[col].astype(str).str.match(r\"^\\d+(\\.\\d+)?\\s*Nm$\")]\n",
    "\n",
    "df[col] = df[col].str.replace(\" Nm\", \"\").astype(int)\n",
    "\n",
    "print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And Again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cars Prices\n",
       "$35,000                    36\n",
       "$30,000                    32\n",
       "$50,000                    31\n",
       "$55,000                    29\n",
       "$25,000                    28\n",
       "$45,000                    28\n",
       "$40,000                    27\n",
       "$60,000                    22\n",
       "$28,000                    22\n",
       "$70,000                    17\n",
       "$20,000                    15\n",
       "$18,000                    15\n",
       "$85,000                    14\n",
       "$32,000                    13\n",
       "$22,000                    12\n",
       "$38,000                    11\n",
       "$20,000 - $25,000          10\n",
       "$25,000 - $30,000           9\n",
       "$36,000                     9\n",
       "$42,000                     9\n",
       "$30,000 - $35,000           9\n",
       "$52,000                     9\n",
       "$33,000                     8\n",
       "$27,000                     8\n",
       "$65,000                     8\n",
       "$23,000                     7\n",
       "$15,000                     7\n",
       "$35,000 - $40,000           7\n",
       "$18,000 - $22,000           7\n",
       "$48,000                     7\n",
       "$44,000                     7\n",
       "$75,000                     7\n",
       "$15,000 - $18,000           6\n",
       "$10,000 - $12,000           6\n",
       "$90,000                     6\n",
       "$95,000                     6\n",
       "$39,000                     5\n",
       "$37,000                     5\n",
       "$31,000                     5\n",
       "$62,000                     5\n",
       "$29,000                     5\n",
       "$12,000                     5\n",
       "$12,000 - $15,000           5\n",
       "$80,000                     5\n",
       "$47,000                     5\n",
       "$46,000                     5\n",
       "$45,000 - $50,000           4\n",
       "$19,000                     4\n",
       "$24,000                     4\n",
       "$18,500                     4\n",
       "$14,500                     4\n",
       "$110,000                    4\n",
       "$100,000                    4\n",
       "$120,000                    4\n",
       "$40,000 - $45,000           4\n",
       "$27,000 - $35,000           4\n",
       "$1,100,000                  4\n",
       "$22,500                     4\n",
       "$58,000                     4\n",
       "$49,000                     4\n",
       "$26,000                     4\n",
       "$53,000                     4\n",
       "$14,000 - $18,000           4\n",
       "$25,000 - $28,000           3\n",
       "$78,000                     3\n",
       "$18,400                     3\n",
       "$22,000 - $28,000           3\n",
       "$28,500                     3\n",
       "$220,000                    3\n",
       "$170,000                    3\n",
       "$15,000 - $17,000           3\n",
       "$14,000                     3\n",
       "$3,300,000                  3\n",
       "$23,500                     3\n",
       "$157,000                    3\n",
       "$280,000                    2\n",
       "$240,000                    2\n",
       "$20,000 - $24,000           2\n",
       "$113,000                    2\n",
       "$28,000 - $35,000           2\n",
       "$142,000                    2\n",
       "$109,000                    2\n",
       "$116,000                    2\n",
       "$20,000 - $23,000           2\n",
       "$22,000 - $26,000           2\n",
       "$258,000                    2\n",
       "$545,000                    2\n",
       "$4,500,000                  2\n",
       "$421,000                    2\n",
       "$350,000                    2\n",
       "$68,000                     2\n",
       "$82,000                     2\n",
       "$40,000 - $50,000           2\n",
       "$35,500                     2\n",
       "$23,000 - $26,000           2\n",
       "$56,995                     2\n",
       "$41,500                     2\n",
       "$28,795                     2\n",
       "$45,500                     2\n",
       "$222,000                    2\n",
       "$11,000                     2\n",
       "$10,000                     2\n",
       "$25,500                     2\n",
       "$92,000                     2\n",
       "$114,000                    2\n",
       "$43,900                     2\n",
       "$34,500                     2\n",
       "$64,100                     2\n",
       "$43,500                     2\n",
       "$65,895                     2\n",
       "$43,000                     2\n",
       "$105,000                    2\n",
       "$500,000                    2\n",
       "$360,000                    2\n",
       "$330,000                    2\n",
       "$190,000                    2\n",
       "$130,000                    2\n",
       "$34,000                     2\n",
       "$17,500                     2\n",
       "$38,400                     2\n",
       "$26,400                     2\n",
       "$57,000                     2\n",
       "$42,500                     2\n",
       "$15,500                     2\n",
       "$77,000                     2\n",
       "$51,000                     2\n",
       "$150,000                    2\n",
       "$56,000                     2\n",
       "$16,000                     2\n",
       "$573,000                    2\n",
       "$54,000                     2\n",
       "$63,000                     2\n",
       "$43,400                     2\n",
       "$33,400                     2\n",
       "$41,400                     2\n",
       "$41,000                     2\n",
       "$20,400                     2\n",
       "$15,400                     2\n",
       "$28,000 - $30,000           2\n",
       "$287,000                    2\n",
       "$18,000 - $24,000           2\n",
       "$8,000 - $10,000            2\n",
       "$15,000 - $20,000           2\n",
       "$193,440                    1\n",
       "$230,000                    1\n",
       "$1,700,000                  1\n",
       "$30,000 - $50,000           1\n",
       "$24,000 - $30,000           1\n",
       "$28,000 - $33,000           1\n",
       "$33,000 - $37,000           1\n",
       "$33,000 - $40,000           1\n",
       "$27,000 - $33,000           1\n",
       "$9,000 - $11,000            1\n",
       "$12,000 - $18,000           1\n",
       "$9,000 - $12,000            1\n",
       "$13,000 - $18,000           1\n",
       "$308,000                    1\n",
       "$445,000                    1\n",
       "$38,000 - $45,000           1\n",
       "$50,000 - $60,000           1\n",
       "$23,000 - $25,000           1\n",
       "$17,000 - $20,000           1\n",
       "$381,000                    1\n",
       "$475,000                    1\n",
       "$335,000                    1\n",
       "$349,000                    1\n",
       "$495,000                    1\n",
       "$355,000                    1\n",
       "$380,000                    1\n",
       "$320,000                    1\n",
       "$104,000                    1\n",
       "$3,200,000                  1\n",
       "$316,000                    1\n",
       "$208,000                    1\n",
       "$71,000                     1\n",
       "$41,820                     1\n",
       "$31,100                     1\n",
       "$58,500                     1\n",
       "$25,390                     1\n",
       "$49,500                     1\n",
       "$40,799                     1\n",
       "$19,950                     1\n",
       "$41,450                     1\n",
       "$30,500                     1\n",
       "$52,400                     1\n",
       "$44,150                     1\n",
       "$40,400                     1\n",
       "$49,400                     1\n",
       "$24,400                     1\n",
       "$12,400                     1\n",
       "$61,750                     1\n",
       "$28,505                     1\n",
       "$21,995                     1\n",
       "$39,735                     1\n",
       "$59,995                     1\n",
       "$31,965                     1\n",
       "$44,640                     1\n",
       "$16,700                     1\n",
       "$26,350                     1\n",
       "$26,700                     1\n",
       "$27,100                     1\n",
       "$37,400                     1\n",
       "$39,900                     1\n",
       "$165,000                    1\n",
       "$81,000                     1\n",
       "$99,000                     1\n",
       "$370,000                    1\n",
       "$390,000                    1\n",
       "$450,000                    1\n",
       "$340,000                    1\n",
       "$189,000                    1\n",
       "$294,000                    1\n",
       "$1,300,000                  1\n",
       "$2,800,000                  1\n",
       "$518,000                    1\n",
       "$274,000                    1\n",
       "$261,000                    1\n",
       "$493,000                    1\n",
       "$45,790                     1\n",
       "$41,750                     1\n",
       "$175,000                    1\n",
       "$98,000                     1\n",
       "$401,000                    1\n",
       "$515,000                    1\n",
       "$375,000                    1\n",
       "$389,000                    1\n",
       "$439,000                    1\n",
       "$194,000                    1\n",
       "$180,000                    1\n",
       "$102,000                    1\n",
       "$115,000                    1\n",
       "$58,950                     1\n",
       "$70,600                     1\n",
       "$13,000                     1\n",
       "$24,960                     1\n",
       "$42,820                     1\n",
       "$65,300                     1\n",
       "$325,000                    1\n",
       "$157,300                    1\n",
       "$184,100                    1\n",
       "$185,000                    1\n",
       "$67,000                     1\n",
       "$600,000                    1\n",
       "$1,000,000                  1\n",
       "$88,000                     1\n",
       "$263,000                    1\n",
       "$327,000                    1\n",
       "$273,000                    1\n",
       "$603,000                    1\n",
       "$253,000                    1\n",
       "$342,000                    1\n",
       "$332,000                    1\n",
       "$369,000                    1\n",
       "$418,000                    1\n",
       "$11,300                     1\n",
       "$11,800                     1\n",
       "$9,200                      1\n",
       "$4,000                      1\n",
       "$34,395                     1\n",
       "$46,595                     1\n",
       "$38,195                     1\n",
       "$50,995                     1\n",
       "$94,800                     1\n",
       "$139,400                    1\n",
       "$90,500                     1\n",
       "$136,700                    1\n",
       "$106,100                    1\n",
       "$129,900                    1\n",
       "$113,300                    1\n",
       "$137,000                    1\n",
       "$16,500                     1\n",
       "$88,490                     1\n",
       "$40,240                     1\n",
       "$53,240                     1\n",
       "$98,490                     1\n",
       "$47,490                     1\n",
       "$207,000                    1\n",
       "$223,800                    1\n",
       "$145,300                    1\n",
       "$135,500                    1\n",
       "$293,200                    1\n",
       "$245,000                    1\n",
       "$750,000                    1\n",
       "$191,300                    1\n",
       "$233,000                    1\n",
       "$8,200                      1\n",
       "$63,595                     1\n",
       "$91,495                     1\n",
       "$59,865                     1\n",
       "$50,695                     1\n",
       "$46,500                     1\n",
       "$44,500                     1\n",
       "$17,000-$20,000             1\n",
       "$6,200                      1\n",
       "$5,000                      1\n",
       "$9,400                      1\n",
       "$6,500                      1\n",
       "$79,295                     1\n",
       "$7,000                      1\n",
       "$7,200                      1\n",
       "$82,295                     1\n",
       "$10,500                     1\n",
       "$104,595                    1\n",
       "$60,495                     1\n",
       "$41,390                     1\n",
       "$51,095                     1\n",
       "$57,095                     1\n",
       "$59,990                     1\n",
       "$64,990                     1\n",
       "$50,490                     1\n",
       "$35,195                     1\n",
       "$42,100                     1\n",
       "$41,530                     1\n",
       "$43,530                     1\n",
       "$37,695                     1\n",
       "$31,590                     1\n",
       "$28,345                     1\n",
       "$38,775                     1\n",
       "$26,600                     1\n",
       "$59,900                     1\n",
       "$30,695                     1\n",
       "$42,795                     1\n",
       "$27,495                     1\n",
       "$23,100                     1\n",
       "$33,500                     1\n",
       "$51,570                     1\n",
       "$66,575                     1\n",
       "$41,295                     1\n",
       "$82,495                     1\n",
       "$37,490                     1\n",
       "$44,195                     1\n",
       "$48,595                     1\n",
       "$58,590                     1\n",
       "$149,990                    1\n",
       "$50,895                     1\n",
       "$48,295                     1\n",
       "$46,600                     1\n",
       "$48,900                     1\n",
       "$65,900                     1\n",
       "$43,700                     1\n",
       "$25,800                     1\n",
       "$17,595                     1\n",
       "$24,100                     1\n",
       "$28,400                     1\n",
       "$75,700                     1\n",
       "$29,200                     1\n",
       "$41,290                     1\n",
       "$14,595                     1\n",
       "$16,720                     1\n",
       "$35,915                     1\n",
       "$33,900                     1\n",
       "$14,395                     1\n",
       "$37,200                     1\n",
       "$36,100                     1\n",
       "$31,900                     1\n",
       "$34,900                     1\n",
       "$56,400                     1\n",
       "$64,400                     1\n",
       "$31,700                     1\n",
       "$62,495                     1\n",
       "$66,700                     1\n",
       "$71,600                     1\n",
       "$76,700                     1\n",
       "$67,300                     1\n",
       "$61,595                     1\n",
       "$55,895                     1\n",
       "$83,000                     1\n",
       "$69,000                     1\n",
       "$146,000                    1\n",
       "$108,000                    1\n",
       "$398,000                    1\n",
       "$36,900                     1\n",
       "$37,100                     1\n",
       "$72,800                     1\n",
       "$66,800                     1\n",
       "$36,500                     1\n",
       "$53,800                     1\n",
       "$72,200                     1\n",
       "$93,800                     1\n",
       "$38,600                     1\n",
       "$54,300                     1\n",
       "$82,400                     1\n",
       "$51,500                     1\n",
       "$20,500                     1\n",
       "$3,000,000                  1\n",
       "$65,500                     1\n",
       "$29,900                     1\n",
       "$36,800                     1\n",
       "$57,400                     1\n",
       "$61,100                     1\n",
       "$101,000                    1\n",
       "$96,000                     1\n",
       "$86,000                     1\n",
       "$64,000                     1\n",
       "$59,000                     1\n",
       "$200,000                    1\n",
       "$133,000                    1\n",
       "$76,000                     1\n",
       "$40,000 - $90,000           1\n",
       "$50,000 - $55,000           1\n",
       "$43,455                     1\n",
       "$29,365                     1\n",
       "$79,420                     1\n",
       "$59,140                     1\n",
       "$64,695                     1\n",
       "$71,505                     1\n",
       "$73,305                     1\n",
       "$72,000                     1\n",
       "$36,300                     1\n",
       "$28,700                     1\n",
       "$76,805                     1\n",
       "$37,700                     1\n",
       "$17,000                     1\n",
       "$39,500                     1\n",
       "$12,000 - $16,000           1\n",
       "$84,910                     1\n",
       "$56,505                     1\n",
       "$79,560                     1\n",
       "$16,000 - $18,000           1\n",
       "$17,000 - $19,000           1\n",
       "$39,000 - $43,000           1\n",
       "$25,000 - $35,000           1\n",
       "$32,000 - $35,000           1\n",
       "$3,500,000                  1\n",
       "$5,800,000                  1\n",
       "$9,000,000                  1\n",
       "$18,000,000                 1\n",
       "$5,000,000                  1\n",
       "$160,000                    1\n",
       "$125,000                    1\n",
       "$211,000                    1\n",
       "$53,900                     1\n",
       "$43,590  $48,000           1\n",
       "$460,000                    1\n",
       "$161,000                    1\n",
       "$253,290                    1\n",
       "$311,000                    1\n",
       "$499,000                    1\n",
       "$210,000                    1\n",
       "$242,000                    1\n",
       "$24,000 - $28,000           1\n",
       "$21,000 - $25,000           1\n",
       "$23,000 - $28,000           1\n",
       "$26,000 - $32,000           1\n",
       "$29,000 - $36,000           1\n",
       "$36,000 - $42,000           1\n",
       "$16,400                     1\n",
       "$10,400                     1\n",
       "$11,400                     1\n",
       "$14,400                     1\n",
       "$32,500                     1\n",
       "$29,400                     1\n",
       "$26,500                     1\n",
       "$20,000 - $22,000           1\n",
       "$28,000 - $32,000           1\n",
       "$18,000 - $20,000           1\n",
       "$13,000 - $16,000           1\n",
       "$14,000 - $16,000           1\n",
       "$5,000,000 - $7,000,000     1\n",
       "$31,000 - $34,000           1\n",
       "$29,000 - $32,000           1\n",
       "$26,000 - $28,000           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Cars Prices\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\2393276654.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_clean = df_clean[~df[col].astype(str).str.contains(\"-\")]\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\2393276654.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_clean = df_clean[~df[col].astype(str).str.contains(\"\\x96\")]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Cars Prices\n",
       "35000.0       36\n",
       "30000.0       32\n",
       "50000.0       31\n",
       "55000.0       29\n",
       "45000.0       28\n",
       "25000.0       28\n",
       "40000.0       27\n",
       "28000.0       22\n",
       "60000.0       22\n",
       "70000.0       17\n",
       "20000.0       15\n",
       "18000.0       15\n",
       "85000.0       14\n",
       "32000.0       13\n",
       "22000.0       12\n",
       "38000.0       11\n",
       "52000.0        9\n",
       "36000.0        9\n",
       "42000.0        9\n",
       "27000.0        8\n",
       "33000.0        8\n",
       "65000.0        8\n",
       "75000.0        7\n",
       "44000.0        7\n",
       "15000.0        7\n",
       "23000.0        7\n",
       "48000.0        7\n",
       "95000.0        6\n",
       "90000.0        6\n",
       "47000.0        5\n",
       "29000.0        5\n",
       "39000.0        5\n",
       "80000.0        5\n",
       "37000.0        5\n",
       "31000.0        5\n",
       "62000.0        5\n",
       "12000.0        5\n",
       "46000.0        5\n",
       "49000.0        4\n",
       "19000.0        4\n",
       "24000.0        4\n",
       "14500.0        4\n",
       "110000.0       4\n",
       "120000.0       4\n",
       "53000.0        4\n",
       "18500.0        4\n",
       "100000.0       4\n",
       "1100000.0      4\n",
       "22500.0        4\n",
       "58000.0        4\n",
       "26000.0        4\n",
       "220000.0       3\n",
       "28500.0        3\n",
       "157000.0       3\n",
       "170000.0       3\n",
       "18400.0        3\n",
       "3300000.0      3\n",
       "78000.0        3\n",
       "14000.0        3\n",
       "23500.0        3\n",
       "42500.0        2\n",
       "105000.0       2\n",
       "51000.0        2\n",
       "16000.0        2\n",
       "25500.0        2\n",
       "287000.0       2\n",
       "190000.0       2\n",
       "130000.0       2\n",
       "92000.0        2\n",
       "10000.0        2\n",
       "421000.0       2\n",
       "545000.0       2\n",
       "258000.0       2\n",
       "573000.0       2\n",
       "11000.0        2\n",
       "222000.0       2\n",
       "43900.0        2\n",
       "113000.0       2\n",
       "64100.0        2\n",
       "34500.0        2\n",
       "43500.0        2\n",
       "28795.0        2\n",
       "45500.0        2\n",
       "41500.0        2\n",
       "56995.0        2\n",
       "65895.0        2\n",
       "82000.0        2\n",
       "142000.0       2\n",
       "350000.0       2\n",
       "280000.0       2\n",
       "17500.0        2\n",
       "116000.0       2\n",
       "330000.0       2\n",
       "360000.0       2\n",
       "109000.0       2\n",
       "500000.0       2\n",
       "114000.0       2\n",
       "77000.0        2\n",
       "54000.0        2\n",
       "63000.0        2\n",
       "15500.0        2\n",
       "150000.0       2\n",
       "38400.0        2\n",
       "26400.0        2\n",
       "41400.0        2\n",
       "33400.0        2\n",
       "15400.0        2\n",
       "43400.0        2\n",
       "56000.0        2\n",
       "20400.0        2\n",
       "41000.0        2\n",
       "43000.0        2\n",
       "68000.0        2\n",
       "34000.0        2\n",
       "35500.0        2\n",
       "57000.0        2\n",
       "4500000.0      2\n",
       "240000.0       2\n",
       "73305.0        1\n",
       "79560.0        1\n",
       "460000.0       1\n",
       "161000.0       1\n",
       "253290.0       1\n",
       "499000.0       1\n",
       "193440.0       1\n",
       "311000.0       1\n",
       "38600.0        1\n",
       "93800.0        1\n",
       "72200.0        1\n",
       "53800.0        1\n",
       "36500.0        1\n",
       "66800.0        1\n",
       "72800.0        1\n",
       "274000.0       1\n",
       "518000.0       1\n",
       "2800000.0      1\n",
       "1300000.0      1\n",
       "294000.0       1\n",
       "189000.0       1\n",
       "208000.0       1\n",
       "316000.0       1\n",
       "3200000.0      1\n",
       "52400.0        1\n",
       "39900.0        1\n",
       "37400.0        1\n",
       "27100.0        1\n",
       "26700.0        1\n",
       "26350.0        1\n",
       "26500.0        1\n",
       "29400.0        1\n",
       "165000.0       1\n",
       "59000.0        1\n",
       "64000.0        1\n",
       "86000.0        1\n",
       "96000.0        1\n",
       "101000.0       1\n",
       "194000.0       1\n",
       "439000.0       1\n",
       "41450.0        1\n",
       "19950.0        1\n",
       "40799.0        1\n",
       "49500.0        1\n",
       "25390.0        1\n",
       "58500.0        1\n",
       "31100.0        1\n",
       "14400.0        1\n",
       "11400.0        1\n",
       "10400.0        1\n",
       "16400.0        1\n",
       "12400.0        1\n",
       "24400.0        1\n",
       "49400.0        1\n",
       "40400.0        1\n",
       "44150.0        1\n",
       "495000.0       1\n",
       "349000.0       1\n",
       "335000.0       1\n",
       "475000.0       1\n",
       "381000.0       1\n",
       "398000.0       1\n",
       "108000.0       1\n",
       "146000.0       1\n",
       "69000.0        1\n",
       "44640.0        1\n",
       "31965.0        1\n",
       "59995.0        1\n",
       "39735.0        1\n",
       "21995.0        1\n",
       "28505.0        1\n",
       "30500.0        1\n",
       "58950.0        1\n",
       "41820.0        1\n",
       "16700.0        1\n",
       "83000.0        1\n",
       "76000.0        1\n",
       "133000.0       1\n",
       "200000.0       1\n",
       "71000.0        1\n",
       "99000.0        1\n",
       "389000.0       1\n",
       "375000.0       1\n",
       "515000.0       1\n",
       "401000.0       1\n",
       "418000.0       1\n",
       "369000.0       1\n",
       "355000.0       1\n",
       "332000.0       1\n",
       "342000.0       1\n",
       "1000000.0      1\n",
       "600000.0       1\n",
       "67000.0        1\n",
       "185000.0       1\n",
       "61750.0        1\n",
       "98000.0        1\n",
       "175000.0       1\n",
       "41750.0        1\n",
       "45790.0        1\n",
       "65300.0        1\n",
       "42820.0        1\n",
       "24960.0        1\n",
       "13000.0        1\n",
       "70600.0        1\n",
       "50995.0        1\n",
       "38195.0        1\n",
       "46595.0        1\n",
       "34395.0        1\n",
       "115000.0       1\n",
       "102000.0       1\n",
       "180000.0       1\n",
       "88000.0        1\n",
       "104000.0       1\n",
       "320000.0       1\n",
       "380000.0       1\n",
       "340000.0       1\n",
       "450000.0       1\n",
       "390000.0       1\n",
       "370000.0       1\n",
       "325000.0       1\n",
       "245000.0       1\n",
       "293200.0       1\n",
       "135500.0       1\n",
       "145300.0       1\n",
       "223800.0       1\n",
       "207000.0       1\n",
       "184100.0       1\n",
       "157300.0       1\n",
       "137000.0       1\n",
       "113300.0       1\n",
       "129900.0       1\n",
       "106100.0       1\n",
       "136700.0       1\n",
       "90500.0        1\n",
       "139400.0       1\n",
       "94800.0        1\n",
       "82295.0        1\n",
       "7200.0         1\n",
       "7000.0         1\n",
       "79295.0        1\n",
       "6500.0         1\n",
       "9400.0         1\n",
       "5000.0         1\n",
       "6200.0         1\n",
       "4000.0         1\n",
       "9200.0         1\n",
       "11800.0        1\n",
       "11300.0        1\n",
       "8200.0         1\n",
       "233000.0       1\n",
       "191300.0       1\n",
       "750000.0       1\n",
       "38775.0        1\n",
       "28345.0        1\n",
       "31590.0        1\n",
       "37695.0        1\n",
       "43530.0        1\n",
       "41530.0        1\n",
       "42100.0        1\n",
       "35195.0        1\n",
       "50490.0        1\n",
       "47490.0        1\n",
       "98490.0        1\n",
       "53240.0        1\n",
       "40240.0        1\n",
       "88490.0        1\n",
       "16500.0        1\n",
       "10500.0        1\n",
       "211000.0       1\n",
       "493000.0       1\n",
       "261000.0       1\n",
       "48595.0        1\n",
       "44195.0        1\n",
       "37490.0        1\n",
       "82495.0        1\n",
       "41295.0        1\n",
       "66575.0        1\n",
       "51570.0        1\n",
       "44500.0        1\n",
       "46500.0        1\n",
       "50695.0        1\n",
       "59865.0        1\n",
       "91495.0        1\n",
       "63595.0        1\n",
       "59990.0        1\n",
       "57095.0        1\n",
       "51095.0        1\n",
       "41390.0        1\n",
       "60495.0        1\n",
       "104595.0       1\n",
       "149990.0       1\n",
       "58590.0        1\n",
       "253000.0       1\n",
       "603000.0       1\n",
       "273000.0       1\n",
       "327000.0       1\n",
       "263000.0       1\n",
       "242000.0       1\n",
       "308000.0       1\n",
       "445000.0       1\n",
       "50895.0        1\n",
       "55895.0        1\n",
       "61595.0        1\n",
       "67300.0        1\n",
       "33500.0        1\n",
       "23100.0        1\n",
       "27495.0        1\n",
       "42795.0        1\n",
       "30695.0        1\n",
       "59900.0        1\n",
       "26600.0        1\n",
       "35915.0        1\n",
       "16720.0        1\n",
       "14595.0        1\n",
       "41290.0        1\n",
       "64990.0        1\n",
       "36100.0        1\n",
       "37200.0        1\n",
       "14395.0        1\n",
       "33900.0        1\n",
       "82400.0        1\n",
       "29200.0        1\n",
       "75700.0        1\n",
       "28400.0        1\n",
       "24100.0        1\n",
       "17595.0        1\n",
       "25800.0        1\n",
       "43700.0        1\n",
       "65900.0        1\n",
       "48900.0        1\n",
       "46600.0        1\n",
       "48295.0        1\n",
       "37100.0        1\n",
       "36900.0        1\n",
       "61100.0        1\n",
       "57400.0        1\n",
       "36800.0        1\n",
       "29900.0        1\n",
       "65500.0        1\n",
       "76700.0        1\n",
       "71600.0        1\n",
       "66700.0        1\n",
       "62495.0        1\n",
       "31700.0        1\n",
       "64400.0        1\n",
       "56400.0        1\n",
       "34900.0        1\n",
       "31900.0        1\n",
       "1700000.0      1\n",
       "56505.0        1\n",
       "84910.0        1\n",
       "64695.0        1\n",
       "59140.0        1\n",
       "79420.0        1\n",
       "29365.0        1\n",
       "43455.0        1\n",
       "5800000.0      1\n",
       "125000.0       1\n",
       "76805.0        1\n",
       "28700.0        1\n",
       "36300.0        1\n",
       "72000.0        1\n",
       "71505.0        1\n",
       "54300.0        1\n",
       "32500.0        1\n",
       "81000.0        1\n",
       "3500000.0      1\n",
       "160000.0       1\n",
       "5000000.0      1\n",
       "18000000.0     1\n",
       "9000000.0      1\n",
       "210000.0       1\n",
       "230000.0       1\n",
       "3000000.0      1\n",
       "20500.0        1\n",
       "51500.0        1\n",
       "39500.0        1\n",
       "17000.0        1\n",
       "37700.0        1\n",
       "53900.0        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "col = \"Cars Prices\"\n",
    "\n",
    "# Keep only entries that do NOT contain \"-\" (ignore ranges)\n",
    "df_clean = df[(df[col].astype(str).str.len() < 13) & (df[col].astype(str).str.len() >1) ]\n",
    "df_clean = df_clean[~df[col].astype(str).str.contains(\"-\")]\n",
    "df_clean = df_clean[~df[col].astype(str).str.contains(\"\\x96\")]\n",
    "\n",
    "# Remove $ and commas, convert to numeric\n",
    "df_clean[col] = df_clean[col].str.replace(\"$\", \"\").str.replace(\",\", \"\").astype(float)\n",
    "df_clean.head()\n",
    "df_clean[col].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seats\n",
       "5       640\n",
       "7       146\n",
       "4       132\n",
       "2       120\n",
       "8        28\n",
       "6        18\n",
       "3        14\n",
       "2+2       5\n",
       "1         3\n",
       "12        1\n",
       "9         1\n",
       "215      1\n",
       "27       1\n",
       "78       1\n",
       "29       1\n",
       "212      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Seats\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Seats\"].astype(str).str.isdigit()]\n",
    "df[\"Seats\"] = df[\"Seats\"].astype(int)\n",
    "df = df[df[\"Seats\"].between(1, 20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here now we can see the data in new columns with their new shape and without odd values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Total Speed in km/h  CC/Battery Capacity in cc  HorsePower  Seats  \\\n",
      "0                340.0                     3990.0       963.0      2   \n",
      "1                250.0                     6749.0       563.0      5   \n",
      "3                250.0                        3.0       630.0      4   \n",
      "4                320.0                        5.0       602.0      2   \n",
      "5                341.0                        3.0       710.0      2   \n",
      "\n",
      "   Performance(0 - 100 )KM/H  Torque  Cars Prices  \n",
      "0                        2.5     800    1100000.0  \n",
      "1                        5.3     900     460000.0  \n",
      "3                        3.2     900     161000.0  \n",
      "4                        3.6     560     253290.0  \n",
      "5                        2.9     770     499000.0  \n",
      "Seats\n",
      "5     640\n",
      "7     146\n",
      "4     132\n",
      "2     120\n",
      "8      28\n",
      "6      18\n",
      "3      14\n",
      "1       3\n",
      "12      1\n",
      "9       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "data[\"Total Speed in km/h\"] = df[\"Total Speed\"].str.extract(r\"([0-9]+)\")\n",
    "data[\"Total Speed in km/h\"] = data[\"Total Speed in km/h\"].astype(float)\n",
    "data[\"CC/Battery Capacity in cc\"] =  df[\"CC/Battery Capacity\"].str.extract(r\"([0-9]+)\")\n",
    "data[\"CC/Battery Capacity in cc\"] = data[\"CC/Battery Capacity in cc\"].astype(float)\n",
    "\n",
    "data[\"HorsePower\"] =  df[\"HorsePower\"].str.extract(r\"([0-9]+)\")\n",
    "data[\"HorsePower\"] = data[\"HorsePower\"].astype(float)\n",
    "\n",
    "data[\"Seats\"] = df[\"Seats\"]\n",
    "data[\"Performance(0 - 100 )KM/H\"] = df[\"Performance(0 - 100 )KM/H\"]\n",
    "data[\"Torque\"] = df[\"Torque\"]\n",
    "data[\"Cars Prices\"] = df_clean[\"Cars Prices\"]\n",
    "\n",
    "\n",
    "# Check the result\n",
    "print(data.head())\n",
    "print(df[\"Seats\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All that was for the numeric data, we have to do the same for the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['CC/Battery Capacity',\t'HorsePower',\t'Total Speed',\t'Performance(0 - 100 )KM/H',\t'Cars Prices', 'Seats',\t'Torque'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Names</th>\n",
       "      <th>Cars Names</th>\n",
       "      <th>Engines</th>\n",
       "      <th>Fuel Types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1103</td>\n",
       "      <td>1103</td>\n",
       "      <td>1103</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>37</td>\n",
       "      <td>1092</td>\n",
       "      <td>304</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>NX Coupe</td>\n",
       "      <td>I4</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Company Names Cars Names Engines Fuel Types\n",
       "count           1103       1103    1103       1103\n",
       "unique            37       1092     304         17\n",
       "top           Nissan   NX Coupe      I4     Petrol\n",
       "freq             148          2      63        815"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fuel Types\n",
       "Petrol                     815\n",
       "Diesel                      96\n",
       "Electric                    73\n",
       "Hybrid                      70\n",
       "Petrol/Hybrid               14\n",
       "Petrol/Diesel               11\n",
       "Plug-in Hybrid               5\n",
       "Hybrid (Petrol)              4\n",
       "Petrol, Diesel               3\n",
       "Hydrogen                     3\n",
       "Petrol/AWD                   2\n",
       "Petrol, Hybrid               2\n",
       "plug in hyrbrid              1\n",
       "Hybrid/Electric              1\n",
       "Diesel/Petrol                1\n",
       "CNG/Petrol                   1\n",
       "Hybrid (Gas + Electric)      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Fuel Types'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"Fuel Types\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the cardinality is super big 1094 we will remove the column \n",
    "df = df.drop(columns=['Cars Names'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I used ChatGPT to generate the mapping list that i use to replace the columns, i used it because beside some odd tips i find on internet, i didn't know how to clean it well. To check that it was good i just had to compare it to the original columns and check how many data was in there now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuel Types\n",
      "Petrol             815\n",
      "Diesel              96\n",
      "Hybrid              77\n",
      "Electric            73\n",
      "Petrol/Hybrid       20\n",
      "Petrol/Diesel       15\n",
      "Hydrogen             3\n",
      "Petrol/AWD           2\n",
      "Hybrid/Electric      1\n",
      "CNG/Petrol           1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Fuel Types\"] = df[\"Fuel Types\"].str.strip().str.title()\n",
    "\n",
    "mapping = {\n",
    "    \"Plug-In Hybrid\": \"Hybrid\",\n",
    "    \"Plug In Hyrbrid\": \"Hybrid\",\n",
    "    \"Hybrid (Petrol)\": \"Petrol/Hybrid\",\n",
    "    \"Hybrid (Gas + Electric)\": \"Hybrid\",\n",
    "    \"Petrol/Hybrid\": \"Petrol/Hybrid\",\n",
    "    \"Petrol/Diesel\": \"Petrol/Diesel\",\n",
    "    \"Petrol, Hybrid\" : \"Petrol/Hybrid\",\n",
    "    \"Petrol, Diesel\": \"Petrol/Diesel\",\n",
    "    \"Hybrid/Electric\": \"Hybrid/Electric\",\n",
    "    \"Diesel/Petrol\": \"Petrol/Diesel\",\n",
    "    \"Cng/Petrol\": \"CNG/Petrol\",\n",
    "    \"Petrol/Awd\": \"Petrol/AWD\",\n",
    "}\n",
    "\n",
    "\n",
    "data[\"Fuel Types\"] = data[\"Fuel Types\"].replace(mapping)\n",
    "\n",
    "print(data[\"Fuel Types\"].value_counts())\n",
    "len(data[\"Fuel Types\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engines\n",
       "I4                                     63\n",
       "V12                                    51\n",
       "V6                                     39\n",
       "Inline-4                               38\n",
       "V8                                     30\n",
       "2.0L Inline-4                          20\n",
       "1.6L Inline-4                          19\n",
       "Electric Motor                         17\n",
       "5.6L V8                                17\n",
       "5.3L V8 Gasoline                       16\n",
       "2.0L I4 Turbo                          15\n",
       "Electric                               15\n",
       "Dual Electric Motors                   15\n",
       "6.2L V8 Gasoline                       15\n",
       "2.0L Turbo I4                          14\n",
       "1.8L Inline-4                          13\n",
       "3.6L V6 Gasoline                       12\n",
       "I4 Petrol                              12\n",
       "I3                                     12\n",
       "V10                                    11\n",
       "3.5L V6                                11\n",
       "2.0L 4-Cylinder                        11\n",
       "8.0L Quad-Turbo W16                    10\n",
       "3.0L Twin-Turbo Flat-6                 10\n",
       "3.8L V6                                 9\n",
       "I6                                      9\n",
       "1.6L Turbocharged 4-Cylinder            9\n",
       "1.5L Inline-4                           9\n",
       "3.0L V6                                 8\n",
       "3.0L Twin-Turbo V6                      8\n",
       "I4 Petrol / V6 Petrol                   8\n",
       "V8 Petrol                               8\n",
       "2.0L Turbo Inline-4 Gasoline            8\n",
       "2.0L Diesel I4                          8\n",
       "2.9L V6 Twin Turbo                      8\n",
       "Hybrid I4                               7\n",
       "3.6L V6 engine                          7\n",
       "2.0L Turbo Inline-4                     7\n",
       "2.4L Diesel Turbo                       7\n",
       "2.0L MIVEC                              7\n",
       "2.5L 4-Cylinder                         7\n",
       "1.5L Turbo Inline-4 Gasoline            6\n",
       "Single Electric Motor                   6\n",
       "2.5L V6                                 6\n",
       "5.3L V8 engine                          6\n",
       "6.2L V8 engine                          6\n",
       "2.5L Inline-4                           6\n",
       "6.6L V8 engine                          6\n",
       "6.6L V8 Diesel                          6\n",
       "3.8L Twin-Turbo Flat-6                  5\n",
       "3.8L Twin-Turbo V6                      5\n",
       "2.0L SkyActiv-G                         5\n",
       "1.2L MIVEC                              5\n",
       "Electric (Dual Motor)                   5\n",
       "3.6L V6 Pentastar Gasoline              5\n",
       "0.7L 3-Cylinder                         5\n",
       "Permanent Magnet Synchronous            5\n",
       "ELECTRIC MOTOR                          4\n",
       "2.5L SkyActiv-G                         4\n",
       "4.0L Naturally Aspirated Flat-6         4\n",
       "4.0L V8 Twin Turbo                      4\n",
       "1.2L Revotron 3-cylinder Petrol         4\n",
       "12.8L I6 Turbo Diesel                   4\n",
       "1.0L Turbocharged Inline-3              4\n",
       "3.0L V6 Turbo                           4\n",
       "Hybrid I4 + Electric Motor              4\n",
       "1.6L 4-Cylinder                         4\n",
       "2.7L Turbo 4-cylinder                   4\n",
       "1.6L Hybrid Turbocharged 4-Cylinder     4\n",
       "1.4L I4 Turbo + Electric Motor          4\n",
       "1.6L 4-Cylinder Hybrid                  4\n",
       "Turbocharged V6                         4\n",
       "V6 Petrol                               4\n",
       "Twin-Turbo V6 Hybrid                    4\n",
       "1.5L Turbo I4                           4\n",
       "3.2L Diesel Turbo                       4\n",
       "660cc Inline-3                          4\n",
       "2.5L Turbocharged 4-Cylinder            3\n",
       "I4 + ELECTRIC                           3\n",
       "1.2L,4-CYLINDER,INLINE-4(I4)            3\n",
       "Diesel I4                               3\n",
       "1.4L CR4 Diesel                         3\n",
       "2.5L Turbocharged                       3\n",
       "1.3L Inline-4                           3\n",
       "1.5L Turbo Inline-3                     3\n",
       "1.5L Turbocharged I4 engine             3\n",
       "2.5L Inline-4 Diesel                    3\n",
       "2.4L Inline-4                           3\n",
       "1.3L Inline-2 (Wankel)                  3\n",
       "2.7L Turbo Inline-4 Gasoline            3\n",
       "6.2L Supercharged V8 Gasoline           3\n",
       "1.4L Inline-4 Gasoline                  3\n",
       "3.7L V6                                 3\n",
       "4.5L V8                                 3\n",
       "I4 Turbocharged                         3\n",
       "2.0L Turbo Diesel I4                    3\n",
       "3.3L V6                                 3\n",
       "2.8L,TURBO,DIESEL                       3\n",
       "1.2L Diesel I3                          3\n",
       "4.0L V6                                 3\n",
       "Dual Electric Motors (AWD)              3\n",
       "1.5L Turbo 4-cylinder                   3\n",
       "2.0L,4-CYLINDER,INLINE-4(I4)            2\n",
       "ELECTRIC                                2\n",
       "1.5L Turbo                              2\n",
       "1.8L MIVEC                              2\n",
       "1.5L MIVEC                              2\n",
       "1.2L I4 Turbo / 2.0L I4 Turbo           2\n",
       "4.3L V6 Gasoline                        2\n",
       "1.5L Inline-4 Diesel                    2\n",
       "13.0L I6 Turbo Diesel                   2\n",
       "V6 Hybrid                               2\n",
       "1.5L I4 Turbo / 2.0L Diesel             2\n",
       "4.0L V8 Turbo Diesel                    2\n",
       "1.0L I3 Turbo / 1.5L I4 Turbo           2\n",
       "1.8L I4 Gas                             2\n",
       "1.0L I3 Turbo                           2\n",
       "2.2L,4-CYLINDER,INLINE-4(I4)            2\n",
       "I4 Hybrid                               2\n",
       "3.5L Twin-Turbo V6                      2\n",
       "3.0L V6 Turbo Diesel                    2\n",
       "V8 Gasoline Engine                      2\n",
       "Turbocharged Inline-4                   2\n",
       "3.0L V6 Twin-Turbo                      2\n",
       "1.5L Turbo Hybrid                       2\n",
       "2.3L Inline-4 Diesel                    2\n",
       "5.0L V8                                 2\n",
       "4.8L Inline-6                           2\n",
       "2.5L I4 engine                          2\n",
       "2.2L Dicor Diesel                       2\n",
       "2.0L Turbo PHEV                         2\n",
       "1.3L Turbo PHEV                         2\n",
       "4.0L V8 + Electric Motor                2\n",
       "2.9L V6 + Electric Motor                2\n",
       "2.4L Inline-6                           2\n",
       "3.0L Inline-4 Diesel                    2\n",
       "Single Electric Motor (RWD)             2\n",
       "2.0L Kryotec Turbocharged Diesel        2\n",
       "1.3L Wankel + Electric                  2\n",
       "1.3L Wankel Rotary Engine               2\n",
       "2.4L Turbo I4 (i-FORCE MAX Hybrid)      1\n",
       "2.5L Hybrid I4                          1\n",
       "2.6L Wankel Rotary Engine               1\n",
       "0.66L Inline-3                          1\n",
       "0.36L Inline-2                          1\n",
       "1.0L Inline-2 (Wankel)                  1\n",
       "1.6L Inline-2 (Wankel)                  1\n",
       "1.2L Inline-4                           1\n",
       "3.0L Inline-6                           1\n",
       "3.0L Inline-4                           1\n",
       "2.6L Inline-4                           1\n",
       "657cc Turbocharged Inline-3             1\n",
       "1.8L Rotary                             1\n",
       "1.3L Rotary                             1\n",
       "2.0L Twin-Rotor Turbo                   1\n",
       "2.3L Miller Cycle V6                    1\n",
       "1.5L SkyActiv-G                         1\n",
       "1.2L Rotary                             1\n",
       "1.3L Rotary Twin-Turbo                  1\n",
       "3.2L Turbo Diesel                       1\n",
       "2.5L Diesel                             1\n",
       "2.3L Turbocharged                       1\n",
       "3.3L Inline-6 Turbo                     1\n",
       "2.2L Diesel                             1\n",
       "1.5L Turbocharged                       1\n",
       "1.4L MPFI Petrol                        1\n",
       "1.2L MPFI Petrol                        1\n",
       "624cc MPFI                              1\n",
       "1.2L Revotron Bi-Fuel                   1\n",
       "1.2L Turbocharged Petrol                1\n",
       "4.2L Naturally Aspirated Flat-6         1\n",
       "3.0L Twin-Turbo V6 Gasoline             1\n",
       "3.0L Flat-6 Twin Turbo                  1\n",
       "1.8L Turbo Inline-4                     1\n",
       "2.8L Inline-6                           1\n",
       "4.1L V8                                 1\n",
       "4.2L Inline-6                           1\n",
       "2.7L Turbo Diesel                       1\n",
       "1.2L Hybrid                             1\n",
       "1.5L Hybrid                             1\n",
       "1.5L 4-Cylinder                         1\n",
       "6.4L V8 Gasoline                        1\n",
       "5.7L V8 Gasoline with eTorque           1\n",
       "1.3L Turbo I4 Gasoline                  1\n",
       "2.0L Turbo Gasoline                     1\n",
       "2.4L I4 Tigershark Gasoline             1\n",
       "2.0L Turbo I4 Gasoline                  1\n",
       "3.0L CR4 Diesel                         1\n",
       "2.2L Varicor Diesel                     1\n",
       "1.2L Revotron Petrol                    1\n",
       "1.0L Turbo Inline-4                     1\n",
       "3.5L Twin-Turbo V8                      1\n",
       "3.0L Twin-Turbo V6 Hybrid               1\n",
       "2.7L Inline-4 Diesel                    1\n",
       "2.8L Inline-6 Diesel                    1\n",
       "1.4L Inline-4                           1\n",
       "2.0L VC-Turbo Inline-4                  1\n",
       "2.6L Twin-Turbo Inline-6                1\n",
       "1.6L Turbo Inline-4                     1\n",
       "1.2L Turbo Inline-3 Gasoline            1\n",
       "2.8L Turbo Diesel I4                    1\n",
       "1.3L Turbo Inline-3 Gasoline            1\n",
       "6.6L V8 Gasoline                        1\n",
       "1.4L Turbo Inline-4 Gasoline            1\n",
       "3.6L Twin-Turbo V6 Gasoline             1\n",
       "6.4L V8 HEMI Gasoline                   1\n",
       "3.2L V6 Pentastar Gasoline              1\n",
       "5.7L V8 Gasoline                        1\n",
       "1.3L Turbo Hybrid Inline-4              1\n",
       "2.5L Inline-4 Hybrid                    1\n",
       "2.0L Inline-6                           1\n",
       "2.0L Inline-4 Hybrid                    1\n",
       "1.2L Inline-3                           1\n",
       "1.2L Turbocharged Inline-4              1\n",
       "4.3L V6 engine                          1\n",
       "2.7L Turbo engine                       1\n",
       "2.0L Turbo 4-cylinder                   1\n",
       "2.5L Inline-4 Gasoline                  1\n",
       "1.2L Inline-3 Hybrid                    1\n",
       "1.5L Turbocharged Inline-3              1\n",
       "1.3L Turbocharged Inline-4              1\n",
       "3.0L V6 Turbo Diesel / Gasoline         1\n",
       "1.4L I4 Turbo / 2.0L Diesel I4          1\n",
       "1.5L I4 CNG                             1\n",
       "Plug-in Hybrid (0.8L I2 Diesel)         1\n",
       "1.6L Turbocharged Rally Engine          1\n",
       "V6 / V8 Petrol                          1\n",
       "5.1L I4 Turbo Diesel                    1\n",
       "7.7L I6 Turbo Diesel                    1\n",
       "16.1L I6 Turbo Diesel                   1\n",
       "Hybrid I4+ Electric Motor               1\n",
       "2.5L Hybrid Turbocharged 4-Cylinder     1\n",
       "3.3L Turbocharged V6                    1\n",
       "1.6L Diesel / 2.0L I4 Turbo             1\n",
       "3.2L VR6                                1\n",
       "1.4L I4 Turbo                           1\n",
       "Plug-in Hybrid (1.4L I4 Turbo)          1\n",
       "1.4L I4 Diesel / 1.6L Diesel            1\n",
       "2.0L I4 Turbo Diesel                    1\n",
       "1.5L I4 Turbo                           1\n",
       "2.0L I4 Turbo / 3.6L V6 Gas             1\n",
       "1.6L I4 Gas / 1.9L I4 Diesel            1\n",
       "1.6L I4 Gas / Diesel                    1\n",
       "3.3L V6 + Electric                      1\n",
       "Turbocharged I4                         1\n",
       "Inline-4 Turbocharged                   1\n",
       "Inline-4 Hybrid                         1\n",
       "I4 Petrol + Electric Motor              1\n",
       "1.2L I4 Gas / 1.4L I4 Gas               1\n",
       "1.2L I4 Gas                             1\n",
       "1.4L I4 Gas / 1.6L I4 Gas               1\n",
       "1.5L I4 Gas                             1\n",
       "3.0L V6 Diesel / 6.0L W12 Gas           1\n",
       "2.9L VR6                                1\n",
       "1.4L I3 Gas / 1.2L Diesel I3            1\n",
       "1.5L Turbo I4 / 2.0L Diesel I4          1\n",
       "Electric AWD                            1\n",
       "Plug-in Hybrid / Diesel I4              1\n",
       "Plug-in Hybrid V6                       1\n",
       "1.0L Turbo I3 / 1.5L Turbo I4           1\n",
       "1.0L Turbo I3                           1\n",
       "V6 Turbocharged                         1\n",
       "V6 EcoBoost                             1\n",
       "I4 Turbo Diesel                         1\n",
       "V6 Hybrid + Electric Motor              1\n",
       "EcoBlue Turbo Diesel                    1\n",
       "Naturally Aspirated V8                  1\n",
       "Supercharged V8                         1\n",
       "Naturally Aspirated V6                  1\n",
       "Turbocharged Inline-3                   1\n",
       "2.7L Twin-Turbo V6                      1\n",
       "2.3L Turbo Inline-4                     1\n",
       "3.0L V6 Turbo Diesel / 4.0L V8          1\n",
       "1.0L Turbo I3 / 1.6L Diesel             1\n",
       "1.5L Turbo I4 / Electric                1\n",
       "1.6L Turbo GDI 4-cylinder               1\n",
       "2.5L Turbocharged Inline-4              1\n",
       "2.4L 4-Cylinder                         1\n",
       "2.4L Petrol                             1\n",
       "2.4L PHEV                               1\n",
       "1.6L MIVEC                              1\n",
       "2.0L Diesel / 2.2L Diesel               1\n",
       "2.4L MIVEC                              1\n",
       "2.2L Diesel Turbo                       1\n",
       "2.0L Turbocharged                       1\n",
       "2.4L Hybrid                             1\n",
       "1.6L PETROL + PLUG IN HYBRID SYSTEM     1\n",
       "1.6L,TURBOCHARGED INLINE-3              1\n",
       "1.8L,HYBRID                             1\n",
       "3.5L,V6,PLUG IN HYBRID                  1\n",
       "1.0L,INLINE-3                           1\n",
       "1.5L,HYBRID                             1\n",
       "2.0L HYBRID                             1\n",
       "2.5L,INLINE-4,HYBRID,OR 3.5L,V6         1\n",
       "HYDROGEN FUEL CELL,ELECTRIC MOTOR       1\n",
       "2.0L,INLINE-4                           1\n",
       "3.5L,V6,HYBRID TWIN-TURBO               1\n",
       "3.3L,V6,TWIN TURBO DIESEL               1\n",
       "2.0L,4-CYLINDER,WITH HYBRID SYSTEM      1\n",
       "1.5L,4-CYLINDER,INLINE(I4)              1\n",
       "1.4L,4-CYLINDER,INLINE-4(I4)            1\n",
       "HYBRID                                  1\n",
       "ELECTRIC                                1\n",
       "BOXER-4                                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Engines\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"Engines\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engines\n",
      "I4                                     219\n",
      "V6                                      64\n",
      "V12                                     51\n",
      "V8                                      49\n",
      "Electric                                35\n",
      "I3                                      28\n",
      "Hybrid                                  23\n",
      "Electric Motor                          21\n",
      "5.3L V8 Gasoline                        16\n",
      "6.2L V8 Gasoline                        15\n",
      "Dual Electric Motors                    15\n",
      "Flat-6                                  14\n",
      "I6                                      13\n",
      "3.6L V6 Gasoline                        12\n",
      "V10                                     11\n",
      "8.0L Quad-Turbo W16                     10\n",
      "1.5L Inline-4                            9\n",
      "1.6L Turbocharged 4-Cylinder             9\n",
      "2.0L Turbo Inline-4 Gasoline             8\n",
      "3.0L Twin-Turbo V6                       8\n",
      "2.9L V6 Twin Turbo                       8\n",
      "2.0L Diesel I4                           8\n",
      "3.0L V6                                  8\n",
      "V8 Petrol                                8\n",
      "I4 Petrol / V6 Petrol                    8\n",
      "3.6L V6 Engine                           7\n",
      "2.0L Turbo Inline-4                      7\n",
      "2.4L Diesel Turbo                        7\n",
      "2.5L 4-Cylinder                          7\n",
      "Hybrid I4                                7\n",
      "2.0L Mivec                               7\n",
      "5.3L V8 Engine                           6\n",
      "6.6L V8 Engine                           6\n",
      "6.6L V8 Diesel                           6\n",
      "1.5L Turbo Inline-4 Gasoline             6\n",
      "2.5L V6                                  6\n",
      "6.2L V8 Engine                           6\n",
      "3.8L Twin-Turbo Flat-6                   5\n",
      "3.8L Twin-Turbo V6                       5\n",
      "2.0L Skyactiv-G                          5\n",
      "1.2L Mivec                               5\n",
      "3.6L V6 Pentastar Gasoline               5\n",
      "Permanent Magnet Synchronous             5\n",
      "2.5L Skyactiv-G                          4\n",
      "Turbocharged V6                          4\n",
      "12.8L I6 Turbo Diesel                    4\n",
      "3.2L Diesel Turbo                        4\n",
      "3.0L V6 Turbo                            4\n",
      "1.4L I4 Turbo + Electric Motor           4\n",
      "1.5L Turbo I4                            4\n",
      "4.0L V8 Twin Turbo                       4\n",
      "1.6L Hybrid Turbocharged 4-Cylinder      4\n",
      "1.2L Revotron 3-Cylinder Petrol          4\n",
      "2.7L Turbo 4-Cylinder                    4\n",
      "2.7L Turbo Inline-4 Gasoline             3\n",
      "3.7L V6                                  3\n",
      "2.0L Turbo Diesel I4                     3\n",
      "1.2L Diesel I3                           3\n",
      "4.0L V6                                  3\n",
      "1.2L,4-Cylinder,Inline-4(I4)             3\n",
      "2.8L,Turbo,Diesel                        3\n",
      "3.3L V6                                  3\n",
      "I4 + Electric                            3\n",
      "2.5L Turbocharged 4-Cylinder             3\n",
      "1.5L Turbocharged I4 Engine              3\n",
      "1.4L Cr4 Diesel                          3\n",
      "1.5L Turbo 4-Cylinder                    3\n",
      "4.5L V8                                  3\n",
      "2.4L Inline-4                            3\n",
      "1.5L Turbo Inline-3                      3\n",
      "2.5L Inline-4 Diesel                     3\n",
      "1.3L Inline-2 (Wankel)                   3\n",
      "1.3L Inline-4                            3\n",
      "1.4L Inline-4 Gasoline                   3\n",
      "6.2L Supercharged V8 Gasoline            3\n",
      "Diesel I4                                3\n",
      "2.5L Turbocharged                        3\n",
      "3.0L Inline-4 Diesel                     2\n",
      "1.5L Turbo Hybrid                        2\n",
      "1.8L Mivec                               2\n",
      "1.3L Wankel + Electric                   2\n",
      "Rotary                                   2\n",
      "V8 Gasoline Engine                       2\n",
      "Turbocharged Inline-4                    2\n",
      "3.5L Twin-Turbo V6                       2\n",
      "1.3L Wankel Rotary Engine                2\n",
      "1.3L Turbo Phev                          2\n",
      "1.5L Mivec                               2\n",
      "1.5L Turbo                               2\n",
      "4.3L V6 Gasoline                         2\n",
      "13.0L I6 Turbo Diesel                    2\n",
      "2.0L Turbo Phev                          2\n",
      "2.2L Dicor Diesel                        2\n",
      "2.0L Kryotec Turbocharged Diesel         2\n",
      "2.5L I4 Engine                           2\n",
      "5.0L V8                                  2\n",
      "3.0L V6 Twin-Turbo                       2\n",
      "1.8L I4 Gas                              2\n",
      "3.0L V6 Turbo Diesel                     2\n",
      "1.2L I4 Turbo / 2.0L I4 Turbo            2\n",
      "4.0L V8 Turbo Diesel                     2\n",
      "1.0L I3 Turbo / 1.5L I4 Turbo            2\n",
      "1.0L I3 Turbo                            2\n",
      "2.2L,4-Cylinder,Inline-4(I4)             2\n",
      "2.0L,4-Cylinder,Inline-4(I4)             2\n",
      "2.9L V6 + Electric Motor                 2\n",
      "1.5L Inline-4 Diesel                     2\n",
      "1.5L I4 Turbo / 2.0L Diesel              2\n",
      "2.4L Inline-6                            2\n",
      "2.3L Inline-4 Diesel                     2\n",
      "4.0L V8 + Electric Motor                 2\n",
      "1.4L I4 Diesel / 1.6L Diesel             1\n",
      "2.0L I4 Turbo Diesel                     1\n",
      "2.0L I4 Turbo / 3.6L V6 Gas              1\n",
      "1.5L I4 Turbo                            1\n",
      "1.6L I4 Gas / 1.9L I4 Diesel             1\n",
      "1.2L I4 Gas                              1\n",
      "1.2L I4 Gas / 1.4L I4 Gas                1\n",
      "1.6L I4 Gas / Diesel                     1\n",
      "1.5L I4 Gas                              1\n",
      "3.0L V6 Diesel / 6.0L W12 Gas            1\n",
      "1.4L,4-Cylinder,Inline-4(I4)             1\n",
      "Boxer                                    1\n",
      "3.3L,V6,Twin Turbo Diesel                1\n",
      "3.5L,V6,Hybrid Twin-Turbo                1\n",
      "2.0L,4-Cylinder,With Hybrid System       1\n",
      "1.5L,4-Cylinder,Inline(I4)               1\n",
      "4.2L Naturally Aspirated Flat-6          1\n",
      "3.0L Twin-Turbo V6 Gasoline              1\n",
      "3.0L Flat-6 Twin Turbo                   1\n",
      "1.8L Turbo Inline-4                      1\n",
      "4.1L V8                                  1\n",
      "4.2L Inline-6                            1\n",
      "2.7L Turbo Diesel                        1\n",
      "1.4L Inline-4                            1\n",
      "2.7L Inline-4 Diesel                     1\n",
      "2.8L Inline-6 Diesel                     1\n",
      "2.0L Vc-Turbo Inline-4                   1\n",
      "3.0L Twin-Turbo V6 Hybrid                1\n",
      "1.0L Turbo Inline-4                      1\n",
      "3.5L Twin-Turbo V8                       1\n",
      "1.5L Hybrid                              1\n",
      "1.2L Hybrid                              1\n",
      "1.2L Inline-3 Hybrid                     1\n",
      "1.5L Turbocharged Inline-3               1\n",
      "3.0L V6 Turbo Diesel / Gasoline          1\n",
      "1.3L Turbocharged Inline-4               1\n",
      "1.4L I4 Turbo / 2.0L Diesel I4           1\n",
      "1.5L I4 Cng                              1\n",
      "1.6L Diesel / 2.0L I4 Turbo              1\n",
      "1.6L Turbocharged Rally Engine           1\n",
      "1.4L I4 Turbo                            1\n",
      "3.2L Vr6                                 1\n",
      "1.2L Turbocharged Inline-4               1\n",
      "1.2L Inline-3                            1\n",
      "2.0L Inline-6                            1\n",
      "1.3L Turbo Hybrid Inline-4               1\n",
      "1.6L Turbo Inline-4                      1\n",
      "2.6L Twin-Turbo Inline-6                 1\n",
      "1.6L Petrol + Plug In Hybrid System      1\n",
      "1.6L,Turbocharged Inline-3               1\n",
      "1.8L,Hybrid                              1\n",
      "3.5L,V6,Plug In Hybrid                   1\n",
      "1.0L,Inline-3                            1\n",
      "1.5L,Hybrid                              1\n",
      "2.0L Hybrid                              1\n",
      "2.5L,Inline-4,Hybrid,Or 3.5L,V6          1\n",
      "Hydrogen                                 1\n",
      "2.0L,Inline-4                            1\n",
      "1.6L Turbo Gdi 4-Cylinder                1\n",
      "1.0L Turbo I3                            1\n",
      "3.0L V6 Turbo Diesel / 4.0L V8           1\n",
      "1.0L Turbo I3 / 1.6L Diesel              1\n",
      "1.5L Turbo I4 / Electric                 1\n",
      "2.5L Turbocharged Inline-4               1\n",
      "1.4L I3 Gas / 1.2L Diesel I3             1\n",
      "1.5L Turbo I4 / 2.0L Diesel I4           1\n",
      "Plug-In Hybrid V6                        1\n",
      "1.0L Turbo I3 / 1.5L Turbo I4            1\n",
      "1.4L I4 Gas / 1.6L I4 Gas                1\n",
      "2.9L Vr6                                 1\n",
      "1.4L Turbo Inline-4 Gasoline             1\n",
      "1.5L 4-Cylinder                          1\n",
      "2.0L Turbo Gasoline                      1\n",
      "3.6L Twin-Turbo V6 Gasoline              1\n",
      "3.2L V6 Pentastar Gasoline               1\n",
      "6.4L V8 Hemi Gasoline                    1\n",
      "5.7L V8 Gasoline                         1\n",
      "1.3L Turbo I4 Gasoline                   1\n",
      "6.4L V8 Gasoline                         1\n",
      "1.2L Mpfi Petrol                         1\n",
      "7.7L I6 Turbo Diesel                     1\n",
      "16.1L I6 Turbo Diesel                    1\n",
      "2.5L Hybrid Turbocharged 4-Cylinder      1\n",
      "Hybrid I4+ Electric Motor                1\n",
      "3.3L Turbocharged V6                     1\n",
      "4.3L V6 Engine                           1\n",
      "2.0L Turbo 4-Cylinder                    1\n",
      "2.7L Turbo Engine                        1\n",
      "1.2L Turbo Inline-3 Gasoline             1\n",
      "2.8L Turbo Diesel I4                     1\n",
      "1.3L Turbo Inline-3 Gasoline             1\n",
      "6.6L V8 Gasoline                         1\n",
      "2.5L Inline-4 Gasoline                   1\n",
      "624Cc Mpfi                               1\n",
      "1.2L Turbocharged Petrol                 1\n",
      "1.2L Revotron Bi-Fuel                    1\n",
      "2.0L Turbo I4 Gasoline                   1\n",
      "3.0L Cr4 Diesel                          1\n",
      "1.2L Revotron Petrol                     1\n",
      "2.2L Varicor Diesel                      1\n",
      "1.4L Mpfi Petrol                         1\n",
      "5.7L V8 Gasoline With Etorque            1\n",
      "2.4L I4 Tigershark Gasoline              1\n",
      "Inline-4 Hybrid                          1\n",
      "Naturally Aspirated V6                   1\n",
      "2.7L Twin-Turbo V6                       1\n",
      "2.3L Turbo Inline-4                      1\n",
      "3.3L V6 + Electric                       1\n",
      "5.1L I4 Turbo Diesel                     1\n",
      "I4 Petrol + Electric Motor               1\n",
      "Turbocharged I4                          1\n",
      "V6 / V8 Petrol                           1\n",
      "1.6L Mivec                               1\n",
      "2.0L Diesel / 2.2L Diesel                1\n",
      "2.4L Mivec                               1\n",
      "2.2L Diesel Turbo                        1\n",
      "2.0L Turbocharged                        1\n",
      "I4 Turbo Diesel                          1\n",
      "Ecoblue Turbo Diesel                     1\n",
      "2.4L Hybrid                              1\n",
      "V6 Turbocharged                          1\n",
      "2.2L Diesel                              1\n",
      "2.3L Turbocharged                        1\n",
      "3.3L Inline-6 Turbo                      1\n",
      "2.4L 4-Cylinder                          1\n",
      "2.4L Petrol                              1\n",
      "2.4L Phev                                1\n",
      "1.5L Turbocharged                        1\n",
      "1.5L Skyactiv-G                          1\n",
      "1.2L Rotary                              1\n",
      "1.3L Rotary Twin-Turbo                   1\n",
      "3.2L Turbo Diesel                        1\n",
      "2.5L Diesel                              1\n",
      "2.0L Twin-Rotor Turbo                    1\n",
      "2.6L Inline-4                            1\n",
      "2.3L Miller Cycle V6                     1\n",
      "1.2L Inline-4                            1\n",
      "3.0L Inline-4                            1\n",
      "1.0L Inline-2 (Wankel)                   1\n",
      "1.6L Inline-2 (Wankel)                   1\n",
      "0.36L Inline-2                           1\n",
      "2.6L Wankel Rotary Engine                1\n",
      "2.5L Hybrid I4                           1\n",
      "2.4L Turbo I4 (I-Force Max Hybrid)       1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Engines\"] = df[\"Engines\"].str.strip().str.title()\n",
    "engine_mapping = {\n",
    "    # --- Électrique & Hybride ---\n",
    "    \"Electric\": \"Electric\",\n",
    "    \"Electric (Dual Motor)\": \"Electric\",\n",
    "    \"Single Electric Motor\": \"Electric\",\n",
    "    \"Single Electric Motor (Rwd)\": \"Electric\",\n",
    "    \"Dual Electric Motors (Awd)\": \"Electric\",\n",
    "    \"Electric Awd\": \"Electric\",\n",
    "    \n",
    "    \"Hybrid\": \"Hybrid\",\n",
    "    \"Hybrid I4 + Electric Motor\": \"Hybrid\",\n",
    "    \"I4 / Electric\": \"Hybrid\",\n",
    "    \"Plug-in Hybrid\": \"Hybrid\",\n",
    "    \"Plug-In Hybrid (1.4L I4 Turbo)\": \"Hybrid\",\n",
    "    \"Plug-In Hybrid (0.8L I2 Diesel)\": \"Hybrid\",\n",
    "    \"Plug-In Hybrid / Diesel I4\": \"Hybrid\",\n",
    "    \"Twin-Turbo V6 Hybrid\": \"Hybrid\",\n",
    "    \"V6 Hybrid\": \"Hybrid\",\n",
    "    \"V6 Hybrid + Electric Motor\": \"Hybrid\",\n",
    "    \"I4 Hybrid\": \"Hybrid\",\n",
    "    \"1.6L 4-Cylinder Hybrid\": \"Hybrid\",\n",
    "    \"2.0L Inline-4 Hybrid\": \"Hybrid\",\n",
    "    \"2.5L Inline-4 Hybrid\": \"Hybrid\",\n",
    "    \"Hybrid (Gas + Electric)\": \"Hybrid\",\n",
    "    \"Hydrogen Fuel Cell,Electric Motor\": \"Hydrogen\",\n",
    "\n",
    "    # --- 3 cylindres ---\n",
    "    \"I3\": \"I3\",\n",
    "    \"0.7L 3-Cylinder\": \"I3\",\n",
    "    \"660Cc Inline-3\": \"I3\",\n",
    "    \"657Cc Turbocharged Inline-3\": \"I3\",\n",
    "    \"0.66L Inline-3\": \"I3\",\n",
    "    \"1.0L Inline-3\": \"I3\",\n",
    "    \"1.0L Turbocharged Inline-3\": \"I3\",\n",
    "    \"Turbocharged Inline-3\": \"I3\",\n",
    "\n",
    "    # --- 4 cylindres ---\n",
    "    \"I4\": \"I4\",\n",
    "    \"Inline-4\": \"I4\",\n",
    "    \"2.0L Inline-4\": \"I4\",\n",
    "    \"1.6L Inline-4\": \"I4\",\n",
    "    \"1.8L Inline-4\": \"I4\",\n",
    "    \"2.5L Inline-4\": \"I4\",\n",
    "    \"2.0L I4 Turbo\": \"I4\",\n",
    "    \"2.0L Turbo I4\": \"I4\",\n",
    "    \"I4 Petrol\": \"I4\",\n",
    "    \"I4 Turbocharged\": \"I4\",\n",
    "    \"Inline-4 Turbocharged\": \"I4\",\n",
    "    \"2.0L 4-Cylinder\": \"I4\",\n",
    "    \"1.6L 4-Cylinder\": \"I4\",\n",
    "\n",
    "    # --- 6 cylindres ---\n",
    "    \"I6\": \"I6\",\n",
    "    \"3.0L Inline-6\": \"I6\",\n",
    "    \"4.0L Inline-6\": \"I6\",\n",
    "    \"4.8L Inline-6\": \"I6\",\n",
    "    \"2.8L Inline-6\": \"I6\",\n",
    "    \"V6\": \"V6\",\n",
    "    \"3.6L V6\": \"V6\",\n",
    "    \"3.5L V6\": \"V6\",\n",
    "    \"2.9L V6\": \"V6\",\n",
    "    \"3.8L V6\": \"V6\",\n",
    "    \"V6 Petrol\": \"V6\",\n",
    "    \"V6 Ecoboost\": \"V6\",\n",
    "\n",
    "    # --- 8 cylindres ---\n",
    "    \"V8\": \"V8\",\n",
    "    \"5.6L V8\": \"V8\",\n",
    "    \"5.3L V8\": \"V8\",\n",
    "    \"6.2L V8\": \"V8\",\n",
    "    \"6.4L V8\": \"V8\",\n",
    "    \"5.7L V8\": \"V8\",\n",
    "    \"Naturally Aspirated V8\": \"V8\",\n",
    "    \"Supercharged V8\": \"V8\",\n",
    "\n",
    "    # --- 10, 12, 16 cylindres ---\n",
    "    \"V10\": \"V10\",\n",
    "    \"V12\": \"V12\",\n",
    "    \"W16\": \"W16\",\n",
    "\n",
    "    # --- Spéciaux ---\n",
    "    \"Wankel\": \"Rotary\",\n",
    "    \"1.3L Rotary\": \"Rotary\",\n",
    "    \"1.8L Rotary\": \"Rotary\",\n",
    "    \"Wankel Rotary Engine\": \"Rotary\",\n",
    "    \"Boxer-4\": \"Boxer\",\n",
    "    \"Flat-6\": \"Flat-6\",\n",
    "    \"3.0L Twin-Turbo Flat-6\": \"Flat-6\",\n",
    "    \"4.0L Naturally Aspirated Flat-6\": \"Flat-6\",\n",
    "}\n",
    "data[\"Engines\"] = data[\"Engines\"].replace(engine_mapping)\n",
    "\n",
    "print(data[\"Engines\"].value_counts())\n",
    "len(data[\"Engines\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Names</th>\n",
       "      <th>Engines</th>\n",
       "      <th>Fuel Types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FERRARI</td>\n",
       "      <td>V8</td>\n",
       "      <td>plug in hyrbrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROLLS ROYCE</td>\n",
       "      <td>V12</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MERCEDES</td>\n",
       "      <td>V8</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUDI</td>\n",
       "      <td>V10</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BMW</td>\n",
       "      <td>V8</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company Names Engines       Fuel Types\n",
       "0       FERRARI      V8  plug in hyrbrid\n",
       "1   ROLLS ROYCE     V12           Petrol\n",
       "3      MERCEDES      V8           Petrol\n",
       "4          AUDI     V10           Petrol\n",
       "5           BMW      V8           Petrol"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company Names\n",
       "Nissan               148\n",
       "Volkswagen           109\n",
       "Mazda                 86\n",
       "Chevrolet             58\n",
       "Peugeot               54\n",
       "Mitsubishi            54\n",
       "Kia                   54\n",
       "GMC                   51\n",
       "Porsche               47\n",
       "TOYOTA                42\n",
       "BMW                   41\n",
       "Jaguar Land Rover     39\n",
       "ROLLS ROYCE           29\n",
       "Ford                  27\n",
       "Acura                 27\n",
       "Tata Motors           24\n",
       "LAMBORGHINI           24\n",
       "HYUNDAI               22\n",
       "AUDI                  21\n",
       "Cadillac              20\n",
       "MERCEDES              19\n",
       "Jeep                  19\n",
       "KIA                   16\n",
       "ASTON MARTIN          11\n",
       "Bugatti               10\n",
       "NISSAN                10\n",
       "Volvo                  9\n",
       "HONDA                  7\n",
       "Tesla                  6\n",
       "FERRARI                5\n",
       "VOLVO                  3\n",
       "MAHINDRA               3\n",
       "MARUTI SUZUKI          3\n",
       "Toyota                 2\n",
       "KIA                    1\n",
       "BENTLEY                1\n",
       "ROLLS ROYCE            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Company Names\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"Company Names\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Company Names\"] = df[\"Company Names\"].str.strip().str.title()\n",
    "len(data[\"Company Names\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Names</th>\n",
       "      <th>Engines</th>\n",
       "      <th>Fuel Types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FERRARI</td>\n",
       "      <td>V8</td>\n",
       "      <td>plug in hyrbrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROLLS ROYCE</td>\n",
       "      <td>V12</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MERCEDES</td>\n",
       "      <td>V8</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUDI</td>\n",
       "      <td>V10</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BMW</td>\n",
       "      <td>V8</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company Names Engines       Fuel Types\n",
       "0       FERRARI      V8  plug in hyrbrid\n",
       "1   ROLLS ROYCE     V12           Petrol\n",
       "3      MERCEDES      V8           Petrol\n",
       "4          AUDI     V10           Petrol\n",
       "5           BMW      V8           Petrol"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quickly check the first few rows of data\n",
    "# to see what we have here\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Speed in km/h</th>\n",
       "      <th>CC/Battery Capacity in cc</th>\n",
       "      <th>HorsePower</th>\n",
       "      <th>Seats</th>\n",
       "      <th>Performance(0 - 100 )KM/H</th>\n",
       "      <th>Torque</th>\n",
       "      <th>Cars Prices</th>\n",
       "      <th>Fuel Types</th>\n",
       "      <th>Engines</th>\n",
       "      <th>Company Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>340.0</td>\n",
       "      <td>3990.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>800</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>V8</td>\n",
       "      <td>Ferrari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250.0</td>\n",
       "      <td>6749.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>900</td>\n",
       "      <td>460000.0</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>V12</td>\n",
       "      <td>Rolls Royce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>900</td>\n",
       "      <td>161000.0</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>V8</td>\n",
       "      <td>Mercedes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>560</td>\n",
       "      <td>253290.0</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>V10</td>\n",
       "      <td>Audi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>341.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>770</td>\n",
       "      <td>499000.0</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>V8</td>\n",
       "      <td>Bmw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total Speed in km/h  CC/Battery Capacity in cc  HorsePower  Seats  \\\n",
       "0                340.0                     3990.0       963.0      2   \n",
       "1                250.0                     6749.0       563.0      5   \n",
       "3                250.0                        3.0       630.0      4   \n",
       "4                320.0                        5.0       602.0      2   \n",
       "5                341.0                        3.0       710.0      2   \n",
       "\n",
       "   Performance(0 - 100 )KM/H  Torque  Cars Prices Fuel Types Engines  \\\n",
       "0                        2.5     800    1100000.0     Hybrid      V8   \n",
       "1                        5.3     900     460000.0     Petrol     V12   \n",
       "3                        3.2     900     161000.0     Petrol      V8   \n",
       "4                        3.6     560     253290.0     Petrol     V10   \n",
       "5                        2.9     770     499000.0     Petrol      V8   \n",
       "\n",
       "  Company Names  \n",
       "0       Ferrari  \n",
       "1   Rolls Royce  \n",
       "3      Mercedes  \n",
       "4          Audi  \n",
       "5           Bmw  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.boxplot(x=data['Cars Prices'])\n",
    "plt.title('Boxplot of Car Prices')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[data['Cars Prices'] < 600000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "sns.boxplot(x=data['Cars Prices'])\n",
    "plt.title('Boxplot of Car Prices')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       937.000000\n",
       "mean      73178.424760\n",
       "std       90491.880455\n",
       "min        4000.000000\n",
       "25%       30000.000000\n",
       "50%       45000.000000\n",
       "75%       69000.000000\n",
       "max      573000.000000\n",
       "Name: Cars Prices, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Cars Prices'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To transform the categoric variables in values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_cols = encoder.fit_transform(data[[\"Fuel Types\", \"Engines\", \"Company Names\"]])\n",
    "encoded_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out([\"Fuel Types\", \"Engines\", \"Company Names\"]))\n",
    "data = pd.concat([data.reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)\n",
    "data = data.drop(columns=[\"Fuel Types\", \"Engines\", \"Company Names\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 251)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total Speed in km/h                            0\n",
       "CC/Battery Capacity in cc                      2\n",
       "HorsePower                                     0\n",
       "Seats                                          0\n",
       "Performance(0 - 100 )KM/H                      0\n",
       "Torque                                         0\n",
       "Cars Prices                                    0\n",
       "Fuel Types_CNG/Petrol                          0\n",
       "Fuel Types_Diesel                              0\n",
       "Fuel Types_Electric                            0\n",
       "Fuel Types_Hybrid                              0\n",
       "Fuel Types_Hybrid/Electric                     0\n",
       "Fuel Types_Hydrogen                            0\n",
       "Fuel Types_Petrol                              0\n",
       "Fuel Types_Petrol/AWD                          0\n",
       "Fuel Types_Petrol/Diesel                       0\n",
       "Fuel Types_Petrol/Hybrid                       0\n",
       "Engines_1.0L I3 Turbo                          0\n",
       "Engines_1.0L I3 Turbo / 1.5L I4 Turbo          0\n",
       "Engines_1.0L Turbo I3                          0\n",
       "Engines_1.0L Turbo I3 / 1.5L Turbo I4          0\n",
       "Engines_1.0L Turbo I3 / 1.6L Diesel            0\n",
       "Engines_1.0L Turbo Inline-4                    0\n",
       "Engines_1.0L,Inline-3                          0\n",
       "Engines_1.2L Diesel I3                         0\n",
       "Engines_1.2L Hybrid                            0\n",
       "Engines_1.2L I4 Gas                            0\n",
       "Engines_1.2L I4 Gas / 1.4L I4 Gas              0\n",
       "Engines_1.2L I4 Turbo / 2.0L I4 Turbo          0\n",
       "Engines_1.2L Inline-3                          0\n",
       "Engines_1.2L Inline-3 Hybrid                   0\n",
       "Engines_1.2L Mpfi Petrol                       0\n",
       "Engines_1.2L Revotron 3-Cylinder Petrol        0\n",
       "Engines_1.2L Revotron Bi-Fuel                  0\n",
       "Engines_1.2L Revotron Petrol                   0\n",
       "Engines_1.2L Turbo Inline-3 Gasoline           0\n",
       "Engines_1.2L Turbocharged Inline-4             0\n",
       "Engines_1.2L Turbocharged Petrol               0\n",
       "Engines_1.2L,4-Cylinder,Inline-4(I4)           0\n",
       "Engines_1.3L Turbo Hybrid Inline-4             0\n",
       "Engines_1.3L Turbo I4 Gasoline                 0\n",
       "Engines_1.3L Turbo Inline-3 Gasoline           0\n",
       "Engines_1.3L Turbo Phev                        0\n",
       "Engines_1.3L Turbocharged Inline-4             0\n",
       "Engines_1.4L Cr4 Diesel                        0\n",
       "Engines_1.4L I3 Gas / 1.2L Diesel I3           0\n",
       "Engines_1.4L I4 Diesel / 1.6L Diesel           0\n",
       "Engines_1.4L I4 Gas / 1.6L I4 Gas              0\n",
       "Engines_1.4L I4 Turbo                          0\n",
       "Engines_1.4L I4 Turbo + Electric Motor         0\n",
       "Engines_1.4L I4 Turbo / 2.0L Diesel I4         0\n",
       "Engines_1.4L Inline-4                          0\n",
       "Engines_1.4L Inline-4 Gasoline                 0\n",
       "Engines_1.4L Mpfi Petrol                       0\n",
       "Engines_1.4L Turbo Inline-4 Gasoline           0\n",
       "Engines_1.4L,4-Cylinder,Inline-4(I4)           0\n",
       "Engines_1.5L Hybrid                            0\n",
       "Engines_1.5L I4 Cng                            0\n",
       "Engines_1.5L I4 Gas                            0\n",
       "Engines_1.5L I4 Turbo                          0\n",
       "Engines_1.5L I4 Turbo / 2.0L Diesel            0\n",
       "Engines_1.5L Inline-4                          0\n",
       "Engines_1.5L Inline-4 Diesel                   0\n",
       "Engines_1.5L Turbo 4-Cylinder                  0\n",
       "Engines_1.5L Turbo Hybrid                      0\n",
       "Engines_1.5L Turbo I4                          0\n",
       "Engines_1.5L Turbo I4 / 2.0L Diesel I4         0\n",
       "Engines_1.5L Turbo I4 / Electric               0\n",
       "Engines_1.5L Turbo Inline-3                    0\n",
       "Engines_1.5L Turbo Inline-4 Gasoline           0\n",
       "Engines_1.5L Turbocharged I4 Engine            0\n",
       "Engines_1.5L Turbocharged Inline-3             0\n",
       "Engines_1.5L,4-Cylinder,Inline(I4)             0\n",
       "Engines_1.5L,Hybrid                            0\n",
       "Engines_1.6L Diesel / 2.0L I4 Turbo            0\n",
       "Engines_1.6L Hybrid Turbocharged 4-Cylinder    0\n",
       "Engines_1.6L I4 Gas / 1.9L I4 Diesel           0\n",
       "Engines_1.6L I4 Gas / Diesel                   0\n",
       "Engines_1.6L Petrol + Plug In Hybrid System    0\n",
       "Engines_1.6L Turbo Gdi 4-Cylinder              0\n",
       "Engines_1.6L Turbo Inline-4                    0\n",
       "Engines_1.6L Turbocharged 4-Cylinder           0\n",
       "Engines_1.6L Turbocharged Rally Engine         0\n",
       "Engines_1.6L,Turbocharged Inline-3             0\n",
       "Engines_1.8L I4 Gas                            0\n",
       "Engines_1.8L Turbo Inline-4                    0\n",
       "Engines_1.8L,Hybrid                            0\n",
       "Engines_12.8L I6 Turbo Diesel                  0\n",
       "Engines_13.0L I6 Turbo Diesel                  0\n",
       "Engines_16.1L I6 Turbo Diesel                  0\n",
       "Engines_2.0L Diesel I4                         0\n",
       "Engines_2.0L Hybrid                            0\n",
       "Engines_2.0L I4 Turbo / 3.6L V6 Gas            0\n",
       "Engines_2.0L I4 Turbo Diesel                   0\n",
       "Engines_2.0L Inline-6                          0\n",
       "Engines_2.0L Kryotec Turbocharged Diesel       0\n",
       "Engines_2.0L Turbo 4-Cylinder                  0\n",
       "Engines_2.0L Turbo Diesel I4                   0\n",
       "Engines_2.0L Turbo Gasoline                    0\n",
       "Engines_2.0L Turbo I4 Gasoline                 0\n",
       "Engines_2.0L Turbo Inline-4                    0\n",
       "Engines_2.0L Turbo Inline-4 Gasoline           0\n",
       "Engines_2.0L Turbo Phev                        0\n",
       "Engines_2.0L Vc-Turbo Inline-4                 0\n",
       "Engines_2.0L,4-Cylinder,Inline-4(I4)           0\n",
       "Engines_2.0L,4-Cylinder,With Hybrid System     0\n",
       "Engines_2.0L,Inline-4                          0\n",
       "Engines_2.2L Dicor Diesel                      0\n",
       "Engines_2.2L Varicor Diesel                    0\n",
       "Engines_2.2L,4-Cylinder,Inline-4(I4)           0\n",
       "Engines_2.3L Inline-4 Diesel                   0\n",
       "Engines_2.3L Turbo Inline-4                    0\n",
       "Engines_2.4L I4 Tigershark Gasoline            0\n",
       "Engines_2.4L Inline-4                          0\n",
       "Engines_2.4L Inline-6                          0\n",
       "Engines_2.4L Turbo I4 (I-Force Max Hybrid)     0\n",
       "Engines_2.5L 4-Cylinder                        0\n",
       "Engines_2.5L Hybrid Turbocharged 4-Cylinder    0\n",
       "Engines_2.5L I4 Engine                         0\n",
       "Engines_2.5L Inline-4 Diesel                   0\n",
       "Engines_2.5L Inline-4 Gasoline                 0\n",
       "Engines_2.5L Turbocharged 4-Cylinder           0\n",
       "Engines_2.5L Turbocharged Inline-4             0\n",
       "Engines_2.5L V6                                0\n",
       "Engines_2.5L,Inline-4,Hybrid,Or 3.5L,V6        0\n",
       "Engines_2.6L Twin-Turbo Inline-6               0\n",
       "Engines_2.7L Inline-4 Diesel                   0\n",
       "Engines_2.7L Turbo 4-Cylinder                  0\n",
       "Engines_2.7L Turbo Diesel                      0\n",
       "Engines_2.7L Turbo Engine                      0\n",
       "Engines_2.7L Turbo Inline-4 Gasoline           0\n",
       "Engines_2.7L Twin-Turbo V6                     0\n",
       "Engines_2.8L Inline-6 Diesel                   0\n",
       "Engines_2.8L Turbo Diesel I4                   0\n",
       "Engines_2.8L,Turbo,Diesel                      0\n",
       "Engines_2.9L V6 + Electric Motor               0\n",
       "Engines_2.9L V6 Twin Turbo                     0\n",
       "Engines_2.9L Vr6                               0\n",
       "Engines_3.0L Cr4 Diesel                        0\n",
       "Engines_3.0L Flat-6 Twin Turbo                 0\n",
       "Engines_3.0L Inline-4 Diesel                   0\n",
       "Engines_3.0L Twin-Turbo V6                     0\n",
       "Engines_3.0L Twin-Turbo V6 Gasoline            0\n",
       "Engines_3.0L V6                                0\n",
       "Engines_3.0L V6 Diesel / 6.0L W12 Gas          0\n",
       "Engines_3.0L V6 Turbo                          0\n",
       "Engines_3.0L V6 Turbo Diesel                   0\n",
       "Engines_3.0L V6 Turbo Diesel / 4.0L V8         0\n",
       "Engines_3.0L V6 Turbo Diesel / Gasoline        0\n",
       "Engines_3.0L V6 Twin-Turbo                     0\n",
       "Engines_3.2L V6 Pentastar Gasoline             0\n",
       "Engines_3.2L Vr6                               0\n",
       "Engines_3.3L Turbocharged V6                   0\n",
       "Engines_3.3L V6                                0\n",
       "Engines_3.3L,V6,Twin Turbo Diesel              0\n",
       "Engines_3.5L Twin-Turbo V6                     0\n",
       "Engines_3.5L,V6,Hybrid Twin-Turbo              0\n",
       "Engines_3.5L,V6,Plug In Hybrid                 0\n",
       "Engines_3.6L Twin-Turbo V6 Gasoline            0\n",
       "Engines_3.6L V6 Engine                         0\n",
       "Engines_3.6L V6 Gasoline                       0\n",
       "Engines_3.6L V6 Pentastar Gasoline             0\n",
       "Engines_3.7L V6                                0\n",
       "Engines_3.8L Twin-Turbo Flat-6                 0\n",
       "Engines_3.8L Twin-Turbo V6                     0\n",
       "Engines_4.0L V6                                0\n",
       "Engines_4.0L V8 + Electric Motor               0\n",
       "Engines_4.0L V8 Turbo Diesel                   0\n",
       "Engines_4.0L V8 Twin Turbo                     0\n",
       "Engines_4.1L V8                                0\n",
       "Engines_4.2L Inline-6                          0\n",
       "Engines_4.3L V6 Engine                         0\n",
       "Engines_4.3L V6 Gasoline                       0\n",
       "Engines_4.5L V8                                0\n",
       "Engines_5.0L V8                                0\n",
       "Engines_5.1L I4 Turbo Diesel                   0\n",
       "Engines_5.3L V8 Engine                         0\n",
       "Engines_5.3L V8 Gasoline                       0\n",
       "Engines_5.7L V8 Gasoline                       0\n",
       "Engines_5.7L V8 Gasoline With Etorque          0\n",
       "Engines_6.2L Supercharged V8 Gasoline          0\n",
       "Engines_6.2L V8 Engine                         0\n",
       "Engines_6.2L V8 Gasoline                       0\n",
       "Engines_6.4L V8 Gasoline                       0\n",
       "Engines_6.4L V8 Hemi Gasoline                  0\n",
       "Engines_6.6L V8 Diesel                         0\n",
       "Engines_6.6L V8 Engine                         0\n",
       "Engines_6.6L V8 Gasoline                       0\n",
       "Engines_624Cc Mpfi                             0\n",
       "Engines_7.7L I6 Turbo Diesel                   0\n",
       "Engines_Boxer                                  0\n",
       "Engines_Diesel I4                              0\n",
       "Engines_Dual Electric Motors                   0\n",
       "Engines_Ecoblue Turbo Diesel                   0\n",
       "Engines_Electric                               0\n",
       "Engines_Electric Motor                         0\n",
       "Engines_Flat-6                                 0\n",
       "Engines_Hybrid                                 0\n",
       "Engines_Hybrid I4                              0\n",
       "Engines_Hybrid I4+ Electric Motor              0\n",
       "Engines_Hydrogen                               0\n",
       "Engines_I3                                     0\n",
       "Engines_I4                                     0\n",
       "Engines_I4 + Electric                          0\n",
       "Engines_I4 Petrol + Electric Motor             0\n",
       "Engines_I4 Petrol / V6 Petrol                  0\n",
       "Engines_I4 Turbo Diesel                        0\n",
       "Engines_I6                                     0\n",
       "Engines_Inline-4 Hybrid                        0\n",
       "Engines_Naturally Aspirated V6                 0\n",
       "Engines_Permanent Magnet Synchronous           0\n",
       "Engines_Plug-In Hybrid V6                      0\n",
       "Engines_Turbocharged I4                        0\n",
       "Engines_Turbocharged Inline-4                  0\n",
       "Engines_Turbocharged V6                        0\n",
       "Engines_V10                                    0\n",
       "Engines_V12                                    0\n",
       "Engines_V6                                     0\n",
       "Engines_V6 / V8 Petrol                         0\n",
       "Engines_V6 Turbocharged                        0\n",
       "Engines_V8                                     0\n",
       "Engines_V8 Gasoline Engine                     0\n",
       "Engines_V8 Petrol                              0\n",
       "Company Names_Acura                            0\n",
       "Company Names_Aston Martin                     0\n",
       "Company Names_Audi                             0\n",
       "Company Names_Bentley                          0\n",
       "Company Names_Bmw                              0\n",
       "Company Names_Cadillac                         0\n",
       "Company Names_Chevrolet                        0\n",
       "Company Names_Ferrari                          0\n",
       "Company Names_Ford                             0\n",
       "Company Names_Gmc                              0\n",
       "Company Names_Honda                            0\n",
       "Company Names_Hyundai                          0\n",
       "Company Names_Jaguar Land Rover                0\n",
       "Company Names_Jeep                             0\n",
       "Company Names_Kia                              0\n",
       "Company Names_Lamborghini                      0\n",
       "Company Names_Mahindra                         0\n",
       "Company Names_Maruti Suzuki                    0\n",
       "Company Names_Mercedes                         0\n",
       "Company Names_Nissan                           0\n",
       "Company Names_Peugeot                          0\n",
       "Company Names_Porsche                          0\n",
       "Company Names_Rolls Royce                      0\n",
       "Company Names_Tata Motors                      0\n",
       "Company Names_Tesla                            0\n",
       "Company Names_Toyota                           0\n",
       "Company Names_Volkswagen                       0\n",
       "Company Names_Volvo                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(36)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X/y-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"Cars Prices\", axis=1)\n",
    "\n",
    "y = data[\"Cars Prices\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/test/validation -split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in Classic ML, we only had train/test -split\n",
    "# in deep learning, we usually use validation-data also, for better\n",
    "# optimization possibilities and better metrics\n",
    "\n",
    "# unfortunately the scikit-learn's train_test_split doesn't support validation\n",
    "# set split in itself.\n",
    "\n",
    "# if you want to split the test set into two for a validation set too, try this trick:\n",
    "\n",
    "# step 1, split the data into 70% (training data) and 30% (temporary data)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# step 2, split the temporary data in HALF (0.5) => 15% test and 15% validation\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize and log transformation find by AI because my values were too high and can tend to go negatives to the predictions side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scale X features\n",
    "X_scaler = MinMaxScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "X_val_scaled = X_scaler.transform(X_val)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Scale y target (you already have this part)\n",
    "y_train_log = np.log1p(y_train.values.reshape(-1, 1))\n",
    "y_val_log = np.log1p(y_val.values.reshape(-1, 1))\n",
    "y_test_log = np.log1p(y_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a neural network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrateur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">64,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m64,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,769</span> (315.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m80,769\u001b[0m (315.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,769</span> (315.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m80,769\u001b[0m (315.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create neural network\n",
    "from tensorflow.keras.losses import Huber\n",
    "\n",
    "# save the amount of support variables into a helper variable\n",
    "# so we don't have to update the input_shape all the time\n",
    "variable_amount = len(X.columns)\n",
    "\n",
    "# Define Sequential neural network model\n",
    "# input shape has to match the amount of SUPPORT VARIABLES\n",
    "# in other words => amount of columns in X \n",
    "# Tip: have at least the same number of nodes as in the input shape\n",
    "# output layer in regression is always 1 node without activation function\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(256, activation=\"relu\", input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1)  # linear output for regression\n",
    "])\n",
    "\n",
    "# select the optimizer and loss function\n",
    "# you can try rmsprop also as optimizer, or stochastic gradient descent\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# common tips on how to change neural network structure if your metrics are not good:\n",
    "\n",
    "# make wider (or narrower) layers (for example, 64 or 128 nodes)\n",
    "# make a longer or shorter network (add or remove layers)\n",
    "# use Dropout -layers (e.g. layers.Dropout(0.1))\n",
    "\n",
    "# remember: there's no process or mathematical formula\n",
    "# in order to figure out the optimal neural network structure\n",
    "# it's mostly all about trial and error => EXPERIMENTATION!\n",
    "\n",
    "# remember to have enough \"decision-space\" for your data!\n",
    "# it's highly unlikely a dataset with 20 different variables is going\n",
    "# to work well with only 8 nodes in each layer etc.\n",
    "\n",
    "# print out the summary of your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 111.1251 - val_loss: 78.1469\n",
      "Epoch 2/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 59.9154 - val_loss: 7.3215\n",
      "Epoch 3/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.4469 - val_loss: 1.3248\n",
      "Epoch 4/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.8617 - val_loss: 0.5845\n",
      "Epoch 5/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3608 - val_loss: 0.2698\n",
      "Epoch 6/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1853 - val_loss: 0.2494\n",
      "Epoch 7/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1357 - val_loss: 0.2355\n",
      "Epoch 8/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1016 - val_loss: 0.2353\n",
      "Epoch 9/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0943 - val_loss: 0.2276\n",
      "Epoch 10/1200\n",
      "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0997"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0740 - val_loss: 0.2311\n",
      "Epoch 11/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0687 - val_loss: 0.2329\n",
      "Epoch 12/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0595 - val_loss: 0.2356\n",
      "Epoch 13/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0520 - val_loss: 0.2365\n",
      "Epoch 14/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0640 - val_loss: 0.2392\n",
      "Epoch 15/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0520 - val_loss: 0.2440\n",
      "Epoch 16/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0400 - val_loss: 0.2451\n",
      "Epoch 17/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0452 - val_loss: 0.2452\n",
      "Epoch 18/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0376 - val_loss: 0.2438\n",
      "Epoch 19/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0503 - val_loss: 0.2541\n",
      "Epoch 20/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0337 - val_loss: 0.2469\n",
      "Epoch 21/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0415 - val_loss: 0.2506\n",
      "Epoch 22/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0381 - val_loss: 0.2519\n",
      "Epoch 23/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0392 - val_loss: 0.2595\n",
      "Epoch 24/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0329 - val_loss: 0.2567\n",
      "Epoch 25/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0352 - val_loss: 0.2557\n",
      "Epoch 26/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0283 - val_loss: 0.2517\n",
      "Epoch 27/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0334 - val_loss: 0.2573\n",
      "Epoch 28/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0349 - val_loss: 0.2575\n",
      "Epoch 29/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0315 - val_loss: 0.2615\n",
      "Epoch 30/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0278 - val_loss: 0.2575\n",
      "Epoch 31/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0242 - val_loss: 0.2589\n",
      "Epoch 32/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0254 - val_loss: 0.2515\n",
      "Epoch 33/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0266 - val_loss: 0.2571\n",
      "Epoch 34/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0312 - val_loss: 0.2601\n",
      "Epoch 35/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0267 - val_loss: 0.2526\n",
      "Epoch 36/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0281 - val_loss: 0.2524\n",
      "Epoch 37/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0278 - val_loss: 0.2557\n",
      "Epoch 38/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0245 - val_loss: 0.2564\n",
      "Epoch 39/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0294 - val_loss: 0.2601\n",
      "Epoch 40/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0224 - val_loss: 0.2619\n",
      "Epoch 41/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0226 - val_loss: 0.2610\n",
      "Epoch 42/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0262 - val_loss: 0.2575\n",
      "Epoch 43/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0247 - val_loss: 0.2553\n",
      "Epoch 44/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0226 - val_loss: 0.2571\n",
      "Epoch 45/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0239 - val_loss: 0.2689\n",
      "Epoch 46/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0242 - val_loss: 0.2615\n",
      "Epoch 47/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0230 - val_loss: 0.2681\n",
      "Epoch 48/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0251 - val_loss: 0.2641\n",
      "Epoch 49/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0243 - val_loss: 0.2555\n",
      "Epoch 50/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0213 - val_loss: 0.2573\n",
      "Epoch 51/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0258 - val_loss: 0.2535\n",
      "Epoch 52/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0240 - val_loss: 0.2564\n",
      "Epoch 53/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0222 - val_loss: 0.2627\n",
      "Epoch 54/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0229 - val_loss: 0.2622\n",
      "Epoch 55/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0198 - val_loss: 0.2628\n",
      "Epoch 56/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0253 - val_loss: 0.2571\n",
      "Epoch 57/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0217 - val_loss: 0.2530\n",
      "Epoch 58/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0246 - val_loss: 0.2547\n",
      "Epoch 59/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0204 - val_loss: 0.2524\n",
      "Epoch 60/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0269 - val_loss: 0.2533\n",
      "Epoch 61/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0215 - val_loss: 0.2554\n",
      "Epoch 62/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0213 - val_loss: 0.2536\n",
      "Epoch 63/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0225 - val_loss: 0.2615\n",
      "Epoch 64/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0237 - val_loss: 0.2511\n",
      "Epoch 65/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0193 - val_loss: 0.2622\n",
      "Epoch 66/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0243 - val_loss: 0.2493\n",
      "Epoch 67/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0228 - val_loss: 0.2509\n",
      "Epoch 68/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0216 - val_loss: 0.2555\n",
      "Epoch 69/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0216 - val_loss: 0.2598\n",
      "Epoch 70/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0249 - val_loss: 0.2504\n",
      "Epoch 71/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0191 - val_loss: 0.2495\n",
      "Epoch 72/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0235 - val_loss: 0.2484\n",
      "Epoch 73/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0224 - val_loss: 0.2554\n",
      "Epoch 74/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0226 - val_loss: 0.2512\n",
      "Epoch 75/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0189 - val_loss: 0.2527\n",
      "Epoch 76/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0204 - val_loss: 0.2588\n",
      "Epoch 77/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0231 - val_loss: 0.2466\n",
      "Epoch 78/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0204 - val_loss: 0.2571\n",
      "Epoch 79/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0225 - val_loss: 0.2410\n",
      "Epoch 80/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0219 - val_loss: 0.2558\n",
      "Epoch 81/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0209 - val_loss: 0.2427\n",
      "Epoch 82/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0203 - val_loss: 0.2586\n",
      "Epoch 83/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0188 - val_loss: 0.2433\n",
      "Epoch 84/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0208 - val_loss: 0.2644\n",
      "Epoch 85/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0206 - val_loss: 0.2484\n",
      "Epoch 86/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0187 - val_loss: 0.2523\n",
      "Epoch 87/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0203 - val_loss: 0.2476\n",
      "Epoch 88/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0212 - val_loss: 0.2503\n",
      "Epoch 89/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0198 - val_loss: 0.2418\n",
      "Epoch 90/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0206 - val_loss: 0.2535\n",
      "Epoch 91/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0218 - val_loss: 0.2461\n",
      "Epoch 92/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0213 - val_loss: 0.2476\n",
      "Epoch 93/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0197 - val_loss: 0.2524\n",
      "Epoch 94/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0195 - val_loss: 0.2525\n",
      "Epoch 95/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0186 - val_loss: 0.2478\n",
      "Epoch 96/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0211 - val_loss: 0.2555\n",
      "Epoch 97/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0190 - val_loss: 0.2432\n",
      "Epoch 98/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0188 - val_loss: 0.2565\n",
      "Epoch 99/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0201 - val_loss: 0.2445\n",
      "Epoch 100/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0228 - val_loss: 0.2428\n",
      "Epoch 101/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0220 - val_loss: 0.2539\n",
      "Epoch 102/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0203 - val_loss: 0.2450\n",
      "Epoch 103/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0194 - val_loss: 0.2523\n",
      "Epoch 104/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0193 - val_loss: 0.2553\n",
      "Epoch 105/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0173 - val_loss: 0.2499\n",
      "Epoch 106/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0200 - val_loss: 0.2430\n",
      "Epoch 107/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0201 - val_loss: 0.2514\n",
      "Epoch 108/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0217 - val_loss: 0.2470\n",
      "Epoch 109/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0209 - val_loss: 0.2517\n",
      "Epoch 110/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0200 - val_loss: 0.2363\n",
      "Epoch 111/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0207 - val_loss: 0.2721\n",
      "Epoch 112/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0224 - val_loss: 0.2417\n",
      "Epoch 113/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0198 - val_loss: 0.2707\n",
      "Epoch 114/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0217 - val_loss: 0.2265\n",
      "Epoch 115/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0240 - val_loss: 0.2566\n",
      "Epoch 116/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0242 - val_loss: 0.2456\n",
      "Epoch 117/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0189 - val_loss: 0.2493\n",
      "Epoch 118/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0184 - val_loss: 0.2476\n",
      "Epoch 119/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0204 - val_loss: 0.2501\n",
      "Epoch 120/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0201 - val_loss: 0.2593\n",
      "Epoch 121/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0216 - val_loss: 0.2556\n",
      "Epoch 122/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0193 - val_loss: 0.2456\n",
      "Epoch 123/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0217 - val_loss: 0.2601\n",
      "Epoch 124/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0188 - val_loss: 0.2497\n",
      "Epoch 125/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0181 - val_loss: 0.2476\n",
      "Epoch 126/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0217 - val_loss: 0.2382\n",
      "Epoch 127/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0223 - val_loss: 0.2688\n",
      "Epoch 128/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0204 - val_loss: 0.2502\n",
      "Epoch 129/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0218 - val_loss: 0.2517\n",
      "Epoch 130/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0201 - val_loss: 0.2472\n",
      "Epoch 131/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0228 - val_loss: 0.2710\n",
      "Epoch 132/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0201 - val_loss: 0.2396\n",
      "Epoch 133/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0197 - val_loss: 0.2570\n",
      "Epoch 134/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0181 - val_loss: 0.2411\n",
      "Epoch 135/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0207 - val_loss: 0.2527\n",
      "Epoch 136/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0210 - val_loss: 0.2503\n",
      "Epoch 137/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0195 - val_loss: 0.2602\n",
      "Epoch 138/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0179 - val_loss: 0.2435\n",
      "Epoch 139/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0212 - val_loss: 0.2669\n",
      "Epoch 140/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0201 - val_loss: 0.2463\n",
      "Epoch 141/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0223 - val_loss: 0.2556\n",
      "Epoch 142/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0228 - val_loss: 0.2771\n",
      "Epoch 143/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0189 - val_loss: 0.2445\n",
      "Epoch 144/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0177 - val_loss: 0.2581\n",
      "Epoch 145/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0221 - val_loss: 0.2419\n",
      "Epoch 146/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0207 - val_loss: 0.2612\n",
      "Epoch 147/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0237 - val_loss: 0.2570\n",
      "Epoch 148/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0233 - val_loss: 0.2444\n",
      "Epoch 149/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0229 - val_loss: 0.2581\n",
      "Epoch 150/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0214 - val_loss: 0.2589\n",
      "Epoch 151/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0224 - val_loss: 0.2627\n",
      "Epoch 152/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0189 - val_loss: 0.2746\n",
      "Epoch 153/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0236 - val_loss: 0.2554\n",
      "Epoch 154/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0217 - val_loss: 0.2639\n",
      "Epoch 155/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0202 - val_loss: 0.2654\n",
      "Epoch 156/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0231 - val_loss: 0.2477\n",
      "Epoch 157/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0208 - val_loss: 0.2966\n",
      "Epoch 158/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0281 - val_loss: 0.2687\n",
      "Epoch 159/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0244 - val_loss: 0.2971\n",
      "Epoch 160/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0282 - val_loss: 0.2496\n",
      "Epoch 161/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0233 - val_loss: 0.2653\n",
      "Epoch 162/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0222 - val_loss: 0.2513\n",
      "Epoch 163/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0230 - val_loss: 0.2540\n",
      "Epoch 164/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0225 - val_loss: 0.2569\n",
      "Epoch 165/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0224 - val_loss: 0.2651\n",
      "Epoch 166/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0218 - val_loss: 0.2744\n",
      "Epoch 167/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0234 - val_loss: 0.2651\n",
      "Epoch 168/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0227 - val_loss: 0.2442\n",
      "Epoch 169/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0226 - val_loss: 0.2665\n",
      "Epoch 170/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0207 - val_loss: 0.2687\n",
      "Epoch 171/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0259 - val_loss: 0.2692\n",
      "Epoch 172/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0213 - val_loss: 0.2555\n",
      "Epoch 173/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0238 - val_loss: 0.2554\n",
      "Epoch 174/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0224 - val_loss: 0.2485\n",
      "Epoch 175/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0189 - val_loss: 0.2847\n",
      "Epoch 176/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0184 - val_loss: 0.2383\n",
      "Epoch 177/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0248 - val_loss: 0.2650\n",
      "Epoch 178/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0219 - val_loss: 0.2519\n",
      "Epoch 179/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0192 - val_loss: 0.2526\n",
      "Epoch 180/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0221 - val_loss: 0.2709\n",
      "Epoch 181/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0253 - val_loss: 0.2862\n",
      "Epoch 182/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0225 - val_loss: 0.2586\n",
      "Epoch 183/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0209 - val_loss: 0.2577\n",
      "Epoch 184/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0230 - val_loss: 0.2840\n",
      "Epoch 185/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0238 - val_loss: 0.2704\n",
      "Epoch 186/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0220 - val_loss: 0.2434\n",
      "Epoch 187/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0253 - val_loss: 0.2898\n",
      "Epoch 188/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0330 - val_loss: 0.2342\n",
      "Epoch 189/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0259 - val_loss: 0.2812\n",
      "Epoch 190/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0223 - val_loss: 0.2621\n",
      "Epoch 191/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0264 - val_loss: 0.2680\n",
      "Epoch 192/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0255 - val_loss: 0.2740\n",
      "Epoch 193/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0241 - val_loss: 0.2536\n",
      "Epoch 194/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0216 - val_loss: 0.2530\n",
      "Epoch 195/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0227 - val_loss: 0.2784\n",
      "Epoch 196/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0243 - val_loss: 0.2563\n",
      "Epoch 197/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0233 - val_loss: 0.2465\n",
      "Epoch 198/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0227 - val_loss: 0.2767\n",
      "Epoch 199/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0227 - val_loss: 0.2550\n",
      "Epoch 200/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0230 - val_loss: 0.2631\n",
      "Epoch 201/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0191 - val_loss: 0.2753\n",
      "Epoch 202/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0230 - val_loss: 0.2457\n",
      "Epoch 203/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0219 - val_loss: 0.2724\n",
      "Epoch 204/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0188 - val_loss: 0.2504\n",
      "Epoch 205/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0229 - val_loss: 0.2621\n",
      "Epoch 206/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0232 - val_loss: 0.2700\n",
      "Epoch 207/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0259 - val_loss: 0.2673\n",
      "Epoch 208/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0224 - val_loss: 0.2653\n",
      "Epoch 209/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0198 - val_loss: 0.2734\n",
      "Epoch 210/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0196 - val_loss: 0.2754\n",
      "Epoch 211/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0222 - val_loss: 0.2564\n",
      "Epoch 212/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0229 - val_loss: 0.2789\n",
      "Epoch 213/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0205 - val_loss: 0.2430\n",
      "Epoch 214/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0230 - val_loss: 0.2582\n",
      "Epoch 215/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0183 - val_loss: 0.2620\n",
      "Epoch 216/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0217 - val_loss: 0.2510\n",
      "Epoch 217/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0239 - val_loss: 0.2504\n",
      "Epoch 218/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0197 - val_loss: 0.2650\n",
      "Epoch 219/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0202 - val_loss: 0.2637\n",
      "Epoch 220/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0198 - val_loss: 0.2877\n",
      "Epoch 221/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0234 - val_loss: 0.2484\n",
      "Epoch 222/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0236 - val_loss: 0.2813\n",
      "Epoch 223/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0178 - val_loss: 0.2621\n",
      "Epoch 224/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0168 - val_loss: 0.2657\n",
      "Epoch 225/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0203 - val_loss: 0.2925\n",
      "Epoch 226/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0231 - val_loss: 0.2274\n",
      "Epoch 227/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0316 - val_loss: 0.3176\n",
      "Epoch 228/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0267 - val_loss: 0.2582\n",
      "Epoch 229/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0228 - val_loss: 0.2867\n",
      "Epoch 230/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0199 - val_loss: 0.2454\n",
      "Epoch 231/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0217 - val_loss: 0.2833\n",
      "Epoch 232/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0209 - val_loss: 0.2582\n",
      "Epoch 233/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0196 - val_loss: 0.2755\n",
      "Epoch 234/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0238 - val_loss: 0.2590\n",
      "Epoch 235/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0200 - val_loss: 0.2669\n",
      "Epoch 236/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0213 - val_loss: 0.2649\n",
      "Epoch 237/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0178 - val_loss: 0.2538\n",
      "Epoch 238/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0203 - val_loss: 0.2688\n",
      "Epoch 239/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0250 - val_loss: 0.2849\n",
      "Epoch 240/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0261 - val_loss: 0.2671\n",
      "Epoch 241/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0265 - val_loss: 0.2406\n",
      "Epoch 242/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0190 - val_loss: 0.2867\n",
      "Epoch 243/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0251 - val_loss: 0.2500\n",
      "Epoch 244/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0175 - val_loss: 0.2758\n",
      "Epoch 245/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0168 - val_loss: 0.2715\n",
      "Epoch 246/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0180 - val_loss: 0.2539\n",
      "Epoch 247/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0215 - val_loss: 0.2667\n",
      "Epoch 248/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0220 - val_loss: 0.2650\n",
      "Epoch 249/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0191 - val_loss: 0.2784\n",
      "Epoch 250/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0218 - val_loss: 0.2779\n",
      "Epoch 251/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0196 - val_loss: 0.2643\n",
      "Epoch 252/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0172 - val_loss: 0.2552\n",
      "Epoch 253/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0187 - val_loss: 0.3067\n",
      "Epoch 254/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0225 - val_loss: 0.2605\n",
      "Epoch 255/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0233 - val_loss: 0.2557\n",
      "Epoch 256/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0246 - val_loss: 0.2740\n",
      "Epoch 257/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0213 - val_loss: 0.2816\n",
      "Epoch 258/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0169 - val_loss: 0.2902\n",
      "Epoch 259/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0205 - val_loss: 0.2594\n",
      "Epoch 260/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0195 - val_loss: 0.2606\n",
      "Epoch 261/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0183 - val_loss: 0.2595\n",
      "Epoch 262/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0183 - val_loss: 0.2699\n",
      "Epoch 263/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0170 - val_loss: 0.2535\n",
      "Epoch 264/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0201 - val_loss: 0.2620\n",
      "Epoch 265/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0166 - val_loss: 0.2570\n",
      "Epoch 266/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0184 - val_loss: 0.2771\n",
      "Epoch 267/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0167 - val_loss: 0.2735\n",
      "Epoch 268/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0175 - val_loss: 0.2536\n",
      "Epoch 269/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0229 - val_loss: 0.2591\n",
      "Epoch 270/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0275 - val_loss: 0.3078\n",
      "Epoch 271/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0311 - val_loss: 0.2951\n",
      "Epoch 272/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0234 - val_loss: 0.2496\n",
      "Epoch 273/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0293 - val_loss: 0.2735\n",
      "Epoch 274/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0222 - val_loss: 0.2674\n",
      "Epoch 275/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0158 - val_loss: 0.2546\n",
      "Epoch 276/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0181 - val_loss: 0.3027\n",
      "Epoch 277/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0224 - val_loss: 0.2654\n",
      "Epoch 278/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0176 - val_loss: 0.2618\n",
      "Epoch 279/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0170 - val_loss: 0.2654\n",
      "Epoch 280/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0194 - val_loss: 0.2867\n",
      "Epoch 281/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0201 - val_loss: 0.2791\n",
      "Epoch 282/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0212 - val_loss: 0.2737\n",
      "Epoch 283/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0201 - val_loss: 0.2556\n",
      "Epoch 284/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0208 - val_loss: 0.2735\n",
      "Epoch 285/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0226 - val_loss: 0.2592\n",
      "Epoch 286/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0240 - val_loss: 0.2509\n",
      "Epoch 287/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0217 - val_loss: 0.3048\n",
      "Epoch 288/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0232 - val_loss: 0.2943\n",
      "Epoch 289/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0212 - val_loss: 0.2878\n",
      "Epoch 290/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0195 - val_loss: 0.2832\n",
      "Epoch 291/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0197 - val_loss: 0.2716\n",
      "Epoch 292/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0162 - val_loss: 0.2519\n",
      "Epoch 293/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0156 - val_loss: 0.2873\n",
      "Epoch 294/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0171 - val_loss: 0.2981\n",
      "Epoch 295/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0221 - val_loss: 0.2566\n",
      "Epoch 296/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0238 - val_loss: 0.2927\n",
      "Epoch 297/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0217 - val_loss: 0.2566\n",
      "Epoch 298/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0229 - val_loss: 0.2596\n",
      "Epoch 299/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0212 - val_loss: 0.2882\n",
      "Epoch 300/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0212 - val_loss: 0.2515\n",
      "Epoch 301/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0192 - val_loss: 0.2787\n",
      "Epoch 302/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0188 - val_loss: 0.2825\n",
      "Epoch 303/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0215 - val_loss: 0.2671\n",
      "Epoch 304/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0184 - val_loss: 0.2795\n",
      "Epoch 305/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0196 - val_loss: 0.2689\n",
      "Epoch 306/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0158 - val_loss: 0.2601\n",
      "Epoch 307/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0157 - val_loss: 0.2798\n",
      "Epoch 308/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0194 - val_loss: 0.2688\n",
      "Epoch 309/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0210 - val_loss: 0.2800\n",
      "Epoch 310/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0228 - val_loss: 0.2479\n",
      "Epoch 311/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0199 - val_loss: 0.2782\n",
      "Epoch 312/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0205 - val_loss: 0.2866\n",
      "Epoch 313/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0180 - val_loss: 0.2712\n",
      "Epoch 314/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0206 - val_loss: 0.2830\n",
      "Epoch 315/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0171 - val_loss: 0.2780\n",
      "Epoch 316/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0167 - val_loss: 0.2515\n",
      "Epoch 317/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0179 - val_loss: 0.2628\n",
      "Epoch 318/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0198 - val_loss: 0.2771\n",
      "Epoch 319/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0177 - val_loss: 0.2958\n",
      "Epoch 320/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0224 - val_loss: 0.2837\n",
      "Epoch 321/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0181 - val_loss: 0.3150\n",
      "Epoch 322/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0284 - val_loss: 0.2847\n",
      "Epoch 323/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0258 - val_loss: 0.2808\n",
      "Epoch 324/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0179 - val_loss: 0.2539\n",
      "Epoch 325/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0171 - val_loss: 0.2646\n",
      "Epoch 326/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0177 - val_loss: 0.2547\n",
      "Epoch 327/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0186 - val_loss: 0.2747\n",
      "Epoch 328/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0173 - val_loss: 0.2572\n",
      "Epoch 329/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0170 - val_loss: 0.2746\n",
      "Epoch 330/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0184 - val_loss: 0.2847\n",
      "Epoch 331/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0202 - val_loss: 0.2846\n",
      "Epoch 332/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0166 - val_loss: 0.3013\n",
      "Epoch 333/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0272 - val_loss: 0.2824\n",
      "Epoch 334/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0243 - val_loss: 0.2470\n",
      "Epoch 335/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0212 - val_loss: 0.2655\n",
      "Epoch 336/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0205 - val_loss: 0.2799\n",
      "Epoch 337/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0203 - val_loss: 0.2789\n",
      "Epoch 338/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0205 - val_loss: 0.2619\n",
      "Epoch 339/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0193 - val_loss: 0.2768\n",
      "Epoch 340/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0227 - val_loss: 0.2436\n",
      "Epoch 341/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0283 - val_loss: 0.2422\n",
      "Epoch 342/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0300 - val_loss: 0.2836\n",
      "Epoch 343/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0240 - val_loss: 0.2783\n",
      "Epoch 344/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0203 - val_loss: 0.2802\n",
      "Epoch 345/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0199 - val_loss: 0.2455\n",
      "Epoch 346/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0196 - val_loss: 0.2623\n",
      "Epoch 347/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0209 - val_loss: 0.2496\n",
      "Epoch 348/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0185 - val_loss: 0.3415\n",
      "Epoch 349/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0298 - val_loss: 0.3072\n",
      "Epoch 350/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0321 - val_loss: 0.3200\n",
      "Epoch 351/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0242 - val_loss: 0.2905\n",
      "Epoch 352/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0212 - val_loss: 0.2921\n",
      "Epoch 353/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0240 - val_loss: 0.2758\n",
      "Epoch 354/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0182 - val_loss: 0.2482\n",
      "Epoch 355/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0172 - val_loss: 0.2784\n",
      "Epoch 356/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0138 - val_loss: 0.2657\n",
      "Epoch 357/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0145 - val_loss: 0.2739\n",
      "Epoch 358/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0139 - val_loss: 0.2689\n",
      "Epoch 359/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0134 - val_loss: 0.2518\n",
      "Epoch 360/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0177 - val_loss: 0.2553\n",
      "Epoch 361/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0186 - val_loss: 0.2657\n",
      "Epoch 362/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0188 - val_loss: 0.2580\n",
      "Epoch 363/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0201 - val_loss: 0.2546\n",
      "Epoch 364/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0188 - val_loss: 0.2540\n",
      "Epoch 365/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0189 - val_loss: 0.2752\n",
      "Epoch 366/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0267 - val_loss: 0.2439\n",
      "Epoch 367/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0239 - val_loss: 0.2517\n",
      "Epoch 368/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0259 - val_loss: 0.2803\n",
      "Epoch 369/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0184 - val_loss: 0.2782\n",
      "Epoch 370/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0170 - val_loss: 0.2682\n",
      "Epoch 371/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0157 - val_loss: 0.2808\n",
      "Epoch 372/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0175 - val_loss: 0.2726\n",
      "Epoch 373/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0149 - val_loss: 0.2587\n",
      "Epoch 374/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0183 - val_loss: 0.2666\n",
      "Epoch 375/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0135 - val_loss: 0.2697\n",
      "Epoch 376/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0151 - val_loss: 0.2693\n",
      "Epoch 377/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0163 - val_loss: 0.2768\n",
      "Epoch 378/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0171 - val_loss: 0.2448\n",
      "Epoch 379/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0184 - val_loss: 0.2557\n",
      "Epoch 380/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0192 - val_loss: 0.2810\n",
      "Epoch 381/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0184 - val_loss: 0.2927\n",
      "Epoch 382/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0175 - val_loss: 0.2385\n",
      "Epoch 383/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0195 - val_loss: 0.2700\n",
      "Epoch 384/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0180 - val_loss: 0.2864\n",
      "Epoch 385/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0193 - val_loss: 0.2622\n",
      "Epoch 386/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0203 - val_loss: 0.2447\n",
      "Epoch 387/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0202 - val_loss: 0.2505\n",
      "Epoch 388/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0161 - val_loss: 0.2967\n",
      "Epoch 389/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0168 - val_loss: 0.2734\n",
      "Epoch 390/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0164 - val_loss: 0.2826\n",
      "Epoch 391/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0202 - val_loss: 0.2438\n",
      "Epoch 392/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0204 - val_loss: 0.2710\n",
      "Epoch 393/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0192 - val_loss: 0.2698\n",
      "Epoch 394/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0137 - val_loss: 0.2506\n",
      "Epoch 395/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0138 - val_loss: 0.2515\n",
      "Epoch 396/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0146 - val_loss: 0.2463\n",
      "Epoch 397/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0249 - val_loss: 0.2566\n",
      "Epoch 398/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0265 - val_loss: 0.2472\n",
      "Epoch 399/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0194 - val_loss: 0.2760\n",
      "Epoch 400/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0197 - val_loss: 0.2757\n",
      "Epoch 401/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0171 - val_loss: 0.2528\n",
      "Epoch 402/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0191 - val_loss: 0.2563\n",
      "Epoch 403/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0178 - val_loss: 0.2644\n",
      "Epoch 404/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0196 - val_loss: 0.2635\n",
      "Epoch 405/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0158 - val_loss: 0.2499\n",
      "Epoch 406/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0180 - val_loss: 0.2595\n",
      "Epoch 407/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0209 - val_loss: 0.2560\n",
      "Epoch 408/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0171 - val_loss: 0.2453\n",
      "Epoch 409/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0224 - val_loss: 0.2703\n",
      "Epoch 410/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0174 - val_loss: 0.2810\n",
      "Epoch 411/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0164 - val_loss: 0.2862\n",
      "Epoch 412/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0201 - val_loss: 0.2965\n",
      "Epoch 413/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0190 - val_loss: 0.2409\n",
      "Epoch 414/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0162 - val_loss: 0.2509\n",
      "Epoch 415/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0169 - val_loss: 0.2653\n",
      "Epoch 416/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0158 - val_loss: 0.2497\n",
      "Epoch 417/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0163 - val_loss: 0.2840\n",
      "Epoch 418/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0154 - val_loss: 0.2513\n",
      "Epoch 419/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0161 - val_loss: 0.2629\n",
      "Epoch 420/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0142 - val_loss: 0.2430\n",
      "Epoch 421/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0142 - val_loss: 0.2598\n",
      "Epoch 422/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0162 - val_loss: 0.2563\n",
      "Epoch 423/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0155 - val_loss: 0.2728\n",
      "Epoch 424/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0140 - val_loss: 0.2550\n",
      "Epoch 425/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0163 - val_loss: 0.2559\n",
      "Epoch 426/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0206 - val_loss: 0.2552\n",
      "Epoch 427/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0181 - val_loss: 0.2984\n",
      "Epoch 428/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0244 - val_loss: 0.2950\n",
      "Epoch 429/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0224 - val_loss: 0.2598\n",
      "Epoch 430/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0193 - val_loss: 0.2480\n",
      "Epoch 431/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0179 - val_loss: 0.2552\n",
      "Epoch 432/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0183 - val_loss: 0.2506\n",
      "Epoch 433/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0181 - val_loss: 0.2673\n",
      "Epoch 434/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0153 - val_loss: 0.2514\n",
      "Epoch 435/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0163 - val_loss: 0.2595\n",
      "Epoch 436/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0179 - val_loss: 0.2463\n",
      "Epoch 437/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0208 - val_loss: 0.2621\n",
      "Epoch 438/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0242 - val_loss: 0.2410\n",
      "Epoch 439/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0299 - val_loss: 0.2633\n",
      "Epoch 440/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0213 - val_loss: 0.2515\n",
      "Epoch 441/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0208 - val_loss: 0.2850\n",
      "Epoch 442/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0237 - val_loss: 0.2681\n",
      "Epoch 443/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0171 - val_loss: 0.2707\n",
      "Epoch 444/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0164 - val_loss: 0.3049\n",
      "Epoch 445/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0232 - val_loss: 0.2788\n",
      "Epoch 446/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0182 - val_loss: 0.2599\n",
      "Epoch 447/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0152 - val_loss: 0.2644\n",
      "Epoch 448/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0134 - val_loss: 0.2851\n",
      "Epoch 449/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0157 - val_loss: 0.2563\n",
      "Epoch 450/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0138 - val_loss: 0.2507\n",
      "Epoch 451/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0142 - val_loss: 0.2780\n",
      "Epoch 452/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0195 - val_loss: 0.2886\n",
      "Epoch 453/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0208 - val_loss: 0.2675\n",
      "Epoch 454/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0132 - val_loss: 0.2530\n",
      "Epoch 455/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0144 - val_loss: 0.2587\n",
      "Epoch 456/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0160 - val_loss: 0.2606\n",
      "Epoch 457/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0202 - val_loss: 0.2474\n",
      "Epoch 458/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0162 - val_loss: 0.2496\n",
      "Epoch 459/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0151 - val_loss: 0.2633\n",
      "Epoch 460/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0151 - val_loss: 0.3088\n",
      "Epoch 461/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0212 - val_loss: 0.2410\n",
      "Epoch 462/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0173 - val_loss: 0.2528\n",
      "Epoch 463/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0142 - val_loss: 0.2645\n",
      "Epoch 464/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0150 - val_loss: 0.2633\n",
      "Epoch 465/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0187 - val_loss: 0.2622\n",
      "Epoch 466/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0155 - val_loss: 0.2796\n",
      "Epoch 467/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0205 - val_loss: 0.2762\n",
      "Epoch 468/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0227 - val_loss: 0.2486\n",
      "Epoch 469/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0188 - val_loss: 0.2796\n",
      "Epoch 470/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0203 - val_loss: 0.2526\n",
      "Epoch 471/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0193 - val_loss: 0.2538\n",
      "Epoch 472/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0170 - val_loss: 0.2501\n",
      "Epoch 473/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0125 - val_loss: 0.2666\n",
      "Epoch 474/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0206 - val_loss: 0.2630\n",
      "Epoch 475/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0226 - val_loss: 0.2400\n",
      "Epoch 476/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0255 - val_loss: 0.2586\n",
      "Epoch 477/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0200 - val_loss: 0.2593\n",
      "Epoch 478/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0194 - val_loss: 0.2409\n",
      "Epoch 479/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0183 - val_loss: 0.2627\n",
      "Epoch 480/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0147 - val_loss: 0.2411\n",
      "Epoch 481/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0194 - val_loss: 0.2466\n",
      "Epoch 482/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0154 - val_loss: 0.2470\n",
      "Epoch 483/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0168 - val_loss: 0.2565\n",
      "Epoch 484/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0165 - val_loss: 0.2439\n",
      "Epoch 485/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0198 - val_loss: 0.2488\n",
      "Epoch 486/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0165 - val_loss: 0.2530\n",
      "Epoch 487/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0162 - val_loss: 0.2901\n",
      "Epoch 488/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0182 - val_loss: 0.2686\n",
      "Epoch 489/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0157 - val_loss: 0.2444\n",
      "Epoch 490/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0152 - val_loss: 0.2620\n",
      "Epoch 491/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0147 - val_loss: 0.2432\n",
      "Epoch 492/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0185 - val_loss: 0.2657\n",
      "Epoch 493/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0157 - val_loss: 0.2311\n",
      "Epoch 494/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0190 - val_loss: 0.2435\n",
      "Epoch 495/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0153 - val_loss: 0.2486\n",
      "Epoch 496/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0138 - val_loss: 0.2685\n",
      "Epoch 497/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0129 - val_loss: 0.2557\n",
      "Epoch 498/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0131 - val_loss: 0.2570\n",
      "Epoch 499/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0128 - val_loss: 0.2588\n",
      "Epoch 500/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0116 - val_loss: 0.2455\n",
      "Epoch 501/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0147 - val_loss: 0.2534\n",
      "Epoch 502/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0122 - val_loss: 0.2489\n",
      "Epoch 503/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0125 - val_loss: 0.2397\n",
      "Epoch 504/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0139 - val_loss: 0.2621\n",
      "Epoch 505/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0157 - val_loss: 0.2405\n",
      "Epoch 506/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0154 - val_loss: 0.2454\n",
      "Epoch 507/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0131 - val_loss: 0.2516\n",
      "Epoch 508/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0162 - val_loss: 0.2494\n",
      "Epoch 509/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0136 - val_loss: 0.2443\n",
      "Epoch 510/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0138 - val_loss: 0.2687\n",
      "Epoch 511/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0147 - val_loss: 0.2768\n",
      "Epoch 512/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0151 - val_loss: 0.2538\n",
      "Epoch 513/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0140 - val_loss: 0.2448\n",
      "Epoch 514/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0168 - val_loss: 0.2773\n",
      "Epoch 515/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0169 - val_loss: 0.2435\n",
      "Epoch 516/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0151 - val_loss: 0.2492\n",
      "Epoch 517/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0141 - val_loss: 0.2698\n",
      "Epoch 518/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0146 - val_loss: 0.2534\n",
      "Epoch 519/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0139 - val_loss: 0.2602\n",
      "Epoch 520/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0155 - val_loss: 0.2580\n",
      "Epoch 521/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0178 - val_loss: 0.2573\n",
      "Epoch 522/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0168 - val_loss: 0.2905\n",
      "Epoch 523/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0165 - val_loss: 0.2550\n",
      "Epoch 524/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0140 - val_loss: 0.2497\n",
      "Epoch 525/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0181 - val_loss: 0.2701\n",
      "Epoch 526/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0161 - val_loss: 0.2412\n",
      "Epoch 527/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0146 - val_loss: 0.2504\n",
      "Epoch 528/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0151 - val_loss: 0.2868\n",
      "Epoch 529/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0232 - val_loss: 0.2549\n",
      "Epoch 530/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0169 - val_loss: 0.2719\n",
      "Epoch 531/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0167 - val_loss: 0.2316\n",
      "Epoch 532/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0167 - val_loss: 0.2623\n",
      "Epoch 533/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0150 - val_loss: 0.2742\n",
      "Epoch 534/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0149 - val_loss: 0.2580\n",
      "Epoch 535/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0153 - val_loss: 0.2651\n",
      "Epoch 536/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0165 - val_loss: 0.2938\n",
      "Epoch 537/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0187 - val_loss: 0.2827\n",
      "Epoch 538/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0180 - val_loss: 0.2586\n",
      "Epoch 539/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0153 - val_loss: 0.2472\n",
      "Epoch 540/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0150 - val_loss: 0.2671\n",
      "Epoch 541/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0206 - val_loss: 0.2450\n",
      "Epoch 542/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0178 - val_loss: 0.2563\n",
      "Epoch 543/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0173 - val_loss: 0.2419\n",
      "Epoch 544/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0252 - val_loss: 0.2732\n",
      "Epoch 545/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0186 - val_loss: 0.2478\n",
      "Epoch 546/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0169 - val_loss: 0.2331\n",
      "Epoch 547/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0175 - val_loss: 0.2304\n",
      "Epoch 548/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0249 - val_loss: 0.2570\n",
      "Epoch 549/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0186 - val_loss: 0.2290\n",
      "Epoch 550/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0183 - val_loss: 0.2588\n",
      "Epoch 551/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0154 - val_loss: 0.2506\n",
      "Epoch 552/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0150 - val_loss: 0.2488\n",
      "Epoch 553/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0118 - val_loss: 0.2434\n",
      "Epoch 554/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0124 - val_loss: 0.2355\n",
      "Epoch 555/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0122 - val_loss: 0.2487\n",
      "Epoch 556/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0122 - val_loss: 0.2374\n",
      "Epoch 557/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0149 - val_loss: 0.2505\n",
      "Epoch 558/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0133 - val_loss: 0.2422\n",
      "Epoch 559/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0178 - val_loss: 0.2600\n",
      "Epoch 560/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0155 - val_loss: 0.2415\n",
      "Epoch 561/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0151 - val_loss: 0.2589\n",
      "Epoch 562/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0149 - val_loss: 0.2455\n",
      "Epoch 563/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0140 - val_loss: 0.2550\n",
      "Epoch 564/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0123 - val_loss: 0.2399\n",
      "Epoch 565/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0171 - val_loss: 0.2446\n",
      "Epoch 566/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0139 - val_loss: 0.2448\n",
      "Epoch 567/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0175 - val_loss: 0.2671\n",
      "Epoch 568/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0134 - val_loss: 0.2429\n",
      "Epoch 569/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0172 - val_loss: 0.2424\n",
      "Epoch 570/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0167 - val_loss: 0.2685\n",
      "Epoch 571/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0143 - val_loss: 0.2394\n",
      "Epoch 572/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0134 - val_loss: 0.2632\n",
      "Epoch 573/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0145 - val_loss: 0.2434\n",
      "Epoch 574/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0148 - val_loss: 0.2366\n",
      "Epoch 575/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0124 - val_loss: 0.2430\n",
      "Epoch 576/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0159 - val_loss: 0.2542\n",
      "Epoch 577/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0167 - val_loss: 0.2545\n",
      "Epoch 578/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0129 - val_loss: 0.2470\n",
      "Epoch 579/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0159 - val_loss: 0.2355\n",
      "Epoch 580/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0133 - val_loss: 0.2629\n",
      "Epoch 581/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0144 - val_loss: 0.2414\n",
      "Epoch 582/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0173 - val_loss: 0.2670\n",
      "Epoch 583/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0160 - val_loss: 0.2681\n",
      "Epoch 584/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0152 - val_loss: 0.2584\n",
      "Epoch 585/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0156 - val_loss: 0.2509\n",
      "Epoch 586/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0141 - val_loss: 0.2618\n",
      "Epoch 587/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0151 - val_loss: 0.2644\n",
      "Epoch 588/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0130 - val_loss: 0.2653\n",
      "Epoch 589/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0153 - val_loss: 0.2593\n",
      "Epoch 590/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0142 - val_loss: 0.2432\n",
      "Epoch 591/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0126 - val_loss: 0.2831\n",
      "Epoch 592/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0161 - val_loss: 0.2746\n",
      "Epoch 593/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0153 - val_loss: 0.2654\n",
      "Epoch 594/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0157 - val_loss: 0.2495\n",
      "Epoch 595/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0131 - val_loss: 0.2399\n",
      "Epoch 596/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0121 - val_loss: 0.2297\n",
      "Epoch 597/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0193 - val_loss: 0.2599\n",
      "Epoch 598/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0155 - val_loss: 0.2355\n",
      "Epoch 599/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0141 - val_loss: 0.2733\n",
      "Epoch 600/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0171 - val_loss: 0.2521\n",
      "Epoch 601/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0141 - val_loss: 0.2711\n",
      "Epoch 602/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0151 - val_loss: 0.2404\n",
      "Epoch 603/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0145 - val_loss: 0.2911\n",
      "Epoch 604/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0166 - val_loss: 0.2327\n",
      "Epoch 605/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0141 - val_loss: 0.2438\n",
      "Epoch 606/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0121 - val_loss: 0.2549\n",
      "Epoch 607/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0133 - val_loss: 0.2396\n",
      "Epoch 608/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0161 - val_loss: 0.2342\n",
      "Epoch 609/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0136 - val_loss: 0.2507\n",
      "Epoch 610/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0134 - val_loss: 0.2301\n",
      "Epoch 611/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0162 - val_loss: 0.2595\n",
      "Epoch 612/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0163 - val_loss: 0.2471\n",
      "Epoch 613/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0134 - val_loss: 0.2287\n",
      "Epoch 614/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0140 - val_loss: 0.2383\n",
      "Epoch 615/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0159 - val_loss: 0.2369\n",
      "Epoch 616/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0182 - val_loss: 0.2634\n",
      "Epoch 617/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0176 - val_loss: 0.2344\n",
      "Epoch 618/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0177 - val_loss: 0.2599\n",
      "Epoch 619/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0126 - val_loss: 0.2467\n",
      "Epoch 620/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0140 - val_loss: 0.2651\n",
      "Epoch 621/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0142 - val_loss: 0.2570\n",
      "Epoch 622/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0146 - val_loss: 0.2418\n",
      "Epoch 623/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0160 - val_loss: 0.2671\n",
      "Epoch 624/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0204 - val_loss: 0.3187\n",
      "Epoch 625/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0214 - val_loss: 0.2441\n",
      "Epoch 626/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0155 - val_loss: 0.2671\n",
      "Epoch 627/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0182 - val_loss: 0.2763\n",
      "Epoch 628/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0158 - val_loss: 0.2509\n",
      "Epoch 629/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0135 - val_loss: 0.2540\n",
      "Epoch 630/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0141 - val_loss: 0.2600\n",
      "Epoch 631/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0138 - val_loss: 0.2441\n",
      "Epoch 632/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0166 - val_loss: 0.2623\n",
      "Epoch 633/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0134 - val_loss: 0.2625\n",
      "Epoch 634/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0171 - val_loss: 0.2621\n",
      "Epoch 635/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0129 - val_loss: 0.2538\n",
      "Epoch 636/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0127 - val_loss: 0.2514\n",
      "Epoch 637/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0146 - val_loss: 0.2399\n",
      "Epoch 638/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0154 - val_loss: 0.2455\n",
      "Epoch 639/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0128 - val_loss: 0.2506\n",
      "Epoch 640/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0120 - val_loss: 0.2387\n",
      "Epoch 641/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0123 - val_loss: 0.2377\n",
      "Epoch 642/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0135 - val_loss: 0.2412\n",
      "Epoch 643/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0150 - val_loss: 0.2583\n",
      "Epoch 644/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0149 - val_loss: 0.3052\n",
      "Epoch 645/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0191 - val_loss: 0.2549\n",
      "Epoch 646/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0147 - val_loss: 0.2415\n",
      "Epoch 647/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0157 - val_loss: 0.2465\n",
      "Epoch 648/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0152 - val_loss: 0.2298\n",
      "Epoch 649/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0179 - val_loss: 0.2472\n",
      "Epoch 650/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0126 - val_loss: 0.2491\n",
      "Epoch 651/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0131 - val_loss: 0.2407\n",
      "Epoch 652/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0134 - val_loss: 0.2738\n",
      "Epoch 653/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0132 - val_loss: 0.2433\n",
      "Epoch 654/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0129 - val_loss: 0.2470\n",
      "Epoch 655/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0155 - val_loss: 0.2300\n",
      "Epoch 656/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0203 - val_loss: 0.2724\n",
      "Epoch 657/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0196 - val_loss: 0.2620\n",
      "Epoch 658/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0162 - val_loss: 0.2491\n",
      "Epoch 659/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0135 - val_loss: 0.2301\n",
      "Epoch 660/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0141 - val_loss: 0.2324\n",
      "Epoch 661/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0132 - val_loss: 0.2423\n",
      "Epoch 662/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0166 - val_loss: 0.2351\n",
      "Epoch 663/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0130 - val_loss: 0.2389\n",
      "Epoch 664/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0173 - val_loss: 0.2483\n",
      "Epoch 665/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0130 - val_loss: 0.2466\n",
      "Epoch 666/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0164 - val_loss: 0.2414\n",
      "Epoch 667/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0228 - val_loss: 0.2523\n",
      "Epoch 668/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0168 - val_loss: 0.2446\n",
      "Epoch 669/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0153 - val_loss: 0.2625\n",
      "Epoch 670/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0136 - val_loss: 0.2356\n",
      "Epoch 671/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0124 - val_loss: 0.2656\n",
      "Epoch 672/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0143 - val_loss: 0.2432\n",
      "Epoch 673/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0123 - val_loss: 0.2583\n",
      "Epoch 674/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0122 - val_loss: 0.2500\n",
      "Epoch 675/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0133 - val_loss: 0.2551\n",
      "Epoch 676/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0130 - val_loss: 0.2473\n",
      "Epoch 677/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0145 - val_loss: 0.2329\n",
      "Epoch 678/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0134 - val_loss: 0.2438\n",
      "Epoch 679/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0115 - val_loss: 0.2523\n",
      "Epoch 680/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0125 - val_loss: 0.2406\n",
      "Epoch 681/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0117 - val_loss: 0.2246\n",
      "Epoch 682/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0128 - val_loss: 0.2451\n",
      "Epoch 683/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0119 - val_loss: 0.2658\n",
      "Epoch 684/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0150 - val_loss: 0.2425\n",
      "Epoch 685/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0131 - val_loss: 0.2495\n",
      "Epoch 686/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0133 - val_loss: 0.2405\n",
      "Epoch 687/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0115 - val_loss: 0.2358\n",
      "Epoch 688/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0144 - val_loss: 0.2358\n",
      "Epoch 689/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0120 - val_loss: 0.2461\n",
      "Epoch 690/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0158 - val_loss: 0.2352\n",
      "Epoch 691/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0183 - val_loss: 0.2627\n",
      "Epoch 692/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0196 - val_loss: 0.2473\n",
      "Epoch 693/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0138 - val_loss: 0.2355\n",
      "Epoch 694/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0118 - val_loss: 0.2252\n",
      "Epoch 695/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0189 - val_loss: 0.2382\n",
      "Epoch 696/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0209 - val_loss: 0.2410\n",
      "Epoch 697/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0247 - val_loss: 0.2470\n",
      "Epoch 698/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0247 - val_loss: 0.2341\n",
      "Epoch 699/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0171 - val_loss: 0.2484\n",
      "Epoch 700/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0148 - val_loss: 0.2511\n",
      "Epoch 701/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0120 - val_loss: 0.2371\n",
      "Epoch 702/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0149 - val_loss: 0.2473\n",
      "Epoch 703/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0114 - val_loss: 0.2384\n",
      "Epoch 704/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0119 - val_loss: 0.2407\n",
      "Epoch 705/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0131 - val_loss: 0.2321\n",
      "Epoch 706/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0120 - val_loss: 0.2487\n",
      "Epoch 707/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0120 - val_loss: 0.2487\n",
      "Epoch 708/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0132 - val_loss: 0.2694\n",
      "Epoch 709/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0131 - val_loss: 0.2459\n",
      "Epoch 710/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0137 - val_loss: 0.2241\n",
      "Epoch 711/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0161 - val_loss: 0.2668\n",
      "Epoch 712/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0142 - val_loss: 0.2410\n",
      "Epoch 713/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0137 - val_loss: 0.2342\n",
      "Epoch 714/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0132 - val_loss: 0.2479\n",
      "Epoch 715/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0159 - val_loss: 0.2483\n",
      "Epoch 716/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0146 - val_loss: 0.2747\n",
      "Epoch 717/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0184 - val_loss: 0.2474\n",
      "Epoch 718/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0115 - val_loss: 0.2437\n",
      "Epoch 719/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0108 - val_loss: 0.2467\n",
      "Epoch 720/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0117 - val_loss: 0.2447\n",
      "Epoch 721/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0108 - val_loss: 0.2457\n",
      "Epoch 722/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0111 - val_loss: 0.2874\n",
      "Epoch 723/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0154 - val_loss: 0.2640\n",
      "Epoch 724/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0159 - val_loss: 0.2506\n",
      "Epoch 725/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0140 - val_loss: 0.2543\n",
      "Epoch 726/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0159 - val_loss: 0.2479\n",
      "Epoch 727/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0217 - val_loss: 0.2737\n",
      "Epoch 728/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0203 - val_loss: 0.2552\n",
      "Epoch 729/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0173 - val_loss: 0.2529\n",
      "Epoch 730/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0130 - val_loss: 0.2555\n",
      "Epoch 731/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0116 - val_loss: 0.2649\n",
      "Epoch 732/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0124 - val_loss: 0.2626\n",
      "Epoch 733/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0174 - val_loss: 0.2619\n",
      "Epoch 734/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0154 - val_loss: 0.2519\n",
      "Epoch 735/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0107 - val_loss: 0.2337\n",
      "Epoch 736/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0115 - val_loss: 0.2343\n",
      "Epoch 737/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0124 - val_loss: 0.2458\n",
      "Epoch 738/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0114 - val_loss: 0.2348\n",
      "Epoch 739/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0154 - val_loss: 0.2646\n",
      "Epoch 740/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0157 - val_loss: 0.2546\n",
      "Epoch 741/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0125 - val_loss: 0.2453\n",
      "Epoch 742/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0118 - val_loss: 0.2415\n",
      "Epoch 743/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0122 - val_loss: 0.2716\n",
      "Epoch 744/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0191 - val_loss: 0.2508\n",
      "Epoch 745/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0169 - val_loss: 0.2457\n",
      "Epoch 746/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0157 - val_loss: 0.2545\n",
      "Epoch 747/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0150 - val_loss: 0.2726\n",
      "Epoch 748/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0164 - val_loss: 0.2526\n",
      "Epoch 749/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0119 - val_loss: 0.2434\n",
      "Epoch 750/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0176 - val_loss: 0.2404\n",
      "Epoch 751/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0178 - val_loss: 0.2376\n",
      "Epoch 752/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0136 - val_loss: 0.2532\n",
      "Epoch 753/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0125 - val_loss: 0.2469\n",
      "Epoch 754/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0109 - val_loss: 0.2515\n",
      "Epoch 755/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0113 - val_loss: 0.2513\n",
      "Epoch 756/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0103 - val_loss: 0.2436\n",
      "Epoch 757/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0092 - val_loss: 0.2469\n",
      "Epoch 758/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0107 - val_loss: 0.2398\n",
      "Epoch 759/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0108 - val_loss: 0.2519\n",
      "Epoch 760/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0103 - val_loss: 0.2401\n",
      "Epoch 761/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0115 - val_loss: 0.2579\n",
      "Epoch 762/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0113 - val_loss: 0.2662\n",
      "Epoch 763/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0114 - val_loss: 0.2604\n",
      "Epoch 764/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0111 - val_loss: 0.2596\n",
      "Epoch 765/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0125 - val_loss: 0.2365\n",
      "Epoch 766/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0114 - val_loss: 0.2484\n",
      "Epoch 767/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0109 - val_loss: 0.2451\n",
      "Epoch 768/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0101 - val_loss: 0.2456\n",
      "Epoch 769/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0110 - val_loss: 0.2466\n",
      "Epoch 770/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0104 - val_loss: 0.2561\n",
      "Epoch 771/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0177 - val_loss: 0.2518\n",
      "Epoch 772/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0173 - val_loss: 0.2320\n",
      "Epoch 773/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0165 - val_loss: 0.2518\n",
      "Epoch 774/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0124 - val_loss: 0.2389\n",
      "Epoch 775/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0138 - val_loss: 0.2378\n",
      "Epoch 776/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0130 - val_loss: 0.2249\n",
      "Epoch 777/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0137 - val_loss: 0.2432\n",
      "Epoch 778/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0166 - val_loss: 0.2450\n",
      "Epoch 779/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0119 - val_loss: 0.2431\n",
      "Epoch 780/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0129 - val_loss: 0.2362\n",
      "Epoch 781/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0119 - val_loss: 0.2378\n",
      "Epoch 782/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0120 - val_loss: 0.2354\n",
      "Epoch 783/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0130 - val_loss: 0.2340\n",
      "Epoch 784/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0105 - val_loss: 0.2386\n",
      "Epoch 785/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0124 - val_loss: 0.2422\n",
      "Epoch 786/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0127 - val_loss: 0.2608\n",
      "Epoch 787/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0137 - val_loss: 0.2584\n",
      "Epoch 788/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0146 - val_loss: 0.2616\n",
      "Epoch 789/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0098 - val_loss: 0.2388\n",
      "Epoch 790/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0114 - val_loss: 0.2380\n",
      "Epoch 791/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0100 - val_loss: 0.2394\n",
      "Epoch 792/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0130 - val_loss: 0.2409\n",
      "Epoch 793/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0123 - val_loss: 0.2609\n",
      "Epoch 794/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0124 - val_loss: 0.2412\n",
      "Epoch 795/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0124 - val_loss: 0.2567\n",
      "Epoch 796/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0148 - val_loss: 0.2315\n",
      "Epoch 797/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0127 - val_loss: 0.2449\n",
      "Epoch 798/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0117 - val_loss: 0.2412\n",
      "Epoch 799/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0129 - val_loss: 0.2658\n",
      "Epoch 800/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0124 - val_loss: 0.2442\n",
      "Epoch 801/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0137 - val_loss: 0.2488\n",
      "Epoch 802/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0128 - val_loss: 0.2272\n",
      "Epoch 803/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0131 - val_loss: 0.2343\n",
      "Epoch 804/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0106 - val_loss: 0.2484\n",
      "Epoch 805/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0133 - val_loss: 0.2302\n",
      "Epoch 806/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0144 - val_loss: 0.2242\n",
      "Epoch 807/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0116 - val_loss: 0.2433\n",
      "Epoch 808/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0157 - val_loss: 0.2236\n",
      "Epoch 809/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0142 - val_loss: 0.2670\n",
      "Epoch 810/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0111 - val_loss: 0.2443\n",
      "Epoch 811/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0114 - val_loss: 0.2578\n",
      "Epoch 812/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0127 - val_loss: 0.2446\n",
      "Epoch 813/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0122 - val_loss: 0.2313\n",
      "Epoch 814/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0118 - val_loss: 0.2361\n",
      "Epoch 815/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0134 - val_loss: 0.2351\n",
      "Epoch 816/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0123 - val_loss: 0.2273\n",
      "Epoch 817/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0183 - val_loss: 0.2354\n",
      "Epoch 818/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0214 - val_loss: 0.2539\n",
      "Epoch 819/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0202 - val_loss: 0.2437\n",
      "Epoch 820/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0180 - val_loss: 0.2576\n",
      "Epoch 821/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0147 - val_loss: 0.2459\n",
      "Epoch 822/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0117 - val_loss: 0.2425\n",
      "Epoch 823/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0114 - val_loss: 0.2416\n",
      "Epoch 824/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0132 - val_loss: 0.2310\n",
      "Epoch 825/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0109 - val_loss: 0.2471\n",
      "Epoch 826/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0104 - val_loss: 0.2486\n",
      "Epoch 827/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0109 - val_loss: 0.2404\n",
      "Epoch 828/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0104 - val_loss: 0.2298\n",
      "Epoch 829/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0123 - val_loss: 0.2362\n",
      "Epoch 830/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0112 - val_loss: 0.2323\n",
      "Epoch 831/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0118 - val_loss: 0.2319\n",
      "Epoch 832/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0097 - val_loss: 0.2435\n",
      "Epoch 833/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0121 - val_loss: 0.2442\n",
      "Epoch 834/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0102 - val_loss: 0.2584\n",
      "Epoch 835/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0135 - val_loss: 0.2538\n",
      "Epoch 836/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0124 - val_loss: 0.2571\n",
      "Epoch 837/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0151 - val_loss: 0.2291\n",
      "Epoch 838/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0138 - val_loss: 0.2408\n",
      "Epoch 839/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0127 - val_loss: 0.2350\n",
      "Epoch 840/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0127 - val_loss: 0.2272\n",
      "Epoch 841/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0162 - val_loss: 0.2391\n",
      "Epoch 842/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0109 - val_loss: 0.2421\n",
      "Epoch 843/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0126 - val_loss: 0.2347\n",
      "Epoch 844/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0106 - val_loss: 0.2497\n",
      "Epoch 845/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0128 - val_loss: 0.2409\n",
      "Epoch 846/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0109 - val_loss: 0.2393\n",
      "Epoch 847/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0107 - val_loss: 0.2424\n",
      "Epoch 848/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0100 - val_loss: 0.2431\n",
      "Epoch 849/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0118 - val_loss: 0.2355\n",
      "Epoch 850/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0123 - val_loss: 0.2360\n",
      "Epoch 851/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0104 - val_loss: 0.2526\n",
      "Epoch 852/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0169 - val_loss: 0.2333\n",
      "Epoch 853/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0134 - val_loss: 0.2481\n",
      "Epoch 854/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0109 - val_loss: 0.2366\n",
      "Epoch 855/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0113 - val_loss: 0.2270\n",
      "Epoch 856/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0136 - val_loss: 0.2349\n",
      "Epoch 857/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0165 - val_loss: 0.2305\n",
      "Epoch 858/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0163 - val_loss: 0.2368\n",
      "Epoch 859/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0134 - val_loss: 0.2557\n",
      "Epoch 860/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0121 - val_loss: 0.2450\n",
      "Epoch 861/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0137 - val_loss: 0.2358\n",
      "Epoch 862/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0127 - val_loss: 0.2474\n",
      "Epoch 863/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0098 - val_loss: 0.2554\n",
      "Epoch 864/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0109 - val_loss: 0.2507\n",
      "Epoch 865/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0136 - val_loss: 0.2372\n",
      "Epoch 866/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0121 - val_loss: 0.2347\n",
      "Epoch 867/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0104 - val_loss: 0.2339\n",
      "Epoch 868/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0090 - val_loss: 0.2370\n",
      "Epoch 869/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0118 - val_loss: 0.2566\n",
      "Epoch 870/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0143 - val_loss: 0.2546\n",
      "Epoch 871/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0148 - val_loss: 0.2576\n",
      "Epoch 872/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0156 - val_loss: 0.2704\n",
      "Epoch 873/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0145 - val_loss: 0.2494\n",
      "Epoch 874/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0141 - val_loss: 0.2501\n",
      "Epoch 875/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0119 - val_loss: 0.2306\n",
      "Epoch 876/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0130 - val_loss: 0.2392\n",
      "Epoch 877/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0106 - val_loss: 0.2405\n",
      "Epoch 878/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0118 - val_loss: 0.2315\n",
      "Epoch 879/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0119 - val_loss: 0.2337\n",
      "Epoch 880/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0091 - val_loss: 0.2441\n",
      "Epoch 881/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0087 - val_loss: 0.2372\n",
      "Epoch 882/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0117 - val_loss: 0.2443\n",
      "Epoch 883/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0122 - val_loss: 0.2342\n",
      "Epoch 884/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0117 - val_loss: 0.2300\n",
      "Epoch 885/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0104 - val_loss: 0.2650\n",
      "Epoch 886/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0157 - val_loss: 0.2377\n",
      "Epoch 887/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0126 - val_loss: 0.2301\n",
      "Epoch 888/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0139 - val_loss: 0.2339\n",
      "Epoch 889/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0120 - val_loss: 0.2440\n",
      "Epoch 890/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0122 - val_loss: 0.2399\n",
      "Epoch 891/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0107 - val_loss: 0.2453\n",
      "Epoch 892/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0118 - val_loss: 0.2325\n",
      "Epoch 893/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0092 - val_loss: 0.2259\n",
      "Epoch 894/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0137 - val_loss: 0.2248\n",
      "Epoch 895/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0153 - val_loss: 0.2550\n",
      "Epoch 896/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0142 - val_loss: 0.2330\n",
      "Epoch 897/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0126 - val_loss: 0.2418\n",
      "Epoch 898/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0135 - val_loss: 0.2424\n",
      "Epoch 899/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0107 - val_loss: 0.2445\n",
      "Epoch 900/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0111 - val_loss: 0.2341\n",
      "Epoch 901/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0113 - val_loss: 0.2250\n",
      "Epoch 902/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0162 - val_loss: 0.2308\n",
      "Epoch 903/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0176 - val_loss: 0.2336\n",
      "Epoch 904/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0173 - val_loss: 0.2451\n",
      "Epoch 905/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0211 - val_loss: 0.2290\n",
      "Epoch 906/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0170 - val_loss: 0.2426\n",
      "Epoch 907/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0140 - val_loss: 0.2450\n",
      "Epoch 908/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0119 - val_loss: 0.2557\n",
      "Epoch 909/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0135 - val_loss: 0.2397\n",
      "Epoch 910/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0106 - val_loss: 0.2280\n",
      "Epoch 911/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0107 - val_loss: 0.2247\n",
      "Epoch 912/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0108 - val_loss: 0.2251\n",
      "Epoch 913/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0102 - val_loss: 0.2484\n",
      "Epoch 914/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0107 - val_loss: 0.2501\n",
      "Epoch 915/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0108 - val_loss: 0.2541\n",
      "Epoch 916/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0156 - val_loss: 0.2577\n",
      "Epoch 917/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0147 - val_loss: 0.2440\n",
      "Epoch 918/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0116 - val_loss: 0.2367\n",
      "Epoch 919/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0111 - val_loss: 0.2417\n",
      "Epoch 920/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0108 - val_loss: 0.2402\n",
      "Epoch 921/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0108 - val_loss: 0.2259\n",
      "Epoch 922/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0102 - val_loss: 0.2350\n",
      "Epoch 923/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0104 - val_loss: 0.2256\n",
      "Epoch 924/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0130 - val_loss: 0.2224\n",
      "Epoch 925/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0133 - val_loss: 0.2287\n",
      "Epoch 926/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0133 - val_loss: 0.2424\n",
      "Epoch 927/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0103 - val_loss: 0.2307\n",
      "Epoch 928/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0098 - val_loss: 0.2354\n",
      "Epoch 929/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0150 - val_loss: 0.2303\n",
      "Epoch 930/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0101 - val_loss: 0.2484\n",
      "Epoch 931/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0104 - val_loss: 0.2440\n",
      "Epoch 932/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0109 - val_loss: 0.2331\n",
      "Epoch 933/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0124 - val_loss: 0.2242\n",
      "Epoch 934/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0130 - val_loss: 0.2460\n",
      "Epoch 935/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0140 - val_loss: 0.2695\n",
      "Epoch 936/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0155 - val_loss: 0.2522\n",
      "Epoch 937/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0138 - val_loss: 0.2257\n",
      "Epoch 938/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0119 - val_loss: 0.2299\n",
      "Epoch 939/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0096 - val_loss: 0.2324\n",
      "Epoch 940/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0095 - val_loss: 0.2270\n",
      "Epoch 941/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0119 - val_loss: 0.2221\n",
      "Epoch 942/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0133 - val_loss: 0.2366\n",
      "Epoch 943/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0105 - val_loss: 0.2243\n",
      "Epoch 944/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0111 - val_loss: 0.2486\n",
      "Epoch 945/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0112 - val_loss: 0.2340\n",
      "Epoch 946/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0095 - val_loss: 0.2218\n",
      "Epoch 947/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0118 - val_loss: 0.2350\n",
      "Epoch 948/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0088 - val_loss: 0.2317\n",
      "Epoch 949/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0128 - val_loss: 0.2258\n",
      "Epoch 950/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0128 - val_loss: 0.2318\n",
      "Epoch 951/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0149 - val_loss: 0.2365\n",
      "Epoch 952/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0152 - val_loss: 0.2359\n",
      "Epoch 953/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0137 - val_loss: 0.2739\n",
      "Epoch 954/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0210 - val_loss: 0.2606\n",
      "Epoch 955/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0147 - val_loss: 0.2478\n",
      "Epoch 956/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0142 - val_loss: 0.2410\n",
      "Epoch 957/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0100 - val_loss: 0.2517\n",
      "Epoch 958/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0120 - val_loss: 0.2555\n",
      "Epoch 959/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0129 - val_loss: 0.2599\n",
      "Epoch 960/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0149 - val_loss: 0.2374\n",
      "Epoch 961/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0121 - val_loss: 0.2254\n",
      "Epoch 962/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0093 - val_loss: 0.2331\n",
      "Epoch 963/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0109 - val_loss: 0.2354\n",
      "Epoch 964/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0102 - val_loss: 0.2280\n",
      "Epoch 965/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0118 - val_loss: 0.2505\n",
      "Epoch 966/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0117 - val_loss: 0.2499\n",
      "Epoch 967/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0125 - val_loss: 0.2276\n",
      "Epoch 968/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0115 - val_loss: 0.2394\n",
      "Epoch 969/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0097 - val_loss: 0.2251\n",
      "Epoch 970/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0117 - val_loss: 0.2343\n",
      "Epoch 971/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0128 - val_loss: 0.2499\n",
      "Epoch 972/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0114 - val_loss: 0.2306\n",
      "Epoch 973/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0115 - val_loss: 0.2242\n",
      "Epoch 974/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0122 - val_loss: 0.2308\n",
      "Epoch 975/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0096 - val_loss: 0.2365\n",
      "Epoch 976/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0102 - val_loss: 0.2318\n",
      "Epoch 977/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0093 - val_loss: 0.2440\n",
      "Epoch 978/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0097 - val_loss: 0.2490\n",
      "Epoch 979/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0110 - val_loss: 0.2242\n",
      "Epoch 980/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0124 - val_loss: 0.2358\n",
      "Epoch 981/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0106 - val_loss: 0.2381\n",
      "Epoch 982/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0130 - val_loss: 0.2317\n",
      "Epoch 983/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0107 - val_loss: 0.2324\n",
      "Epoch 984/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0111 - val_loss: 0.2379\n",
      "Epoch 985/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0091 - val_loss: 0.2432\n",
      "Epoch 986/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0125 - val_loss: 0.2184\n",
      "Epoch 987/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0141 - val_loss: 0.2473\n",
      "Epoch 988/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0120 - val_loss: 0.2231\n",
      "Epoch 989/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0112 - val_loss: 0.2373\n",
      "Epoch 990/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0110 - val_loss: 0.2539\n",
      "Epoch 991/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0138 - val_loss: 0.2507\n",
      "Epoch 992/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0143 - val_loss: 0.2377\n",
      "Epoch 993/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0105 - val_loss: 0.2263\n",
      "Epoch 994/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0150 - val_loss: 0.2239\n",
      "Epoch 995/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0183 - val_loss: 0.2351\n",
      "Epoch 996/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0188 - val_loss: 0.2319\n",
      "Epoch 997/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0141 - val_loss: 0.2507\n",
      "Epoch 998/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0127 - val_loss: 0.2286\n",
      "Epoch 999/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0112 - val_loss: 0.2319\n",
      "Epoch 1000/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0111 - val_loss: 0.2352\n",
      "Epoch 1001/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0095 - val_loss: 0.2317\n",
      "Epoch 1002/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0111 - val_loss: 0.2541\n",
      "Epoch 1003/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0119 - val_loss: 0.2390\n",
      "Epoch 1004/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0098 - val_loss: 0.2303\n",
      "Epoch 1005/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0109 - val_loss: 0.2311\n",
      "Epoch 1006/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0157 - val_loss: 0.2452\n",
      "Epoch 1007/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0106 - val_loss: 0.2261\n",
      "Epoch 1008/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0100 - val_loss: 0.2292\n",
      "Epoch 1009/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0090 - val_loss: 0.2549\n",
      "Epoch 1010/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0105 - val_loss: 0.2373\n",
      "Epoch 1011/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0142 - val_loss: 0.2333\n",
      "Epoch 1012/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0134 - val_loss: 0.2353\n",
      "Epoch 1013/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0118 - val_loss: 0.2383\n",
      "Epoch 1014/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0085 - val_loss: 0.2477\n",
      "Epoch 1015/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0129 - val_loss: 0.2393\n",
      "Epoch 1016/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0102 - val_loss: 0.2456\n",
      "Epoch 1017/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0092 - val_loss: 0.2223\n",
      "Epoch 1018/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0100 - val_loss: 0.2344\n",
      "Epoch 1019/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0081 - val_loss: 0.2333\n",
      "Epoch 1020/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0107 - val_loss: 0.2375\n",
      "Epoch 1021/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0109 - val_loss: 0.2514\n",
      "Epoch 1022/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0160 - val_loss: 0.2404\n",
      "Epoch 1023/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0108 - val_loss: 0.2445\n",
      "Epoch 1024/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0099 - val_loss: 0.2302\n",
      "Epoch 1025/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0119 - val_loss: 0.2297\n",
      "Epoch 1026/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0148 - val_loss: 0.2260\n",
      "Epoch 1027/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0127 - val_loss: 0.2312\n",
      "Epoch 1028/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0104 - val_loss: 0.2256\n",
      "Epoch 1029/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0098 - val_loss: 0.2424\n",
      "Epoch 1030/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0102 - val_loss: 0.2365\n",
      "Epoch 1031/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0125 - val_loss: 0.2357\n",
      "Epoch 1032/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0110 - val_loss: 0.2309\n",
      "Epoch 1033/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0091 - val_loss: 0.2364\n",
      "Epoch 1034/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0083 - val_loss: 0.2317\n",
      "Epoch 1035/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0100 - val_loss: 0.2260\n",
      "Epoch 1036/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0094 - val_loss: 0.2293\n",
      "Epoch 1037/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0098 - val_loss: 0.2241\n",
      "Epoch 1038/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0096 - val_loss: 0.2318\n",
      "Epoch 1039/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0093 - val_loss: 0.2281\n",
      "Epoch 1040/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0100 - val_loss: 0.2278\n",
      "Epoch 1041/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0113 - val_loss: 0.2198\n",
      "Epoch 1042/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0135 - val_loss: 0.2454\n",
      "Epoch 1043/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0115 - val_loss: 0.2256\n",
      "Epoch 1044/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0094 - val_loss: 0.2362\n",
      "Epoch 1045/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0109 - val_loss: 0.2361\n",
      "Epoch 1046/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0094 - val_loss: 0.2356\n",
      "Epoch 1047/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0102 - val_loss: 0.2426\n",
      "Epoch 1048/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0109 - val_loss: 0.2387\n",
      "Epoch 1049/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0111 - val_loss: 0.2295\n",
      "Epoch 1050/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0091 - val_loss: 0.2489\n",
      "Epoch 1051/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0107 - val_loss: 0.2397\n",
      "Epoch 1052/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0122 - val_loss: 0.2456\n",
      "Epoch 1053/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0097 - val_loss: 0.2363\n",
      "Epoch 1054/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0120 - val_loss: 0.2377\n",
      "Epoch 1055/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0108 - val_loss: 0.2410\n",
      "Epoch 1056/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0096 - val_loss: 0.2463\n",
      "Epoch 1057/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0085 - val_loss: 0.2318\n",
      "Epoch 1058/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0086 - val_loss: 0.2369\n",
      "Epoch 1059/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0104 - val_loss: 0.2289\n",
      "Epoch 1060/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0115 - val_loss: 0.2286\n",
      "Epoch 1061/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0097 - val_loss: 0.2332\n",
      "Epoch 1062/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0090 - val_loss: 0.2330\n",
      "Epoch 1063/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0095 - val_loss: 0.2450\n",
      "Epoch 1064/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0113 - val_loss: 0.2341\n",
      "Epoch 1065/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0117 - val_loss: 0.2445\n",
      "Epoch 1066/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0116 - val_loss: 0.2507\n",
      "Epoch 1067/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0116 - val_loss: 0.2335\n",
      "Epoch 1068/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0111 - val_loss: 0.2402\n",
      "Epoch 1069/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0104 - val_loss: 0.2430\n",
      "Epoch 1070/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0098 - val_loss: 0.2367\n",
      "Epoch 1071/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0097 - val_loss: 0.2450\n",
      "Epoch 1072/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0122 - val_loss: 0.2394\n",
      "Epoch 1073/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0144 - val_loss: 0.2231\n",
      "Epoch 1074/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0158 - val_loss: 0.2326\n",
      "Epoch 1075/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0171 - val_loss: 0.2345\n",
      "Epoch 1076/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0185 - val_loss: 0.2687\n",
      "Epoch 1077/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0233 - val_loss: 0.2686\n",
      "Epoch 1078/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0202 - val_loss: 0.2373\n",
      "Epoch 1079/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0177 - val_loss: 0.2420\n",
      "Epoch 1080/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0109 - val_loss: 0.2248\n",
      "Epoch 1081/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0132 - val_loss: 0.2359\n",
      "Epoch 1082/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0102 - val_loss: 0.2325\n",
      "Epoch 1083/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0096 - val_loss: 0.2396\n",
      "Epoch 1084/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0088 - val_loss: 0.2331\n",
      "Epoch 1085/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0096 - val_loss: 0.2399\n",
      "Epoch 1086/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0081 - val_loss: 0.2299\n",
      "Epoch 1087/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0094 - val_loss: 0.2343\n",
      "Epoch 1088/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0086 - val_loss: 0.2519\n",
      "Epoch 1089/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0120 - val_loss: 0.2342\n",
      "Epoch 1090/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0114 - val_loss: 0.2487\n",
      "Epoch 1091/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0101 - val_loss: 0.2318\n",
      "Epoch 1092/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0085 - val_loss: 0.2267\n",
      "Epoch 1093/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0089 - val_loss: 0.2448\n",
      "Epoch 1094/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0108 - val_loss: 0.2318\n",
      "Epoch 1095/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0094 - val_loss: 0.2333\n",
      "Epoch 1096/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0106 - val_loss: 0.2430\n",
      "Epoch 1097/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0132 - val_loss: 0.2297\n",
      "Epoch 1098/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0135 - val_loss: 0.2302\n",
      "Epoch 1099/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0132 - val_loss: 0.2342\n",
      "Epoch 1100/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0119 - val_loss: 0.2402\n",
      "Epoch 1101/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0095 - val_loss: 0.2469\n",
      "Epoch 1102/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0107 - val_loss: 0.2293\n",
      "Epoch 1103/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0164 - val_loss: 0.2316\n",
      "Epoch 1104/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0149 - val_loss: 0.2275\n",
      "Epoch 1105/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0113 - val_loss: 0.2412\n",
      "Epoch 1106/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0081 - val_loss: 0.2351\n",
      "Epoch 1107/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0090 - val_loss: 0.2366\n",
      "Epoch 1108/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0099 - val_loss: 0.2453\n",
      "Epoch 1109/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0088 - val_loss: 0.2411\n",
      "Epoch 1110/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0083 - val_loss: 0.2505\n",
      "Epoch 1111/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0080 - val_loss: 0.2322\n",
      "Epoch 1112/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0097 - val_loss: 0.2486\n",
      "Epoch 1113/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0124 - val_loss: 0.2654\n",
      "Epoch 1114/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0140 - val_loss: 0.2302\n",
      "Epoch 1115/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0098 - val_loss: 0.2318\n",
      "Epoch 1116/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0086 - val_loss: 0.2482\n",
      "Epoch 1117/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0124 - val_loss: 0.2408\n",
      "Epoch 1118/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0087 - val_loss: 0.2347\n",
      "Epoch 1119/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0092 - val_loss: 0.2421\n",
      "Epoch 1120/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0091 - val_loss: 0.2305\n",
      "Epoch 1121/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0106 - val_loss: 0.2279\n",
      "Epoch 1122/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0149 - val_loss: 0.2289\n",
      "Epoch 1123/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0123 - val_loss: 0.2361\n",
      "Epoch 1124/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0094 - val_loss: 0.2467\n",
      "Epoch 1125/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0107 - val_loss: 0.2422\n",
      "Epoch 1126/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0092 - val_loss: 0.2292\n",
      "Epoch 1127/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0075 - val_loss: 0.2518\n",
      "Epoch 1128/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0086 - val_loss: 0.2252\n",
      "Epoch 1129/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0143 - val_loss: 0.2380\n",
      "Epoch 1130/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0136 - val_loss: 0.2307\n",
      "Epoch 1131/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0094 - val_loss: 0.2385\n",
      "Epoch 1132/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0108 - val_loss: 0.2373\n",
      "Epoch 1133/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0107 - val_loss: 0.2372\n",
      "Epoch 1134/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0101 - val_loss: 0.2293\n",
      "Epoch 1135/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0088 - val_loss: 0.2332\n",
      "Epoch 1136/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0119 - val_loss: 0.2462\n",
      "Epoch 1137/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0105 - val_loss: 0.2590\n",
      "Epoch 1138/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0137 - val_loss: 0.2427\n",
      "Epoch 1139/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0106 - val_loss: 0.2321\n",
      "Epoch 1140/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0112 - val_loss: 0.2369\n",
      "Epoch 1141/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0116 - val_loss: 0.2234\n",
      "Epoch 1142/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0094 - val_loss: 0.2416\n",
      "Epoch 1143/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0102 - val_loss: 0.2374\n",
      "Epoch 1144/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0098 - val_loss: 0.2302\n",
      "Epoch 1145/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0116 - val_loss: 0.2280\n",
      "Epoch 1146/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0123 - val_loss: 0.2356\n",
      "Epoch 1147/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0130 - val_loss: 0.2375\n",
      "Epoch 1148/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0102 - val_loss: 0.2274\n",
      "Epoch 1149/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0104 - val_loss: 0.2419\n",
      "Epoch 1150/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0092 - val_loss: 0.2370\n",
      "Epoch 1151/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0108 - val_loss: 0.2259\n",
      "Epoch 1152/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0092 - val_loss: 0.2347\n",
      "Epoch 1153/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0085 - val_loss: 0.2342\n",
      "Epoch 1154/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0123 - val_loss: 0.2229\n",
      "Epoch 1155/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0096 - val_loss: 0.2371\n",
      "Epoch 1156/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0127 - val_loss: 0.2411\n",
      "Epoch 1157/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0104 - val_loss: 0.2343\n",
      "Epoch 1158/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0093 - val_loss: 0.2221\n",
      "Epoch 1159/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0151 - val_loss: 0.2445\n",
      "Epoch 1160/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0111 - val_loss: 0.2314\n",
      "Epoch 1161/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0098 - val_loss: 0.2374\n",
      "Epoch 1162/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0096 - val_loss: 0.2375\n",
      "Epoch 1163/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0096 - val_loss: 0.2373\n",
      "Epoch 1164/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0098 - val_loss: 0.2253\n",
      "Epoch 1165/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0112 - val_loss: 0.2425\n",
      "Epoch 1166/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0103 - val_loss: 0.2424\n",
      "Epoch 1167/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0116 - val_loss: 0.2469\n",
      "Epoch 1168/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0119 - val_loss: 0.2275\n",
      "Epoch 1169/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0147 - val_loss: 0.2511\n",
      "Epoch 1170/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0110 - val_loss: 0.2497\n",
      "Epoch 1171/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0113 - val_loss: 0.2399\n",
      "Epoch 1172/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0100 - val_loss: 0.2629\n",
      "Epoch 1173/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0142 - val_loss: 0.2507\n",
      "Epoch 1174/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0108 - val_loss: 0.2309\n",
      "Epoch 1175/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0112 - val_loss: 0.2507\n",
      "Epoch 1176/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0104 - val_loss: 0.2445\n",
      "Epoch 1177/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0116 - val_loss: 0.2346\n",
      "Epoch 1178/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0131 - val_loss: 0.2393\n",
      "Epoch 1179/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0128 - val_loss: 0.2366\n",
      "Epoch 1180/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0086 - val_loss: 0.2411\n",
      "Epoch 1181/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0088 - val_loss: 0.2386\n",
      "Epoch 1182/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0073 - val_loss: 0.2305\n",
      "Epoch 1183/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0086 - val_loss: 0.2380\n",
      "Epoch 1184/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0113 - val_loss: 0.2595\n",
      "Epoch 1185/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0126 - val_loss: 0.2438\n",
      "Epoch 1186/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0091 - val_loss: 0.2442\n",
      "Epoch 1187/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0098 - val_loss: 0.2452\n",
      "Epoch 1188/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0089 - val_loss: 0.2334\n",
      "Epoch 1189/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0111 - val_loss: 0.2462\n",
      "Epoch 1190/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0091 - val_loss: 0.2325\n",
      "Epoch 1191/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0102 - val_loss: 0.2348\n",
      "Epoch 1192/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0113 - val_loss: 0.2404\n",
      "Epoch 1193/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0087 - val_loss: 0.2429\n",
      "Epoch 1194/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0088 - val_loss: 0.2360\n",
      "Epoch 1195/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0088 - val_loss: 0.2438\n",
      "Epoch 1196/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0103 - val_loss: 0.2398\n",
      "Epoch 1197/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0094 - val_loss: 0.2393\n",
      "Epoch 1198/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0084 - val_loss: 0.2381\n",
      "Epoch 1199/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0088 - val_loss: 0.2390\n",
      "Epoch 1200/1200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0104 - val_loss: 0.2411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b32c906240>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/fit neural network with validation data\n",
    "# see the instructions on the train/test -split above on how to split the data correctly\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=True)\n",
    "model.fit(\n",
    "    X_train_scaled, y_train_log,\n",
    "    validation_data=(X_val_scaled, y_val_log),\n",
    "    epochs=1200,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 151ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test True Y</th>\n",
       "      <th>Model Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35915.0</td>\n",
       "      <td>40968.789062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75000.0</td>\n",
       "      <td>30905.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>171985.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>18198.402344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>85075.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>36662.035156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70600.0</td>\n",
       "      <td>88106.210938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>157300.0</td>\n",
       "      <td>133612.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>11402.186523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>14271.686523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>42000.0</td>\n",
       "      <td>42033.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>85000.0</td>\n",
       "      <td>72762.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>62000.0</td>\n",
       "      <td>47459.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>21254.798828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>44633.082031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36100.0</td>\n",
       "      <td>14002.797852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>50666.996094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>64014.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23000.0</td>\n",
       "      <td>11772.467773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>31000.0</td>\n",
       "      <td>36609.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>67300.0</td>\n",
       "      <td>152381.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>518000.0</td>\n",
       "      <td>555522.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64695.0</td>\n",
       "      <td>84356.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>72000.0</td>\n",
       "      <td>73492.710938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9200.0</td>\n",
       "      <td>9324.800781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>36800.0</td>\n",
       "      <td>20369.800781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>18400.0</td>\n",
       "      <td>19656.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>47000.0</td>\n",
       "      <td>41139.730469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>10518.724609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>49000.0</td>\n",
       "      <td>74658.039062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>32249.521484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>58500.0</td>\n",
       "      <td>23955.519531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>32491.308594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>59900.0</td>\n",
       "      <td>67144.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>11477.382812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>24960.0</td>\n",
       "      <td>20546.691406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>184100.0</td>\n",
       "      <td>185992.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>15516.800781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>22766.896484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>55000.0</td>\n",
       "      <td>59330.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>53000.0</td>\n",
       "      <td>56594.867188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>15987.569336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42000.0</td>\n",
       "      <td>45154.695312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>55000.0</td>\n",
       "      <td>90919.242188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>65723.148438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>360000.0</td>\n",
       "      <td>399543.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>18000.0</td>\n",
       "      <td>17659.792969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>56000.0</td>\n",
       "      <td>50801.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>18000.0</td>\n",
       "      <td>22831.541016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>25894.048828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>55000.0</td>\n",
       "      <td>56366.585938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>316000.0</td>\n",
       "      <td>395134.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>208000.0</td>\n",
       "      <td>265944.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>27100.0</td>\n",
       "      <td>26021.568359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>69232.679688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>57276.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>7000.0</td>\n",
       "      <td>6908.301758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>26628.414062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>43455.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>23734.363281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>85000.0</td>\n",
       "      <td>151395.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>8345.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>55000.0</td>\n",
       "      <td>48206.683594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>44397.378906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>47000.0</td>\n",
       "      <td>36046.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>390000.0</td>\n",
       "      <td>398400.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>78000.0</td>\n",
       "      <td>76813.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>22500.0</td>\n",
       "      <td>18763.224609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>95000.0</td>\n",
       "      <td>70197.914062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>45500.0</td>\n",
       "      <td>65341.789062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>82495.0</td>\n",
       "      <td>55855.972656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>19796.699219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>15937.345703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>40572.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>398000.0</td>\n",
       "      <td>374580.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>17595.0</td>\n",
       "      <td>14714.474609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>55000.0</td>\n",
       "      <td>59534.808594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>33000.0</td>\n",
       "      <td>35543.726562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>136700.0</td>\n",
       "      <td>139359.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>42795.0</td>\n",
       "      <td>54718.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>211000.0</td>\n",
       "      <td>254619.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>42000.0</td>\n",
       "      <td>41542.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>33077.542969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>180387.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>19898.330078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>38000.0</td>\n",
       "      <td>32351.332031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>18000.0</td>\n",
       "      <td>22226.947266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>56505.0</td>\n",
       "      <td>103483.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>33000.0</td>\n",
       "      <td>29792.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>44150.0</td>\n",
       "      <td>32822.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>68000.0</td>\n",
       "      <td>64014.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>12040.477539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>34492.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>32000.0</td>\n",
       "      <td>33087.226562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>137000.0</td>\n",
       "      <td>135249.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>61750.0</td>\n",
       "      <td>78751.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>48000.0</td>\n",
       "      <td>10701.009766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>349000.0</td>\n",
       "      <td>361364.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>65000.0</td>\n",
       "      <td>73753.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>41450.0</td>\n",
       "      <td>37064.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>58000.0</td>\n",
       "      <td>90919.242188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>23854.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>38000.0</td>\n",
       "      <td>32639.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>55895.0</td>\n",
       "      <td>54718.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>26496.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>85000.0</td>\n",
       "      <td>114753.992188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>34000.0</td>\n",
       "      <td>36195.214844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>545000.0</td>\n",
       "      <td>591266.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>39696.316406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>355000.0</td>\n",
       "      <td>414932.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>18718.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>327000.0</td>\n",
       "      <td>303688.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>11781.139648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>32000.0</td>\n",
       "      <td>26642.791016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>88490.0</td>\n",
       "      <td>80925.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>48000.0</td>\n",
       "      <td>43093.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>28000.0</td>\n",
       "      <td>30054.716797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>18500.0</td>\n",
       "      <td>18726.414062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>75000.0</td>\n",
       "      <td>74020.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>85000.0</td>\n",
       "      <td>43607.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>16720.0</td>\n",
       "      <td>13278.320312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>79295.0</td>\n",
       "      <td>80320.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>116000.0</td>\n",
       "      <td>101464.242188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>38400.0</td>\n",
       "      <td>42959.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>320000.0</td>\n",
       "      <td>392048.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>72947.695312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>45301.824219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>56995.0</td>\n",
       "      <td>65841.085938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>59865.0</td>\n",
       "      <td>57737.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>14322.821289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>50664.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>55000.0</td>\n",
       "      <td>111318.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>222000.0</td>\n",
       "      <td>121871.601562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>42000.0</td>\n",
       "      <td>33664.332031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>13185.124023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Test True Y  Model Predictions\n",
       "0        35915.0       40968.789062\n",
       "1        75000.0       30905.984375\n",
       "2       120000.0      171985.953125\n",
       "3        20000.0       18198.402344\n",
       "4        80000.0       85075.078125\n",
       "5        10000.0       36662.035156\n",
       "6        70600.0       88106.210938\n",
       "7       157300.0      133612.390625\n",
       "8        35000.0       11402.186523\n",
       "9        60000.0       14271.686523\n",
       "10       42000.0       42033.898438\n",
       "11       85000.0       72762.250000\n",
       "12       62000.0       47459.203125\n",
       "13       20000.0       21254.798828\n",
       "14       35000.0       44633.082031\n",
       "15       36100.0       14002.797852\n",
       "16       45000.0       50666.996094\n",
       "17       70000.0       64014.359375\n",
       "18       23000.0       11772.467773\n",
       "19       31000.0       36609.593750\n",
       "20       67300.0      152381.593750\n",
       "21      518000.0      555522.875000\n",
       "22       64695.0       84356.515625\n",
       "23       72000.0       73492.710938\n",
       "24        9200.0        9324.800781\n",
       "25       36800.0       20369.800781\n",
       "26       18400.0       19656.593750\n",
       "27       47000.0       41139.730469\n",
       "28       30000.0       10518.724609\n",
       "29       49000.0       74658.039062\n",
       "30       30000.0       32249.521484\n",
       "31       58500.0       23955.519531\n",
       "32       45000.0       32491.308594\n",
       "33       59900.0       67144.765625\n",
       "34       25000.0       11477.382812\n",
       "35       24960.0       20546.691406\n",
       "36      184100.0      185992.984375\n",
       "37       25000.0       15516.800781\n",
       "38       25000.0       22766.896484\n",
       "39       55000.0       59330.023438\n",
       "40       53000.0       56594.867188\n",
       "41       60000.0       15987.569336\n",
       "42       42000.0       45154.695312\n",
       "43       55000.0       90919.242188\n",
       "44       90000.0       65723.148438\n",
       "45      360000.0      399543.281250\n",
       "46       18000.0       17659.792969\n",
       "47       56000.0       50801.796875\n",
       "48       18000.0       22831.541016\n",
       "49       25000.0       25894.048828\n",
       "50       55000.0       56366.585938\n",
       "51      316000.0      395134.062500\n",
       "52      208000.0      265944.562500\n",
       "53       27100.0       26021.568359\n",
       "54       60000.0       69232.679688\n",
       "55       60000.0       57276.640625\n",
       "56        7000.0        6908.301758\n",
       "57       30000.0       26628.414062\n",
       "58       45000.0       43455.171875\n",
       "59       25000.0       23734.363281\n",
       "60       85000.0      151395.437500\n",
       "61       20000.0        8345.099609\n",
       "62       55000.0       48206.683594\n",
       "63       70000.0       44397.378906\n",
       "64       47000.0       36046.671875\n",
       "65      390000.0      398400.656250\n",
       "66       78000.0       76813.617188\n",
       "67       22500.0       18763.224609\n",
       "68       95000.0       70197.914062\n",
       "69       45500.0       65341.789062\n",
       "70       82495.0       55855.972656\n",
       "71       50000.0       19796.699219\n",
       "72       15000.0       15937.345703\n",
       "73       35000.0       40572.769531\n",
       "74      398000.0      374580.531250\n",
       "75       17595.0       14714.474609\n",
       "76       55000.0       59534.808594\n",
       "77       33000.0       35543.726562\n",
       "78      136700.0      139359.062500\n",
       "79       42795.0       54718.375000\n",
       "80      211000.0      254619.343750\n",
       "81       42000.0       41542.910156\n",
       "82       30000.0       33077.542969\n",
       "83       70000.0      180387.484375\n",
       "84       12000.0       19898.330078\n",
       "85       38000.0       32351.332031\n",
       "86       18000.0       22226.947266\n",
       "87       56505.0      103483.812500\n",
       "88       33000.0       29792.507812\n",
       "89       44150.0       32822.781250\n",
       "90       68000.0       64014.359375\n",
       "91       20000.0       12040.477539\n",
       "92       35000.0       34492.046875\n",
       "93       32000.0       33087.226562\n",
       "94      137000.0      135249.796875\n",
       "95       61750.0       78751.625000\n",
       "96       48000.0       10701.009766\n",
       "97      349000.0      361364.281250\n",
       "98       65000.0       73753.484375\n",
       "99       41450.0       37064.750000\n",
       "100      58000.0       90919.242188\n",
       "101      50000.0       23854.796875\n",
       "102      38000.0       32639.359375\n",
       "103      55895.0       54718.375000\n",
       "104      28000.0       26496.328125\n",
       "105      85000.0      114753.992188\n",
       "106      34000.0       36195.214844\n",
       "107     545000.0      591266.500000\n",
       "108      25000.0       39696.316406\n",
       "109     355000.0      414932.281250\n",
       "110      25000.0       18718.093750\n",
       "111     327000.0      303688.812500\n",
       "112      45000.0       11781.139648\n",
       "113      32000.0       26642.791016\n",
       "114      88490.0       80925.703125\n",
       "115      48000.0       43093.234375\n",
       "116      28000.0       30054.716797\n",
       "117      18500.0       18726.414062\n",
       "118      75000.0       74020.828125\n",
       "119      85000.0       43607.453125\n",
       "120      16720.0       13278.320312\n",
       "121      79295.0       80320.203125\n",
       "122     116000.0      101464.242188\n",
       "123      38400.0       42959.218750\n",
       "124     320000.0      392048.250000\n",
       "125      70000.0       72947.695312\n",
       "126      45000.0       45301.824219\n",
       "127      56995.0       65841.085938\n",
       "128      59865.0       57737.875000\n",
       "129      20000.0       14322.821289\n",
       "130      50000.0       50664.484375\n",
       "131      55000.0      111318.859375\n",
       "132     222000.0      121871.601562\n",
       "133      42000.0       33664.332031\n",
       "134      15000.0       13185.124023"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test predictions\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "test_predictions = np.expm1(y_pred_scaled)\n",
    "\n",
    "# reshape the data for easier comparison table\n",
    "test_predictions = pd.Series(test_predictions.reshape(len(y_test),))\n",
    "pred_df = pd.DataFrame(np.asarray(y_test), columns=['Test True Y'])\n",
    "pred_df = pd.concat([pred_df, test_predictions], axis=1)\n",
    "pred_df.columns = ['Test True Y', 'Model Predictions']\n",
    "\n",
    "# print the comparison table - true values vs. model predicted values\n",
    "# we can nicely see here how far off our model is in some cases\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 50\n",
    "y_true = np.asarray(y_test)[0:n]\n",
    "y_pred = np.asarray(test_predictions)[0:n]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(y_true, marker='o', label=\"True Values\")\n",
    "plt.plot(y_pred, marker='x', label=\"Predictions\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Sample number\")\n",
    "plt.ylabel(\"Cars Prices\")\n",
    "plt.title(\"True Values vs. Model Predictions, first 50 samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         loss   val_loss\n",
      "0  102.003456  78.146896\n",
      "1   43.438705   7.321540\n",
      "2    3.223266   1.324796\n",
      "3    0.709700   0.584504\n",
      "4    0.309192   0.269751\n",
      "------------------------\n",
      "       loss  val_loss\n",
      "4  0.309192  0.269751\n",
      "5  0.169954  0.249418\n",
      "6  0.124580  0.235481\n",
      "7  0.099345  0.235328\n",
      "8  0.083069  0.227614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "print(loss_df.head())\n",
    "print(\"------------------------\")\n",
    "loss_df.drop(index=0, inplace=True)\n",
    "loss_df.drop(index=1, inplace=True)\n",
    "loss_df.drop(index=2, inplace=True)\n",
    "loss_df.drop(index=3, inplace=True)\n",
    "\n",
    "print(loss_df.head())\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot((y_pred - y_true))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 709540154.9284046\n",
      "Mean Absolute Error: 16360.07371238426\n",
      "R^2 Score: 0.9250632898524691\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "mse = mean_squared_error(pred_df['Test True Y'], pred_df['Model Predictions'])\n",
    "mae = mean_absolute_error(pred_df['Test True Y'], pred_df['Model Predictions'])\n",
    "r2 = r2_score(pred_df['Test True Y'], pred_df['Model Predictions'])\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying the model in practice with new imaginary house, I use AI here because my values were too high in range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (629, 250), (629,)\n"
     ]
    }
   ],
   "source": [
    "train = 0.7\n",
    "validation = 0.15\n",
    "test = 0.15\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=train, random_state=42)\n",
    "relative_val_test_size = test / (test + validation)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=relative_val_test_size, random_state=42)\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_10532\\1358472983.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  imaginary_cars_encoded[col] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted Car Price\n",
      "0        171990.546875\n",
      "1         86021.960938\n",
      "2        161838.125000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "\n",
    "# ----------------------------\n",
    "# Step 0: Define your imaginary cars\n",
    "# ----------------------------\n",
    "imaginary_cars = pd.DataFrame([\n",
    "    {'Total Speed in km/h': 320, 'CC/Battery Capacity in cc': 4000, 'HorsePower': 700,\n",
    "     'Seats': 2, 'Performance(0 - 100 )KM/H': 3.0, 'Torque': 750, 'Cars Prices': 0,\n",
    "     'Fuel Types': 'Petrol', 'Engines': 'V8', 'Company Names': 'BMW'},\n",
    "    \n",
    "    {'Total Speed in km/h': 250, 'CC/Battery Capacity in cc': 5000, 'HorsePower': 600,\n",
    "     'Seats': 4, 'Performance(0 - 100 )KM/H': 4.0, 'Torque': 600, 'Cars Prices': 0,\n",
    "     'Fuel Types': 'Hybrid', 'Engines': 'V6', 'Company Names': 'Audi'},\n",
    "    \n",
    "    {'Total Speed in km/h': 280, 'CC/Battery Capacity in cc': 3000, 'HorsePower': 650,\n",
    "     'Seats': 2, 'Performance(0 - 100 )KM/H': 3.5, 'Torque': 700, 'Cars Prices': 0,\n",
    "     'Fuel Types': 'Petrol', 'Engines': 'V8', 'Company Names': 'Ferrari'}\n",
    "])\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Categorical Encoding\n",
    "# ----------------------------\n",
    "categorical_cols = ['Fuel Types', 'Engines', 'Company Names']\n",
    "imaginary_cars_encoded = pd.get_dummies(imaginary_cars, columns=categorical_cols)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Align columns with training data\n",
    "# ----------------------------\n",
    "training_columns = X_train.columns  # X_train after preprocessing including one-hot\n",
    "for col in training_columns:\n",
    "    if col not in imaginary_cars_encoded.columns:\n",
    "        imaginary_cars_encoded[col] = 0\n",
    "\n",
    "# Reorder columns exactly like training data\n",
    "imaginary_cars_encoded = imaginary_cars_encoded[training_columns]\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Scale numerical columns\n",
    "# ----------------------------\n",
    "# Identify numeric columns in X_train (you scaled them before)\n",
    "numeric_cols = ['Total Speed in km/h', 'CC/Battery Capacity in cc', 'HorsePower',\n",
    "                'Seats', 'Performance(0 - 100 )KM/H', 'Torque']  # exclude target\n",
    "\n",
    "imaginary_cars_scaled = X_scaler.transform(imaginary_cars_encoded)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 4: Predict with trained model\n",
    "# ----------------------------\n",
    "y_pred_scaled = model.predict(imaginary_cars_scaled)\n",
    "\n",
    "# Reverse log transformation to get actual price\n",
    "predicted_prices = np.expm1(y_pred_scaled)\n",
    "\n",
    "pred_df = pd.DataFrame(predicted_prices, columns=['Predicted Car Price'])\n",
    "\n",
    "# ----------------------------\n",
    "# Step 5: Output\n",
    "# ----------------------------\n",
    "pred_df = pd.DataFrame(predicted_prices, columns=['Predicted Car Price'])\n",
    "print(pred_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
